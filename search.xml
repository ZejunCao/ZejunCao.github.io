<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>6个无代码LLM、Agent、RAG开源工具及推理大模型用于时间序列预测工作</title>
      <link href="/2025/07/06/1000001255-2648421562-1-1751773056/"/>
      <url>/2025/07/06/1000001255-2648421562-1-1751773056/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/hzioWalNp5pPbDN05ifpag">6个无代码LLM、Agent、RAG开源工具及推理大模型用于时间序列预测工作</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月6日，星期日，北京，晴<br>现在直接界面式进行操作的开源工具越来越多，所以，我们来看看6个无代码LLM、Agent、RAG开源项目，可以作为应用选型。<br>另一个看看推理大模型用于时序预测，看看数据怎么组织的，以及奖励函数如何设计的，会有一些启发。<br>来看看6款无代码的LLM、Agent和RAG构建工具，做个介绍和地址整理。<br>1、RAGFlow<br>RAGFlow是一款用于深度文档理解的RAG引擎，能够在复杂的文档上构建企业级的RAG工作流，并提供可靠的引用，支持多模态数据理解、网络搜索、深度研究等。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;infiniflow&#x2F;ragflow<br>2、xpander<br>xpander是一个框架无关的智能代理后端，管理内存、工具、多用户状态、事件、防护栏等，可以主要通过用户界面构建、测试和部署智能代理，兼容LlamaIndex、CrewAI等。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;xpander-ai&#x2F;xpander. ai<br>3、TransformerLab<br>TransformerLab是一款用于实验LLM的应用程序，可以进行训练、微调或聊天，一键下载LLM（如DeepSeek、Gemma等），拖放式UI用于RAG，内置日志记录等功能。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;transformerlab&#x2F;transformerlab-app<br>4、LlamaFactory<br>LLaMA-Factory，无需编写代码即可训练和微调开源LLM和VLM，支持100多种模型、多模态微调、PPO、DPO、实验跟踪等。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;hiyouga&#x2F;LLaMA-Factory<br>5、Langflow<br>Langflow是一款用于构建AI代理的拖放式可视化工具，允许构建和部署AI驱动的代理和工作流。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;langflow-ai&#x2F;langflow<br>6、AutoAgent<br>AutoAgent，可以通过自然语言构建和部署智能代理，支持函数调用和ReAct交互模式。<br>地址：https :&#x2F;&#x2F;github. com&#x2F;HKUDS&#x2F;AutoAgent<br>看时序推理大模型的一个工作，时间序列预测（TSF）方法多依赖快速思考范式，通过提取历史模式直接映射未来值，缺乏显式的中间推理过程。</p><p>这个工作提出Time-R1，采用两阶段强化微调（RFT）策略：<br>第一阶段通过监督微调（SFT）预热，利用合成思维链（CoT）轨迹训练LLM学习时间序列分析和输出格式，数据格式如下：<br>第二阶段通过强化学习（RL）优化，结合细粒度多目标奖励函数（涵盖格式、长度、准确性、结构相似性等维度）和GRIP（基于组的相对重要性策略优化），提升LLM的泛化能力和推理路径探索效率，这里其奖励策略的设定比较重要，如下：<br>最后，看下预测的效果，实验表明，Time-R1在9个跨领域数据集上显著优于传统模型和LLM基线。<br>1、https :&#x2F;&#x2F;github. com&#x2F;lqzxt&#x2F;Time-R1<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>NLP之文本纠错开源大模型：兼看语音大模型总结</title>
      <link href="/2025/07/05/1000001254-2648421544-1-1751691077/"/>
      <url>/2025/07/05/1000001254-2648421544-1-1751691077/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/R-u7N_PheZ6MEPcMjvjAgw">NLP之文本纠错开源大模型：兼看语音大模型总结</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月5日，星期六，北京，晴<br>我们来看开源相关进展，看两个问题。<br>一个是大模型用于文本纠错开源工具，有一些模型跟数据，可以做个记录。<br>另外，在语音方面，也有一些语音转写或者对话的大模型，也做个技术汇总，看看有哪些模型，哪些数据，哪些tokenizer。</p><p>在具体功能上，支持缺字漏字、错别字错误、缺少标点、错用标点、主语不明、谓语残缺、宾语残缺、其他成分残缺、虚词多余、其他成分多余、主语多余、语序不当、动宾搭配不当、其他搭配不当共14种错误。</p><p>在训练数据上，使用200万纠错数据进行全量训练，适用于语法纠错和拼写纠错，也开源了数据集，数据集如下：</p><p>其中重点的，可以看：<br>1、目前有哪些训练数据集：<br>2、目前对于语音的tokenizer：<br>3、目前主流的语音大模型：<br>1、https :&#x2F;&#x2F;github. com&#x2F;TW-NLP&#x2F;ChineseErrorCorrector<br>2、https :&#x2F;&#x2F;github. com&#x2F;dreamtheater123&#x2F;Awesome-SpeechLM-Survey<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>研究生期间准备踏踏实实搞科研？那在这之前有本事先把这本同样踏踏实实的书看完吧。</title>
      <link href="/2025/07/04/1000000138-2247492494-1-1751621930/"/>
      <url>/2025/07/04/1000000138-2247492494-1-1751621930/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/usBgK-O9f2EnwByPPzfgqg">研究生期间准备踏踏实实搞科研？那在这之前有本事先把这本同样踏踏实实的书看完吧。</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>为什么说这本书只适合踏踏实实学的“老实人”？因为它不像大多数书籍仅教调用现成框架（如TensorFlow&#x2F;PyTorch），本书深入拆解反向传播、梯度下降等等等等核心算法的数学推导过程，并结合Python代码、Pytorch框架来逐行实现。<br>如果按照100%来划分书的内容：数学基石可以到40%、各种经典前沿神经网络工作机制40%、训练与优化技术20%。<br>而且实战部分都是以工业级问题为导向：针对实际训练中常见的梯度消失、目标函数设计难题，用矩阵微分、概率分布等数学工具提供解决方案，而非仅停留理论。<br>如果能踏踏实实学完，你就能拥有非常扎实的深度学习基础和工业级实战能力去做科研。<br>老规矩，因网盘易和谐，如果你需要这本书的PDF与配套代码可以直接扫码添加我的助理让她无偿及时发送给你最新网盘链接。<br>避免单个微信添加频繁，故备了两个微信，随意添加一个即可</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI算法工程师Future </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>再看大模型数据合成开源工具–DataFlow及自然场景文档解析评估问题</title>
      <link href="/2025/07/04/1000001253-2648421530-1-1751601527/"/>
      <url>/2025/07/04/1000001253-2648421530-1-1751601527/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/U5W_YYdLAFKJj2JlvdYTNA">再看大模型数据合成开源工具–DataFlow及自然场景文档解析评估问题</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月4日，星期五，北京，晴</p><p>为大模型微调数据集而设计的项目，提供了直观的界面，用于上传特定领域的文件，智能分割内容，生成问题，并为模型微调生成高质量的训练数据。社区成员有测试过，还不错，具体说明说明文档在：https :&#x2F;&#x2F;rncg5jvpme. feishu.cn&#x2F;docx&#x2F;IRuad1eUIo8qLoxxwAGcZvqJnDb?302from&#x3D;wiki。</p><p>另外，继续看文档解析这个场景上，看看自然场景的文档解析评估，有一个评估数据集，也有一个评估结论。</p><p>1、有哪些功能？<br>支持的任务包括纯文本训练合成、强推理数据合成、Text-to-SQL数据合成、AgenticRAG数据合成流程等。<br>其中：<br>1）纯文本数据处理不同格式的文本信息，包括预训练文本和指令微调格式文本。从大规模纯文本（多为网络爬取）中挖掘问答对，用于监督微调和强化学习训练。<br>2）强推理数据合成的核心目标是通过数学问答数据的合成与处理，扩展现有数据集的规模和多样性，增强已有问答对，添加长链式推理（Chain-of-Thought）、类别标注、难度估计。<br>具体的：问题处理：过滤非数学问题、合成新问题、验证问题正确性、进行难度评分和类别分类；答案生成与处理：根据问题的标准答案或模型生成的答案进行处理，包括格式过滤、长度过滤和正确性验证等；数据去重：对生成的问答数据进行去重，确保数据集的质量。<br>3）Text-to-SQL数据合成，通过清洗和扩充现有的Text-to-SQL数据，为每个样本生成包含训练提示词（prompt）和长链推理过程（chain-of-thought）的高质量问答数据，将自然语言问题转化为SQL查询，辅以解释、思维链推理和数据库结构上下文信息。<br>4）AgenticRAG，端到端的框架，基于强化学习的AgenticRAG训练。从提供的文本内容中生成高质量的问题和答案对。<br>2、如何评估有效性<br>其实，更为重要的还是如何验证这类工具的有效性问题，最好的方式就是消融实验，例如：<br>Bird数据集上使用DataFlow-Text2SQL流程构建数据，并分别通过监督微调（SFT）与强化学习（RL）对Qwen2. 5-Coder-14B模型进进行训练，然后看效果：<br>现在多模态大模型做文档解析的工作越来越多，我们已经做个多个介绍，但其更多的还是针对标准印刷体文档。对于拍照版本的，其实从layout以及解析等任务看，都会存在一些问题，例如下面这个图。<br>在未矫正前，直接进行布局检测，会发生错乱。<br>所以，这自然会出来一个问题，就是评估自然环境下文档理解能力，现有的DocVQA和ChartQA等主流基准测试主要涵盖扫描文档或者印刷文档，无法充分反映现实世界中各种场景（例如光照变化和物理变形）所带来的复杂挑战。<br>那么，怎么评估？关键还是这个评估数据怎么做？</p><p>论文理论本身价值不大，重点还是这份数据。<br>1、具体如何实现？<br>在具体实现上，靠虑到日常生活中遇到的各种场景，选择了五个关键因素：环境、照明、视图、失真、效果。<br>2、实际效果如何？<br>结果表明，当面对常见的现实世界扭曲（例如皱纹、弯曲和折痕）影响的文档时，MLLM的性能会显著下降，具体的指标变化，如下图所示：<br>其实这是个很有趣的话题，是先矫正，图像增强，然后变成标准文档解析，还是直接让vllm做处理，都是值得探索的方向。<br>1、https :&#x2F;&#x2F;github. com&#x2F;OpenDCAI&#x2F;DataFlow<br>2、https :&#x2F;&#x2F;arxiv. org&#x2F;pdf&#x2F;2505. 11015<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Agent做多模态RAG方案-MDocAgent及文档解析中的图像前处理问题</title>
      <link href="/2025/07/03/1000001252-2648421511-1-1751513953/"/>
      <url>/2025/07/03/1000001252-2648421511-1-1751513953/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/BbT0XCGbjwJ6mXb2EuVyGg">Agent做多模态RAG方案-MDocAgent及文档解析中的图像前处理问题</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月3日，星期四，北京，雨<br>先来看多模态RAG进展，关于这块，已经在多模态RAG专题中介绍过很多了。<br>其中提到最多的，就是ColBERT、ColPali这两类embedding模型，不过，从技术角度上讲，两者存在一定局限性。<br>例如：<br>ColBERT和ColPali可以检索到了包含相关信息的页面，但仅检索到页面是不够的，还需要进一步分析页面中的具体内容；<br>ColBERT仅依赖文本信息，未能准确解析文本中的数值数据，例如，在某些场景下或错误地得出“外国出生的拉丁裔人口更多”的结论；<br>此外，标准的多模态RAG框架，例如M3DocRAG，虽然结合了文本和图像信息，但由于缺乏对关键信息的细致提取和跨模态整合能力，未能正确回答问题。<br>因此，针对这个问题，一个很自然的方式，就是召回后，再做一些内容上的过滤，再贴点边，就是跟Agent相结合，所以，就搞个Agent?那么可以怎么玩？看一个工作。<br>另外，说到文档处理，那么，就可以再看看文档预处理，尤其是一些不规则的非印刷体文档，如何做标准化，这个对RAG也很重要。</p><p>1、有哪几个Agent?</p><p>2、具体实现步骤是什么？<br>具体步骤分成5步，如下图所示：<br>1）文档预处理：使用OCR和PDF解析提取文本，并将每页文档保存为图像，形成文本和视觉表示<br>2）多模态上下文检索：使用ColBERT和ColPali分别对文本和图像进行检索，获取与问题最相关的文本段和图像页<br>3）初始分析和关键信息提取：GeneralAgent生成初步答案，CriticalAgent提取关键信息，指导文本及图像细分处理进行分析<br>4）文本及图像细分处理：TextAgent和ImageAgent分别在各自模态内分析检索到的上下文，生成详细的答案<br>5）答案合成：SummarizingAgent综合所有智能体的输出，生成最终答案。可以重点看架构选型。<br>文档解析是当前RAG系统的重点问题，在实际处理过程中，并非总是会遇到标准的印刷体文档，还会存在一些拍照版本的问题，这个如果不做处理，直接送到layout或者ocr，会影响实际效果。<br>1、具体存在哪些问题？<br>这类问题常常表现为几何失真、阴影、污渍等多种问题，如下：<br>所以，经常需要做去畸变（去扭曲消除几何失真，如弯曲和褶皱）、去阴影、外观增强、去模糊和二值化任务，这个其实也叫文档恢复任务。<br>那么，是否可以将这几个任务放在一起做？</p><p>其意义在于提出一个统一了五种文档图像还原任务的通用模型，包括去扭曲、去阴影、外观增强、去模糊和二值化。<br>其中：<br>外观增强（也称为照明校正）不限于特定的退化类型，旨在恢复类似于从扫描仪或数字原生PDF文件获得的清晰外观；<br>去阴影的目的是消除主要由遮挡引起的阴影，以获得无阴影的文档图像；<br>去扭曲，也称为几何校正，旨在校正受到曲线、折叠、皱褶、透视&#x2F;仿射变形和其他几何扭曲的文档图像；<br>1、架构及训练阶段？<br>架构方面，特征提取网络使用DTPrompt生成器根据指定任务从输入图像中提取先验特征，并将其与输入图像拼接，恢复网络使用Restormer。<br>核心两个阶段：<br>1）动态任务特定提示（DTPrompt），根据输入图像的特征提取不同的先验特征，这些特征包括文档分割掩码、二值化结果、梯度图等，这个解决的是特征提取问题。<br>2）提示融合和恢复网络：将DTPrompt与输入图像沿通道维度拼接，形成新的输入用于恢复网络，选择Restormer作为恢复网络，并对其进行微调，这个解决的是恢复问题。<br>2、训练数据有哪些？<br>数据往往更为重要，这块没办法，还是合成方案居多，例如：<br>去扭曲处理数据包括Doc3D，一个包含100K样本的合成数据集，其中包括几何扭曲的文档图像及相应的反向映射图。<br>去阴影数据及包含来自FSDSRD的14200张合成图像和来自RDD训练集的4371张真实图像。<br>外观增强包含来自Doc3DShade数据集的90K张合成图像和来自RealDAE训练集的450张真实世界图像。<br>去模糊使用文本去模糊数据集（TDD）包含66K训练样本；二值化使用(H)-DIBCO数据集。<br>3、看下实际效果<br>看论文中提到的一些实现效果，包括输入、DTSPrompt、DocRes修复结果及真实值的可视化对比，包括去弯曲、去阴影、外观增强、去模糊和二值化。<br>4、关于文档处理这块更进一步的延伸？<br>如果要文档处理这块有更深的了解，可以看一个技术总结，包含文档图像处理方法的论文集，包括外观增强、去阴影、去扭曲、去模糊和二值化，可以跟一下一个技术总结项目。<br>地址在：https :&#x2F;&#x2F;github. com&#x2F;ZZZHANG-jx&#x2F;Recommendations-Document-Image-Processing<br>1、https :&#x2F;&#x2F;github. com&#x2F;aiming-lab&#x2F;MDocAgent<br>2、https :&#x2F;&#x2F;arxiv. org&#x2F;pdf&#x2F;2405. 04408<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>继续看真实场景下文档解析的8个另外问题：公式输出重复、阅读顺序评测等</title>
      <link href="/2025/07/02/1000001251-2648421488-1-1751426008/"/>
      <url>/2025/07/02/1000001251-2648421488-1-1751426008/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/v6cIIMALyutu74NDpuLONQ">继续看真实场景下文档解析的8个另外问题：公式输出重复、阅读顺序评测等</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月2日，星期三，北京，晴</p><p>《真实场景下文档解析中的2大类8个常见问题：目录层级解析、布局检测、阅读顺序及长表格拼接》(https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;DxIXNkF4lHzVzgw6tiSwCA)，提到多个问题，包括8个问题，pocrv5模型的具体表现？布局检测的问题？阅读顺序的问题？文档背景的干扰问题？文档目录层级解析问题？长表格的拼接问题等等。我们可以将其归并为文档解析处理中的检测问题和语义解析问题两大块内容。<br>又如：《再思考文档解析最新趋势方案及7类真实场景下文档解析Badcase记录》(https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;OcQXshrVo9gow-ADqpElHw)，包括7个问题，包括为什么要先做版面分析？为什么不用一个模型在做三个阶段的任务？换成多模态文档解析之后的经典显存问题？下划线的问题，如何解码得到？关于文档跨页拼接的问题等。<br>现在我们从issues继续看几个典型使用问题，包括数学公式解码、阅读顺序评测、内容遗漏、大写识别、合并页面、幻觉问题、表格带公式等8个问题。<br>从实际的业务case出发，看在实际应用过程中会遇到什么问题，以及怎么理解并解释，这其实能够更清晰和直接。<br>还是回归到具体落地问题，从实际的业务case出发，看在实际应用过程中会遇到什么问题，以及怎么理解并解释。<br>1、文档解析中的内容遗漏问题及通用性问题<br>继续看文档解析中的问题，ref:https :&#x2F;&#x2F;github. com&#x2F;Yuliang-Liu&#x2F;MonkeyOCR&#x2F;issues&#x2F;54<br>其实是版式分析layout标签的问题。<br>另外，关于文档解析中的图片通用性问题，问题是：医疗的诊断表，包含印刷体和非常潦草的手写体。<br>建议是，对于拍照文档和手写文本，模型目前解析能力比较有限，可以尝试切换布局检测模型为Structure&#x2F;layout_zh. pt吗，这个对于拍照文档检测效果稍微好一点。<br>另外，将图片处理为完全黑白的格式可以缓解背景颜色的干扰。<br>ref:https :&#x2F;&#x2F;github. com&#x2F;Yuliang-Liu&#x2F;MonkeyOCR&#x2F;issues&#x2F;109<br>2、文档解析中的公式重复输出问题<br>这个在我们训练时也出现过，就是测试多行推导公式时，会滥用\qquad，甚至会填充上千个\qquad，这也是语法的问题，训练数据的问题，大家在构造数据的时候可以关注。<br>ref:https :&#x2F;&#x2F;github. com&#x2F;Yuliang-Liu&#x2F;MonkeyOCR&#x2F;issues&#x2F;32<br>3、文档解析中的大写识别问题<br>中文数字大写识别效果很差，ref:https :&#x2F;&#x2F;github. com&#x2F;Yuliang-Liu&#x2F;MonkeyOCR&#x2F;issues&#x2F;129，<br>繁体字应该属于多语言的范畴，MonkeyOCR目前没有使用繁体字数据进行训练，所以繁体字识别可能不好，之后会计划支持繁体字和多语言。<br>4、文档解析中的阅读顺序评测问题</p><p>是编辑距离只能衡量字符插入、删除和替换，因此不能在文字层面上测量，因为版面顺序的结果本质是检测打乱了的文字顺序。OmniDocBench的阅读顺序是按照文本块级别的顺序index进行编辑距离的计算的，可以反应整体的阅读顺序性能。<br>5、文档解析中的layout缓解误差传播问题</p><p>问题是：本质上还是一个pipeline的方法，只是中间识别各种element的时候都使用了同一个大模型而已。因此前面的layout出现了问题，还是会影响后面。所以本方法除了更换了中间识别的模型，和其他pipeline的区别在哪里呢？<br>从回答上看，不用文本行检测和行内公式检测，减少了检测模型的使用，自然就减少了一部分误差；<br>以往的主流pipeline方法在做文本块识别的时候会调用公式检测、公式识别、文字检测以及文字识别等多个模型，例如行内公式的识别首先会检测出行内公式，再将检测得到的内容扣出来，送入公式识别模型进行识别，例如一个非常典型的错误例子——这些方法在公式检测时可能会将上一行单词的一部分截取下来，导致公式上下标识别错误。<br>但是，这个问题确实可以缓解公式的检测问题。但是对于text和table的效果提升文章内似乎并没有提到是如何做到的，这部分的检测和传统的pipeline似乎并无不同，当前的瓶颈主要集中在版面（layout）检测部分。<br>版面检测的不准确会对表格识别效果造成一定影响，因此目前只能在一定程度上缓解这一问题。<br>6、文档解析中的合并页面的问题<br>这个其实在ocrflux中重点讲过，这个在dolphin的issues也有提及，ref:https :&#x2F;&#x2F;github. com&#x2F;bytedance&#x2F;Dolphin&#x2F;issues&#x2F;46<br>其中提到一个点，可以关注，“近期也在做文档电子化这块的工作，目前比较通用且效果不错的的方案是，先做分类看是简历、分栏论文、法律文书等，再针对性做layout识别，对每个layout区域做识别（这个部分就可以用传统rapidOCR、视觉大模型、有线无线表格识别等工具了），识别完之后再做融合。“”<br>这里面做文档的分类，这个路由其实并不太现实，并且需要维护多个layout模型，分类的特征并不明显。<br>7、文档解析中的幻觉问题</p><p>官方回复是：简历场景Dolphin支持的并不好，目前支持的最好的是论文场景，后续会进行简历场景的优化。<br>8、表格解析中的内部数学公式的识别问题<br>在使用Dolphin模型处理PDF中的表格时，发现模型对表格内部的数学公式（特别是分数和上标）识别效果不佳，在表格解析模式下，模型似乎倾向于将公式的格式信息（如分数线、上标位置）丢失，并输出为纯文本，导致后续无法正确渲染。<br>ref:https :&#x2F;&#x2F;github. com&#x2F;bytedance&#x2F;Dolphin&#x2F;issues&#x2F;63<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聚焦RAG＆KG＆LLM＆文档解析：老刘说NLP技术社区对外纳新</title>
      <link href="/2025/07/01/1000001250-2648421473-1-1751342396/"/>
      <url>/2025/07/01/1000001250-2648421473-1-1751342396/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/6Pu6PbD5ipPTMQrWZXKpOg">聚焦RAG＆KG＆LLM＆文档解析：老刘说NLP技术社区对外纳新</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>老刘说NLP技术社区，自建立以来，旨在以公正、客观的角度，围绕大模型&amp;RAG&amp;文档智能&amp;知识图谱四个方向，展开每日早报、社区讨论、月度不定时分享、月度备份、专题整理等多种形式，以期达到一个较好的技术分享。<br>一起共创，共同地提升老刘说NLP的价值感和技术深度感，将是一件十分有意义的事儿，我们正在朝这个方向发展，逐步完善，逐步体系化。老刘说NLP技术社区持续对外纳新，欢迎大家加入。<br>一、社区介绍及内容建设<br>围绕大模型&amp;RAG&amp;文档智能&amp;知识图谱四个主题，展开每日早报、社区讨论、月度不定时分享等多种形式，以期达到一个较好的技术分享。<br>1、每日大模型&amp;文档智能&amp;知识图谱&amp;RAG技术前沿、论文、项目、落地、代码拆解技术答疑等话题讨论<br>2、每日大模型早报推送总结，160+日记录<br>我们已经陆续地举行了43次线上技术社区交流活动，包括知识图谱的构建与情报分析应用、KBQA、行业微调大模型等多个方面，老刘说NLP线上报告集锦，目前全集包括43+，分为《知识图谱与NLP专题》、《大模型训练、微调及评估专题》、《RAG、文档智能与知识图谱融合主题》等几大专题，例如：<br>老刘说NLP技术社区第43讲《文档智能+知识图谱如何增强大模型推理(数据合成+推理引导)》<br>老刘说NLP技术社区第42讲《落地场景下的RAG花式变体、技术特点及建议》<br>老刘说NLP技术社区第41讲《大模型最基本代码实操-大模型部署\微调\文档解析\RAG\Agent》<br>老刘说NLP技术社区第40讲《Ktranformers大模型低成本推理框架技术实现及部署》<br>……<br>知识图谱与NLP主题系列，包括学习路径指引、领域知识图谱与事件图谱应用探索、开源项目实操等多次报告<br>大模型训练、微调及评估专题，主要涉及大模型基本认知、领域微调模型实现范式、大模型、知识图谱与文档智能的落地技术结合范式等多个主题：<br>RAG、文档智能与知识图谱融合主题，主要涉及大模型RAG、KG-RAG、Agent部署、文档智能、模型部署、langchain-rag教程等多个线上分享。<br>4、老刘说NLP课堂11个专题课程<br>做成一个个小的课堂，进一步细分成一个个的小知识点，然后可以进行自定义的观看(比如网盘播放)，也可以更精准的找到相关的点，涵盖RAG课堂、知识图谱、大模型课堂、Deepseek、Agent等，总共11个课。<br>例如：<br>5、老刘说NLP的27个系列专题文章<br>对社区公众号共【1265篇】文章进行进行了主题归类，共【27】个专题：Agent智能体、AI搜索、Embedding嵌入、KG+RAG、NLP、prompt工程、RAG、大模型+文档智能、大模型幻觉、大模型可解释、大模型评估、大模型数据工程、大模型微调、大模型训练、大模型应用、多模态RAG、多模态大模型、领域大模型、面试、事件图谱、事理图谱、推理大模型、文档智能、语言资源、语音大模型、知识图谱、知识图谱+RAG、知识图谱+大模型。可以涵盖住目前的主流研究方向，是个很好的索引。<br>以及通过可视化图解形式总结：<br>以及在技术层面的专题工作：<br>1、老刘说NLP技术社区目前采用会员制，免责条款及规则如下：<br>1）入群者深知入群的条件、会员权益以及可能存在的风险，一旦进入技术交流群的，概不退款，退群后权益自动失效，再入后需要重新申请<br>2）会员权益中的不定期，视老刘的具体时间而定，最终解释权供老刘所有；<br>3）为保护社区成员权益，禁止将网盘文件外传，一旦发现，踢出群并追究相应责任；<br>2、老刘说NLP技术社区成员权益如下：<br>1）享有不定期精选的知识图谱、大模型、RAG等方向前沿技术文章、项目在群里推送；<br>2）开展技术讨论等，相应讨论答疑服务；<br>3）享有每日早报推送及技术专题材料服务；<br>4）享有不定期的知识图谱&#x2F;大模型&#x2F;RAG等相关技术解读&#x2F;线上分享；<br>5）享有老刘课堂全集服务；<br>6）享有随时退群的权利；<br>3、加入社区方式<br>首先，扫描购买社区会员二维码（左边第一个码，365&#x2F;年，1元&#x2F;天），完成付款，并截图保存，社区资格一年有效，一年一续。<br>其次、扫描添加微信，备注“加入会员群”，并将截图发微信，可拉取进入社区，获得社区资格。<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入会员方式：关注公众号，在后台菜单栏中点击会员社区-&gt;会员入群加入</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Dify落地知识库场景的小思考及多模态RAG结合图像信息的几种策略评估</title>
      <link href="/2025/07/01/1000001250-2648421473-2-1751342396/"/>
      <url>/2025/07/01/1000001250-2648421473-2-1751342396/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/SlZhiw6_QbPqpoIQNDN0aQ">Dify落地知识库场景的小思考及多模态RAG结合图像信息的几种策略评估</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年7月1日，星期二，北京，晴<br>今天是2025年下半年的第一天，新的起点，我们继续看技术。<br>从评估角度看多模态RAG中的文档信息增强，逐步整合跨模态输入（文本、图像、字幕、OCR）后对应的相应影响，虽然说，这种范式看起来像是去年的，但温故而知新。<br>另外，来看看一个问题，关于dify是否应该被抛弃的一些思考？还是要分具体使用场景去看。</p><p>看两个点，一个是实验环境，一个是实验结果。<br>1、实验环境<br>这个visrag的核心就是充分利用好文档内部的各个元素，把图像进行文本化，如下图所示：<br>提出的方法（顶部，绿色背景）通过从PDF文档中提取并处理文本和视觉内容，增强了信息检索能力。<br>不同于传统的纯文本方法（底部，米色背景），系统同时提取文本和图像（如图片示例、表格以图像形式存在的人力资源文档等），通过自动生成标题和OCR文本提取对其进行丰富，并将所有模态整合为可检索的综合单元存储于S3&#x2F;KB中。<br>在响应用户查询时，传统方法仅依赖PyPDF技术进行文本提取，无法捕捉关键的视觉信息，导致下游应用获取的上下文不完整。<br>多模态方法通过检索相关文本上下文及视觉元素，提供了更为完整的信息，使得下游应用能生成更有效支持用户动作的响应。<br>2、评估结论<br>采用四种逐步增强的方法进行评估：仅文本、文本+图像、文本+图像+标题、文本+图像+标题+OCR。<br>其中，三种标题生成方法：BLIP、Transformer-GPT2、Claude3. 5Sonnet模型&#x2F;Haiku3. 5或NovaProLLM模型的基于大语言模型的标题生成。<br>每种方法的评估结果通过精确短语匹配、词重叠、CLIP嵌入比较和语义相似性等方法进行综合评分。<br>看下效果：<br>其中：<br>文本+图像:相较于仅文本方法，文本+图像方法的平均得分提高了5. 2%，达到0. 2511；<br>文本+图像+标题:使用Claude3. 5Sonnet生成标题的方法得分最高，达到0. 3572，相较于仅文本方法提高了42. 3%；<br>文本+图像+标题+OCR:最优模态权重（30%文本，15%图像，25%字幕，30%OCR），得分最高，达到0. 3754，相较于仅文本方法提高了**57. 3%**。<br>使用dify这类平台搭建RAG等应用除了很容易达到上限外，还有什么缺点？如果真的要商用，打造可用的产品，是否应该自己去搭建？抛弃掉dify?dify适合做什么，不适合做什么？<br>实际上，如果要回答这些问题，则需要对Dify的特点和定位摸清楚。<br>先说下结论：<br>Dify是“AI应用快速试验田”，而非生产级精密工具。优势在效率，劣势在深度。短期需求：用Dify验证后，逐步替换瓶颈模块。在PoC阶段用Dify测试，再根据性能瓶颈决定模块替换或迁移，避免“全盘推翻”或“将就妥协”。<br>这里面的支撑逻辑是什么？<br>由于是个工具标品，所以很多都是内置封装最小化配置，从文本切分、排序到大模型，大多的策略都并不能解决高精度场景。<br>例如，Dify的RAG文档处理效果一般，特别是PDF表格识别问题严重，导致召回失败。而且切割策略并不先进，只能使用固定的正则表达式切割，对于普通用户来说操作困难，多路召回的效果也不理想，关键词召回实际上效果很差，基本依赖向量检索，所以，这个就是很容易达到上限。<br>而对于是否应该自己自研搭建，建议根据需求复杂度决定。<br>简单场景用Dify快速验证，复杂或高性能需求则需自研。提到结合部署方案，比如用Dify做前端+RAGFlow或者mineru处理文档。<br>当然，对于用户而言，还是要因地制宜，例如，技术能力弱、需求简单用Dify，复杂逻辑、长期投入则选自研。<br>一般来说，需要权衡开发效率与定制需求，Dify适合原型和简单应用，但商用产品若涉及高性能或复杂处理，可能需要自研或者魔改其他。<br>我们落地时，往往看的是这个东西的下限，并且要做到商用，其实很复杂，需要做许多优化策略，但是，具体选择什么，全凭自己在做的事情，没有绝对。<br>1、https :&#x2F;&#x2F;arxiv. org&#x2F;pdf&#x2F;2506. 21604<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GraphRAG的索引动态更新解法-分桶+局部更新及“上下文工程”新概念？</title>
      <link href="/2025/06/30/1000001249-2648421462-1-1751245240/"/>
      <url>/2025/06/30/1000001249-2648421462-1-1751245240/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/YjotrXspCQr2G7C2Y7soog">GraphRAG的索引动态更新解法-分桶+局部更新及“上下文工程”新概念？</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月30日，星期一，北京，晴，今天是2025年上半年的最后一天了。<br>我们继续看GraphRAG的问题，基于图的检索增强生成（Graph-RAG）在处理动态增长语料库时的效率问题。<br>现在的一些方案，主要集中在静态语料库的检索增强生成，如VanillaRAG、Graph-basedRAG等。动态检索方法如DRAGIN、LightRAG和DyPRAG等虽然尝试解决动态语料库的问题，但在高频数据变化下的动态更新消耗仍然较高。<br>这个问题的难点在于如何在不需要全图重建的情况下，高效地更新语料库，并保持高检索准确性和低延迟。<br>所以，问题来了，既然需要动不动就重新构图，那么是否可以去个重，分个桶，然后把新更新的，归类到某个桶中，然后再根据这个桶所属的层级中，做局部更新？<br>这也就一种动全部，不如拉相似度分桶动局部的思路，那就会用到聚类，去重这些，所以，我们来看看一个具体的实现思路，很简单。<br>另外，最近也在继续造新词，还是需要新故事维持热度，继续换概念，值得就是这个上下文工程（contextengineering），来看看是个啥？</p><p>其实现思路很简单，利用基于超平面的局部敏感哈希（LSH）将原始语料库分区和组织成层次化的图结构，通过将相似项映射到相同的桶中，实现高效的分组。通过递归的LSH分割和总结，构建了一个多层次的图结构，当新语料条目到达时，EraRAG通过将新块编码为向量嵌入，并将其插入到适当的桶中，进行向上传播的调整，这些调整仅限于受影响的部分，而不会改变图的其他部分。<br>进一步的拆分开来，核心步骤就几个：<br>1、LSH-based图构建<br>LSH局部敏感哈希，是常见的相似度方案，利用哈希将相似项映射到同一桶中。<br>1）LSH分段<br>在这个方案中，给定输入语料库后，首先将其处理为文本块，然后将它们编码为向量嵌入。然后，将这些向量投影到n个随机采样的超平面上，并编码为一个n位二进制哈希码。具有相似哈希值的向量被分组到同一个桶中。<br>2）分段调整<br>每个分段的大小受到用户定义的上下限控制。较小的桶会与相邻的桶合并，而较大的桶会被分割。对于每个生成的分段，使用LLM将其包含的文本块总结为一个新的块。<br>3）构建层次图<br>递归调用哈希、分段和总结这个过程，采用RAPTOR方案，构建多层次的图结构。<br>4）局部更新<br>当新语料库条目到达时，新块被编码成向量嵌入，插入到相应的桶中，并进行向上的传播调整，仅限于受影响的部分，而不改变无关部分。<br>所以说，这个想法很自然，动全部，不如拉相似度分桶动局部，结果也很直接，例如，在HotpotQA数据集上，EraRAG相比RAPTOR减少了高达77. 5%的图重建时间。<br>但是，这种方法也存在一些问题，这个很依赖于分桶的质量，以及初始形成的图结构。适当的分段大小有助于平衡效率和检索质量，过大或过小的分段都会影响性能。</p><p>从这张图上，可以很直接的看到“上下文工程”是个啥，就是把RAG、提示词工程、记忆、历史记录这些包成了一个整体的新词。<br>用这个blog的话来说，上下文工程就是构建动态系统，以提供正确格式的信息和工具，使大型语言模型（LLM）能够合理地完成任务。<br>大多数情况下，当代理（agent）不可靠地执行任务时，根本原因是没有将适当的上下文、指令和工具传达给模型（这是个废话，因为现在大模型做应用，prompt是媒介。）<br>MCP\ACP这些也不火了，Agent继续炒，就要新的名词，新的概念，这样，才有新的故事，但这并不好，并没有新的东西产生，反而加重了认知负担。<br>1、https :&#x2F;&#x2F;github. com&#x2F;EverM0re&#x2F;EraRAG-Official<br>2、https :&#x2F;&#x2F;blog. langchain.com&#x2F;the-rise-of-context-engineering&#x2F;<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>落地方案：Cursor的代码库索引及文档解析中的跨页表/段落合并实现思路</title>
      <link href="/2025/06/29/1000001248-2648421447-1-1751170031/"/>
      <url>/2025/06/29/1000001248-2648421447-1-1751170031/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/QAV5dTNBbBqeUfMP6qAN5A">落地方案：Cursor的代码库索引及文档解析中的跨页表&#x2F;段落合并实现思路</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月29日，星期日，北京，晴<br>我们继续来看文档解析进展，2025年上半年已经出了很多个文档解析模型方案了，这个在专题中有介绍过许多。<br>那么，还可以继续做什么差异性？<br>那就是往后面做，考虑跨页表&#x2F;段落合并问题差异性，也就是做下合并场景，这个在文档恢复场景中先的更为重要，当前的开源方案比较简单，都是逐页处理，并将各个页面的结果连接起来，而不考虑其逻辑连续性，或者写一些规则。<br>例如这个图里面的多列合并问题、跨页表格等。<br>所以可以往后走一下，做成模型，分成检测和合并两个子任务，看下具体怎么做。<br>另一个是，还是看代码RAG，看看Cursor的代码库索引思路，其中提到的Merkle树。<br>文档解析方向目前逐步走向差异化，在完成每个部件之间的拆解(检测)和解析之后，还需要进行拼接操作。<br>所以，也可以看看这方面的新工作，看看文档文档智能进展，PDF转markdown新轮子，ocrflux，为什么要说这个，这个有点差异性，模型支持跨页表合并和跨页段落合并<br>1、ocrflux方案介绍<br>ocrflux，3B参数，基于的QWEN2. 5-VL-3B-Instruct微调，目前这类工作很多，所以还是要看差异性，根据官方描述，模型亮点是原生支持多页文档解析，自动检测和合并跨页面元素以生成连贯文档结构，可以从跨页面的拆分对应物中重建完整的表格。<br>也就是在这个prompt的结果后面，再进行段落合并和表格合并。<br>在训练数据上，训练数据包括110万页金融和学术文件，以及25w的OLMOCR-MIX-0225数据，在效果上，与7B基线模型相比，在GTX3090GPU中可实现约3倍的吞吐量。在训练架构上，仅使用页面图像作为输入。<br>看下详细的介绍地址，相关信息如下：<br>技术博客在https :&#x2F;&#x2F;ocrflux. pdfparser.io&#x2F;#&#x2F;blog；<br>项目主页在https :&#x2F;&#x2F;github. com&#x2F;chatdoc-com&#x2F;OCRFlux；<br>模型权重在https :&#x2F;&#x2F;huggingface. co&#x2F;ChatDOC&#x2F;OCRFlux-3B；<br>2、跨页段落及表格的合并问题？<br>为什么要做这个，因为PDF文档通常带有分页，这常常导致表格或段落被拆分到连续的页面中，准确检测并合并此类跨页面结构对于避免生成不完整或碎片化的内容至关重要。<br>那么，具体怎么做？那就做成一个模型如何？最直接的方式，就是训练一个模型，以两个拆分的表格碎片作为输入，并生成一个完整的、结构良好的表格作为输出。<br>可以建模为两个任务，一个是检测任务，一个是合并任务。<br>其中：<br>对于检测任务，给定两个连续页面的Markdown（每个页面都构建为Markdown元素列表（例如，段落和表格）），目标是识别应跨页面合并的元素的索引。<br>例如，其实现很简单，就是通过prompt控制：<br>对于合并任务，如果要合并的元素是段落，可以直接将它们连接起来。但是，对于两个表格碎片，它们的合并更具挑战性，例如，跨越多页的表格会在第二页重复第一页的页眉。<br>另一个困难的情况是表格单元格包含较长的内容，这些内容在单元格内跨越多行，前几行出现在上一页，而其余行则延续到下一页，有一些包含大量列的表格被垂直拆分并放置在连续两个页面上的情况。<br>同样的，这个模型处理也很简单，直接通过prompt进行提示控制（段落直接写规则就好，如上面说的）：<br>看下训练细节：在训练中使用了大约450,000个样本用于检测任务，以及100,000个样本用于合并任务，针对这两个任务，分别训练单页面解析和跨页面合并任务，而是在同一个多模态LLM中使用不同的提示进行联合训练。<br>3、在跨页段落及表格的合并问题上可用的两个评估基准<br>这个项目提供了两个评测基准。</p><p>4、在实际落地中需要考虑的点<br>但是，一般来讲，直接写规则拼接即可，再加一个模型做其实会很慢，所以，最合适的方式，其实是加一个开关进行控制，例如，这个项目中，设置–skip_cross_page_merge跳过解析过程中的跨页面合并来加速，会简单地将各个页面的解析结果拼接起来生成最终的Markdown文档。<br>此外，在部署侧，最新的NVIDIAGPU（在RTX3090、4090、L40S、A100、H100上测试），至少具有12GB的GPURAM，20GB可用磁盘空间。<br>最后，具体结果如何，其实还得看具体测试，很多评估结果都是相对的，并且可信度、一般性都会严格可信，可用，可借鉴，对于我们而言，最重要的是知道其实现的技术思路和想解决的问题。</p><p>那么具体怎么做的？<br>1、Merkle树<br>Merkle树是一种树形结构，其中每个“叶”节点都标记有数据块的加密哈希值，每个非叶节点都标记有其子节点标签的加密哈希值，这种结构创建了一个分层结构。<br>每一块数据（比如一个文件）都有其独特的指纹（哈希值）；成对的指纹被组合并赋予一个新的指纹；这个过程一直持续，直到你只剩下一个主指纹（根哈希值）。<br>2、具体怎么做的树构建？<br>Cursor首先在本地将代码库文件分割成语义上有意义的块，启用代码库索引时，Cursor会扫描编辑器中打开的文件夹，并计算所有有效文件的哈希值的Merkle树。</p><p>但是，还是老问题，代码库索引的有效性在很大程度上取决于代码是如何被分割的。<br>简单的方法会按字符、单词或行来分割代码，但它们往往会错过语义边界，从而导致嵌入质量下降。<br>一个更有效的方法是使用一个理解代码结构的智能分割器，例如使用高级分隔符（如类和函数定义）在适当的语义边界处分割代码。<br>这个就是我们在前面文章中所述的，<br>《代码类型的RAG做chunk切分怎么做？兼看改进AST方案》(https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;N7C-1IRgJYZyyNYiFexC2Q)<br>基于代码的抽象语法树（AST）结构来分割代码。通过深度优先遍历AST，它将代码分割成适合标记限制的子树。为了避免创建过多的小块，只要不超过标记限制，就会将兄弟节点合并成更大的块。</p><p>此外，为了在仍然允许基于路径的过滤的同时保持隐私，Cursor会为每个向量存储一个混淆的相对文件路径。<br>1、https :&#x2F;&#x2F;read. engineerscodex.com&#x2F;p&#x2F;how-cursor-indexes-codebases-fast<br>2、https :&#x2F;&#x2F;ocrflux. pdfparser.io&#x2F;#&#x2F;blog<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>这本书可以说是最适合只需要浅尝辄止下机器学习深度学习数学知识的人！！</title>
      <link href="/2025/06/28/1000000137-2247492478-1-1751113901/"/>
      <url>/2025/06/28/1000000137-2247492478-1-1751113901/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/JB4vU1d1zNdyZ4SHJAcaVg">这本书可以说是最适合只需要浅尝辄止下机器学习深度学习数学知识的人！！</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>其实在机器学习深度学习方向，很多的同学更偏向于通过代码来使用机器学习深度学习的各种算法模型（特别是对于跨学科的学生），起码百分之780的人都不需要去深刻理解每一个模型底层的数学公式推导。<br>但不能说可以完全不懂一点机器学习深度学习相关的数学知识，毕竟你还是需要理解模型的基本工作原理和内部结构的。<br>这本《白话机器学习的数学》真的就非常非常适合只需要浅尝辄止下机器学习深度学习数学知识的人！<br>这本书是通过正在学习机器学习的程序员绫乃和她朋友美绪的对话，结合回归和分类的具体问题，逐步讲解了机器学习中实用的数学基础知识，纯正的日本动漫白话书！让你学机器学习深度学习数学知识就和读了一本故事书一样简单！<br>虽然说没有很深入的讲解，但对于只是需要简单入门下机器学习深度学习数学知识的人那可真的太合适了！完全没有任何压力！在豆瓣上收获了很多初学者的好评！<br>因网盘易和谐，如果你需要这本书的高清原版PDF➕配套代码可以直接扫码添加我的助理让她无偿及时发送给大家！<br>避免单个微信添加频繁，故备了两个微信，大家随意添加一个即可！<br>不同的是它不仅仅讲解数学知识，全程都是有具体的算法应用例子绑定的，让你知道怎么把数学公式通过Python代码来实现，再应用到具体的任务中，让你又懂理论也懂使用！这样的思路真的很棒！<br>下方为目录与具体内容展示：<br>非常推荐给大家！</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI算法工程师Future </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>好落地前沿精读：Hunyuan-A13B推理模型、qwen3多尺寸及Jina多模态向量模型</title>
      <link href="/2025/06/28/1000001247-2648421431-1-1751082755/"/>
      <url>/2025/06/28/1000001247-2648421431-1-1751082755/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/HYd2EkU01O3IgQn2ENaEkw">好落地前沿精读：Hunyuan-A13B推理模型、qwen3多尺寸及Jina多模态向量模型</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月28日，星期六，重庆，晴<br>我们来快速回顾下最近一周技术方面值得关注的利好落地的前沿进展。<br>一个是腾讯混元开源混合推理MoE模型，这个算是填补了70-90B之间的推理模型空白，看下模型特点和里面跟qwen很类似的思考模式thinkornothink。<br>另一个是与RAG场景落地关系比较密切的embedding进展，一个是多尺寸比较能打的qwen3-embedding系列，一个是多模态embdding的jina-v4版本，体现出现在embedding侧的一些变化，从单模态到多模态，从单一向量到多向量、从固定维度到自定义维度（MRL俄罗斯套娃）、开始转向使用大模型作为基座模型、开始使用合成数据等方式挖掘难样本、针对特定任务补充能力项<br>腾讯混元开源混合推理MoE模型HunyuanA13B，技术亮点为混合专家(MOE)模型，拥有800亿总参数和130亿激活参数，包含1个共享专家和64个非共享专家，训练时只有8个非共享专家被激活。<br>1、相关地址<br>先看地址：<br>体验入口地址在https :&#x2F;&#x2F;hunyuan. tencent.com&#x2F;；<br>API地址在https :&#x2F;&#x2F;cloud. tencent.com&#x2F;product&#x2F;tclm；<br>Github地址在https :&#x2F;&#x2F;github. com&#x2F;Tencent-Hunyuan；<br>HuggingFace地址在https :&#x2F;&#x2F;huggingface. co&#x2F;tencent。<br>2、模型特点<br>原生支持256K上下文窗口，优化Agent能力，采用分组查询注意力(GQA)策略，支持多量化格式；<br>支持快思考和慢思考两种模式，模型的默认输出是慢思考模式，若想让模型进行快思考，可在guery前附加上\“&#x2F;nothink\“，这个是采用与qwen类似的think&#x2F;no_think模式，这是成为标配。<br>这个在训练过程中，也是靠数据策略来控制如下，构建dual-cot数据进行训练：<br>快思考模式的训练示例在“”内容块中不包含详细的推理步骤；慢思考的训练示例在“”内容块中显式包含逐步推理。<br>3、模型训练<br>预训练分为三个阶段：基础训练阶段处理20万亿token，学习率采用三阶段调度；快速退火阶段在3000亿token上实现快速衰减；长上下文训练阶段将上下文窗口扩展到256K。<br>后训练阶段包括4步，通过监督微调（SFT）和强化学习（RL）进一步提升模型性能。SFT阶段使用高质量的指令-响应数据集，涵盖数学、代码、逻辑和科学推理等任务。RL阶段利用结果奖励模型和沙盒反馈，进一步增强模型的推理能力。<br>Embedding是RAG等应用场景的重要组件，当前的一些趋势就是，从单模态到多模态，从单一向量到多向量、从固定维度到自定义维度（MRL俄罗斯套娃）、开始转向使用大模型作为基座模型、开始使用合成数据等方式挖掘难样本、针对特定任务补充能力项<br>所以，可以看看一些大致的细节，两个工作。<br>1、Qwen3-embedding中的数据合成思路和多尺寸系列<br>既然说到embedding，这个就再温习下Qwen3-embedding，提供了多种模型大小（0. 6B、4B、8B），适用于嵌入与重排序任务，满足用户在不同部署场景下对效率或效果优化的需求。<br>所以，其核心点就是，基于Qwen3LLM做工作，先看地址：<br>GitHub在https :&#x2F;&#x2F;github. com&#x2F;QwenLM&#x2F;Qwen3-Embedding；<br>技术报告在https :&#x2F;&#x2F;github. com&#x2F;QwenLM&#x2F;Qwen3-Embedding&#x2F;blob&#x2F;main&#x2F;qwen3_embedding_technical_report. pdf；<br>Qwen3-Embedding模型地址在https :&#x2F;&#x2F;modelscope. cn&#x2F;collections&#x2F;Qwen3-Embedding-3edc3762d50f48；<br>Qwen3-Reranker模型地址在https :&#x2F;&#x2F;modelscope. cn&#x2F;collections&#x2F;Qwen3-Reranker-6316e71b146c4f<br>1）双塔及单塔训练架构<br>训练架构上，Embedding模型和Reranker模型分别采用了双塔结构和单塔结构的设计。<br>通过LoRA微调，最大限度地保留并继承了基础模型的文本理解能力。<br>其中：<br>Reranker模型接收文本对（例如用户查询与候选文档）作为输入，利用单塔结构计算并输出两个文本的相关性得分，根据给定输入计算相关性得分，也就是评估下一个token为“是”或“否”的似然。<br>Embedding模型接收单段文本作为输入，在输入序列末尾附加一个[ EOS]token，饭后取模型最后一层「EOS」标记对应的隐藏状态向量，作为输入文本的语义表示。<br>其中，MRL支持”表示嵌入模型是否支持自定义最终嵌入的维度，这个用的很多，已经成为标配。<br>也可以进行Embedding模型的进一步微调，以适应特定领域的embedding数据需求；<br>2）三阶段训练路线<br>训练方式上，采用“合成数据驱动的弱监督+高质量数据的有监督微调+模型合并”的三阶段训练Pipeline。<br>1）阶段1-大规模弱监督预训练（WeaklySupervisedPre-Training），基于Qwen3-32B，构建了四种类型的合成数据——检索、双语挖掘、语义文本相似度和分类，以使模型在预训练期间能够适应各种相似度任务。</p><p>再在“QueryGeneration”阶段根据上述配置生成用户角度的查询句，最终合成约1. 5亿对多任务弱监督训练数据，然后采用改进的InfoNCE对比损失；<br>2）阶段2-高质量数据有监督微调（SupervisedFine-Tuning），沿用InfoNCE损失对嵌入模型进行微调，重排序模型直接采用SFT（二分类交叉熵）损失；<br>3）阶段3-模型合并（ModelMerging），在有监督微调阶段保存的多个检查点（checkpoints）之间，通过球面线性插值（slerp）技术，将不同阶段或不同任务偏好模型进行“合并”。<br>2、Jina-embeddings-v4多模态向量模型<br>Jina-embeddings-v4，参数规模38亿，为多模态Embedding模型，对于RAG应用，该模型还新增了处理视觉丰富图像（也称为视觉文档）的功能，即包含文本和图像混合的材料，如表格、图表、图示及其他常见混合媒体。<br>先看地址在https :&#x2F;&#x2F;huggingface. co&#x2F;jinaai&#x2F;jina-embeddings-v4；<br>API地址在https :&#x2F;&#x2F;jina. ai&#x2F;embeddings&#x2F;；<br>技术报告地址在https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2506. 18902。<br>1）看训练架构<br>将其底座模型更换为Qwen2. 5-VL-3B-InstructQwen2. 5-VL模型作为主干。与Qwen2. 5-VL类似，支持文本和图像两种输入模态，并以相同的方式处理输入。<br>两个改动点。<br>1）多任务LoRA扩展<br>添加LoRA扩展以提升特定任务的性能，包括三个针对特定任务的LoRA适配器（每个含6000万参数），整体参数的2%额外新增。<br>分别是非对称查询-文档检索、语义相似度与对称检索、代码（即计算机编程语言）检索，用户可以在推理时从中选择。<br>2）单向量和多向量输出<br>与Qwen2. 5-VL及其他一般嵌入模型不同，用户可在两种输出选项间进行选择，即传统的单一（稠密）向量嵌入，以及适用于延迟交互策略的ColBERT风格多向量嵌入。<br>单向量嵌入的维度为2048，但可以截断至128，且几乎不会损失准确率，这个主要得益于通过Matryoshka表示学习进行训练，因此单向量嵌入的标量值大致按语义重要性排序，去除最不重要的维度对准确率的影响微乎其微。<br>多向量嵌入是通过Transformer模型处理token后未池化的结果，对应于模型在分析token时根据其上下文所得到的token。输出向量的长度与输入token（包括“图像token”）的数量成正比，每个token对应一个128维的输出向量。<br>该输出可直接与ColBERT和ColPali生成的未池化嵌入进行比较，并适用于延迟交互比比较【这个就是主流的了，多模态RAG常用】。<br>1、https :&#x2F;&#x2F;github. com&#x2F;QwenLM&#x2F;Qwen3-Embedding&#x2F;blob&#x2F;main&#x2F;qwen3_embedding_technical_report. pdf<br>2、https :&#x2F;&#x2F;github. com&#x2F;Tencent-Hunyuan<br>3、https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2506. 18902<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>落地角度看Agent搭建的稳妥到激进路线及VLLM图片分辨率策略</title>
      <link href="/2025/06/27/1000001246-2648421412-1-1751012061/"/>
      <url>/2025/06/27/1000001246-2648421412-1-1751012061/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/30eTvYCRFX2CgPsvDXXpfw">落地角度看Agent搭建的稳妥到激进路线及VLLM图片分辨率策略</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月27日，星期五，重庆，晴<br>我们来看两个问题。<br>一个是Agent，看看推理大模型规划能力搭建Agent应用的一些变化，那些是稳妥、次稳妥、激进的思路。<br>一个是技术侧看文档智能，主要看多模态大模型的分辨率处理策略，看目前有哪些主流应对方案。<br>Agent的东西已经讲了很多了，Agent已经成为互联网的新流量入口。我们站在现在众多智能体产品，如manus，百度心响、天工超级智能体等节点上，再来看看这个问题。<br>1、Agent的构成跟核心？<br>LLM是Agent的大脑，其核心能力是“逻辑推理”，其中包括多个部件<br>PlanningSkills：对问题进行拆解得到解决路径，既进行任务规划；ToolUse：评估自⼰所需的工具，进行工具选择，并生成调用工具请求；<br>Memory：短期记忆包括工具返回值，已完成推理路径；<br>长期记忆包括可访问的外部长期存储等。<br>2、Agent研发的实际窘境？<br>Deepseek等大模型的能力持续快速提升，带动AI智能体的能力提升。<br>但是，现在依旧存在多个问题，例如：<br>大模型的能力没那么强，其不确定性直接导致；Agent的规划能力依赖于prompt工程能力，它比想象中更重要、执行起来也更琐碎；不要让Agent一次性做复杂的推理性规划工作，而是把复杂任务人工拆解后再教给Agent；<br>Agent的Action能力强烈依赖于基座模型的functioncalling能力。在规划Agent之前，对模型的functioncalling能力要充分调研；<br>3、Agent开发的最稳妥路线-低代码平台Agent？<br>既然大模型能力不行，那么就直接把大模型当啥子好了，不让它做规划，只让他做一个单点的执行，但这种做法做出来的，与Agent的初衷背道而驰。<br>最稳妥的Agent开发范式，就是人工定义好实现流程，低代码平台开发，例如，Dify应用开发平台，多模型支持、可视化工作流设计、检索增强生成（RAG）、API接口与SDK、数据与监控等核心功能，适用于企业知识管理、智能客服与问答系统、代码助手、自动化办公等场景。<br>4、Agent开发的次稳妥路线-交互型平台Agent？<br>最稳妥的Agent开发范式，就是人工定义好实现流程，低代码平台开发。但这个太慢，是否可以做个折中？<br>其实是可以的，这个也是一个趋势，<br>实现方式：每一步出llm结果，人工编辑确认执行。对于用户不清楚的问题，llm以多轮追问的方式进行引导-&gt;用户确认，迭代至意图信息完整，然后再最终生成结果，例如如下天工智能体的人工接入补充信息的中间过程：<br>5、Agent开发的激进路线-纯自动平台Agent？<br>激进路线，就是全放开让大模型去做Agent，但这块容易受到通用性的挑战，也需要做大量的prompt工程或者流程设计，例如manus等为代表。<br>这个不是很可控，并且很容易陷入死循环，或者耗费大量token。<br>现在视觉多模态模型，尤其是在处理文档图像时，图像的分辨率的处理逻辑直接影响模型效果，这连同数据成为两个重要工程性工作。<br>很自然的想法，就是分辨率越高越好，但是其中的Transformer的注意力机制导致Token数量增加时计算量激增（如Qwen2-VL处理4K图像需16KToken），分块策略易丢失全局结构，无损缩放则计算成本高。<br>所以，目前也有一些新趋势。比如，渐进式分辨率思路，InternVL2从低分辨率开始训练，逐步过渡到高分辨率，或者采用多阶段微调方案，如LLaVA-UHD冻结视觉编码器，仅微调重采样器和LLM，缩短训练周期。<br>所以，当我们看现有的主流模型时候，可以挖掘出其中的一些典型处理措施。<br>具体的：<br>1）InternVL2采用动态切块策略，将图像分割为多个448x448像素块，同时配合PixelShuffle技术降低计算量。<br>2）Qwen-VL通过NaiveDynamicResolution机制，移除绝对位置嵌入改用2D-RoPE，实现任意分辨率处理。<br>3）LLaVA-UHD采用图像模块化策略，将高分辨率图像分割为可变大小的切片，并通过视觉Token压缩技术减少计算负担。这种方法能保持任意宽高比，避免信息丢失。<br>4）LLaVA-Next采用双分支处理（切图和缩放），同时保留全局语义和局部细节，实现动态高分辨率。<br>5）MiniCPM-V系列采用\“全局缩略图+局部网格切片\“方案，通过复杂的分块算法处理高分辨率图像；<br>6）Qwen2-VL则通过自适应缩放和维度重排直接处理原始图像，避免切割导致的信息断裂。<br>那么，是否可以再总结下，形成一些可用的策略？大致就是如下几种：<br>1）动态分块与切片（PatchPartition）策略<br>其思想在于将高分辨率图像分割为多个子图，分别编码后融合特征，避免整图缩放导致的细节丢失。<br>在具体实现上，主要包括自适应网格划分、全局缩略图补偿以及Token压缩几个实现步骤，例如：<br>自适应网格划分方面，根据图像宽高比动态计算最优分块数量（如m×n网格），确保子图宽高比接近预训练标准（如14的倍数）。<br>全局缩略图补偿方面，在分块基础上添加低分辨率全局图（如MiniCPM-V系列），保留整体结构信息，解决分块导致的语义割裂问题。<br>Token压缩方面，使用重采样器（如LLaVA-UHD的Q-Former）压缩子图Token，将可变长度视觉特征统一为固定长度，降低计算开销，这个主要冲着降低计算量去的。<br>2、无损自适应缩放（Resolution-awareScaling）策略<br>无损自适应缩放的核心思想在于，直接处理原始分辨率图像，通过维度重排和缩放减少像素损失。<br>在具体实现上，主要包括如下几点：<br>一个是分辨率微调，例如Qwen2-VL将图像调整至28的倍数分辨率（如1365×2048→1372×2044），确保与视觉编码器的Patch机制兼容。<br>一个是动态Token生成，移除ViT的绝对位置嵌入，引入2D旋转位置编码（2D-RoPE），支持任意分辨率生成可变数量视觉Token（低至4个）。<br>3、局部-全局特征融合（HybridResolutionEncoding）策略<br>局部-全局特征融合策略也是一种常用方式，其核心思想为，并行处理低分辨率全局特征和高分辨率局部特征，选择性融合关键信息。<br>而既然要用到全局信息和局部信息，因此，可以采用双分支编码器，如Mini-Gemini，一路编码低分辨率全局语义，另一路提取高分辨率局部特征，通过交叉注意力检索关键细节。<br>也可以采用多尺度特征池化，如S2-Wrapper，将不同尺度子图特征池化至统一空间尺寸并拼接，增强细节感知。<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>技术前沿之Graph+Agent：Chat2Graph如何重构GraphRAG范式？</title>
      <link href="/2025/06/26/2648421397-2648421397-1-1750939443/"/>
      <url>/2025/06/26/2648421397-2648421397-1-1750939443/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/TKev6oPft5I1VOlXqHwONQ">技术前沿之Graph+Agent：Chat2Graph如何重构GraphRAG范式？</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>▍作者：范志东，蚂蚁图计算开源负责人、图计算布道师<br>引言<br>去年年底，我在《2024年度Graph+AI开源探索思考》一文中，细致拆解并总结了TuGraph在「Graph+AI」领域的开源技术实践经验。文中引用了一段业内不成文的观点：「23年卷SFT，24年卷RAG，25年卷智能体」，并将「GraphNative」的理念引入到智能体的设计中。<br>借助符号主义的可解释性优势，全面增强智能体推理能力。同时增强的智能体架构，可以更好地帮助用户降低用图门槛，实现更智能的用图体验，实现Graph与AI的双向增益。这正是「图原生智能体」的基本设计原则。</p><p>项目文档：https :&#x2F;&#x2F;chat2graph. vercel.app&#x2F;<br>在Chat2Graph中，通过多个图领域专家的动态协作，而非固定链路，便可以完成GraphRAG链路中知识图谱的抽取、存储、检索的过程。Chat2Graph在提升GraphRAG链路灵活性的同时，也将解决的问题域从传统的Q&amp;A扩展到智能交互，相当于用智能体的方式对GraphRAG范式进行了重构。那么，其重构的内在逻辑是什么，这仍需要从「人工智能的三大流派」说起。<br>在人工智能研究领域，「符号主义」、「连接主义」、「行为主义」各有所长。「符号主义」工于数理逻辑，基于显式的人工规则，获得高度可解释性的推理效果。「连接主义」长于自主学习，通过大规模神经网络并行计算，以模型权重的形式固化隐式的知识。「行为主义」强调环境反馈，旨在以感知进化的方式让行为智能化。<br>然而，基于人工规则的「符号主义」的智能水平受限于规则的规模，而以概率统计为基础的「连接主义」在推理时的幻觉总是不可避免，同时「行为主义」从环境中学习的能力很难有效地迁移泛化。单项能力的不足反而为优势互补提供了空间，比如大模型与强化学习结合的推理模型（LRM）、环境反馈赋能的大模型智能体（Agent）等。<br>我们都知道GraphRAG其实是对RAG链路中「知识库」的改进技术，它以知识图谱而非向量的形式组织模型外的知识信息结构，属于典型的知识图谱与大模型的技术结合案例，回归到思想本源，也就是「符号主义」与「连接主义」的融合。<br>同时，基于论文《ATheoryofFormalismsforRepresentingKnowledge》（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2412. 11855）的关键结论：“在知识表示上，符号主义与连接主义具有等价性，并且可以相互借鉴”，这进一步地提升了我们对「符号主义」与「连接主义」融合的价值认知和技术决策信心。</p><p>更进一步地，如果将GraphRAG看做“符号⋈连接”的产物（Graph⋈LLM），将Agent看做“连接⋈行为”的产物（LLM⋈环境反馈），那么继续推导“符号⋈连接⋈行为”这三方结合的产物：「Graph⋈LLM⋈环境反馈」，简而化之，即Graph⋈Agent。没错，这正是我们这次要探讨的主题！<br>要弄清Graph⋈Agent的核心内涵和价值归宿，仍要从Graph⋈LLM开始，我们需要从「历史唯物主义」的角度重新审视GraphRAG技术的演进过程，弄清每一次技术「变革」的背后，要解决的核心的「矛盾」是什么。<br>从2022年底ChatGPT正式发布，提供给用户的最初界面便是「自然语言问答」，后续我们统一简称为Q&amp;A。由于相信ScalingLaw，因此我们相信LLM中的大规模参数「压缩」了「世界知识」，既而期望通过「提示工程」优化表达，逐步打开信息的「潘多拉魔盒」。至于如何优化表达，成为合格的「提示工程师」，可以参考之前这篇文章《访谈李继刚：从哲学层面与大模型对话》（链接：https :&#x2F;&#x2F;zhuanlan. zhihu.com&#x2F;p&#x2F;7494277954）。<br>然而事实往往不尽如人意，大家都意识到了LLM至今都无法回避的问题——幻觉。为了缓解LLM幻觉，各路“诸侯”是「十八般武艺」全往上招呼：模型微调、查询重写、检索增强、向量嵌入、重排序、知识图谱、智能体技术，一股脑得全往上怼，只为让评测效果提升几个百分点，逐步形成了如今面向「知识问答」的AI工程链路形态。从某种意义的说，LLM幻觉问题为这两年AI工程链路的持续改进提供了原始动力，真可谓「成也萧何，败也萧何」。<br>2023年，也就是ChatGPT发布后的第二年，私域知识的问答诉求与日俱增，借助于SFT对LLM进行后训练的方式，可以快速为LLM补充私域知识，扩展其知识边界。在这个历史时期，用户的知识图谱数据还是通过传统的数据工程手段采集、清洗、加工，存储在图数据库系统内。如果希望借助LLM通过自然语言的方式访问这些图数据，最直接的手段就是将自然语言通过LLM直接翻译为图查询语言（GQL），既而访问图数据库获取数据。为此，我们还专门训练了Text2GQL模型，同时解决了GQL语料不足的自动合成问题。具体可以参考文章《Awesome-Text2GQL：从语料生成到TuGraph-DBChatBot》。<br>本质上说，Text2GQL可以看作GraphRAG的初级形态。然而，以LLM微调后训练为基础的技术方案，仍然无法逃脱私域知识语料无法实时更新的羁绊。<br>2024年，以向量知识库为数据底座，结合ICL（InContextLearning）的RAG技术全面爆发，通过外挂知识库组件避免了私域知识更新困难的问题，相比于微调在工程实现上具备了更高的灵活度，行业繁荣程度可参考我去年底整理的《RAG七十二式：2024年度RAG清单》。<br>然而，基于向量表征的知识管理方案，忽视了文本之间的事实关联信息，导致文档召回出现遗漏、噪声、错误、矛盾等一系列问题（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2401. 05856）。<br>相比而言，图数据结构就更适合描述事物间的复杂关联信息，因此集成图数据库作为知识库底座，已成必然趋势。同时为了让图数据库能与RAG框架无缝集成，必须引入知识图谱语义层支持「文档载入」、「文档召回」等能力，形成与向量数据库底座兼容的通用RAG框架。<br>构建通用RAG框架仅仅是第一步，增强RAG问答效果才是核心。微软的GraphRAG方案（链接：https :&#x2F;&#x2F;github. com&#x2F;microsoft&#x2F;graphrag）爆火，引爆了「LLM+KG」热潮。同时其「社区摘要」的理念也为GraphRAG链路中知识图谱的处理带来了新思路——借助于图算法，可以从更高的维度丰富知识图谱语义。<br>图算法的引入，为知识图谱引入了新的图特征信息，相当于在原始知识图谱层之上新增了知识层次。比如引入社区发现算法构建社区摘要知识，引入PPR算法挖掘重要节点信息等。这相当于构建了知识分层的架构，属于对知识图谱的「垂直扩展」。<br>相对应的，便是对知识图谱的「水平扩展」，最直接的莫过于引入新的知识图谱数据，比如文档结构图谱。<br>文档结构的引入提升了知识图谱中的文档溯源能力，以提供更完备的GraphRAG上下文。当然，除此之外仍有诸多更灵活的知识扩充方法，比如知识图谱增强技术中常用的的消歧、链指、融合等方法也可以看做广义上的知识扩充手段。<br>知识图谱的分层与扩展在强化了知识库能力的同时，也对知识召回的能力提出了更进一步的要求。我们可以清晰地看到，GraphRAG的知识召回链路也从单一的「关键词检索」，到「向量检索」，再到「混合检索」的逐步演进路径。<br>尤其是在引入了「意图识别+Text2GQL」的「文本驱动」检索链路后，GraphRAG不光整合了Text2GQL技术，还对智能体技术提出了新的要求。因为我们发现一个事实：依赖简单的「意图识别」、「查询重写」手段已不足以解决复杂的Q&amp;A问题，通过智能体对用户问题拆分、规划已开始提上日程。<br>在另一个维度上，单一的外挂知识库方法也开始不能满足用户日益增长的查询诉求了。用户不再满足于异步的知识库文档加载延迟，而是需要调用工具实时地感知开放的外部世界知识，AgenticRAG（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2501. 09136）自然也就应运而生。<br>AgenticRAG引入了工具调用，将RAG从原本的「检索增强」，逐步过渡到「工具增强」形态，RAG的原生含义开始被默默「变革」。</p><p>结合混合检索中对用户问题「规划拆分」，以及AgenticRAG中「工具使用」对智能体关键能力的诉求，我们可以果断地得出一个清晰的结论：<br>有了这个结论之后，紧接着一个新问题就是：“什么是GraphAgent？”。如果只是单纯地把「GraphRAG+任务规划+工具使用」进行硬性地组合，是我们期望的GraphAgent真正形态吗？<br>比如GraphRAG在GraphAgent中的定位是什么？访问图数据库的工具和GraphAgent的工具是什么关系？需不需要多个GraphAgent进行协作？在回答这些问题之前，我们需要对智能体有一个更清晰的认知，以指导我们更好完成GraphAgent的设计。<br>在《人类简史》这本书中，描述了人类历史发展过程中最重要的三种力量：</p><p>比较神奇的是，如今热门的MCP、A2A“恰好”都在工具这个类别下，当然这不是巧合，大厂积极地推广这样的交互协议，本质是期望通过定义智能体与世界的交互标准，达到构建生态的目的。细心的读者可能会发现，大家目前都在“卷”工具的标准，那么知识有没有标准呢？我相信这件事正在发生。<br>说完智能体的结构，还需要再探索另一个问题：“我们应该选择单智能体，还是多智能体？”。</p><p>当下这个问题并未尘埃落定，单从架构灵活性考虑，支持多智能体能力不失为一种稳健的选择。这样既保留了面向生态和未来的扩展性，也不妨碍我们专注于优化单智能体的能力。<br>连接主义的代表性技术「神经网络」，是通过模拟大脑神经元的组织和行为而逐步发展的技术体系，属于仿生学习的典型案例。另外，论文《AdvancesandChallengesinFoundationAgents》（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2504. 01990）中对仿生的理念做了延伸，将大脑的不同功能区与AI研究领域进行了映射。<br>仿生学习理念在智能体时代可以有更广阔的发挥，可以将脑神经科学、认知心理学、社会学、哲学等跨学科知识与计算机科学进行深度的结合。更进一步地，我们扩展出「广义仿生」的理念：从神经元、大脑、四肢、个体、群体乃至到世界的全面仿生。<br>并且，我们发现这种广义的仿生理念，和Graph有着深度的内在联系，这得益于Graph在描述「事物客观联系」上的天然优势。从而可以使用多样化的Graph结构和技术描述智能体中LLM（大脑）、推理&amp;规划（思考）、记忆（海马体）、知识（世界知识）、工具（四肢&amp;外部工具）、协作（群体）的内在组织结构，实现Graph对智能体能力的全面增强。<br>结合GraphRAG的演进历史，以及Graph对「广义仿生」驱动的智能体的设计思考，我们基本梳理清楚了「Graph+AI」技术的关联逻辑，也就是「图智互融」。<br>一方面借助AI加速Graph的构建、分析，提升产品的使用效率和自动化，即「AIforGraph」。另一方面，利用Graph在连接上的优势，重构AI组件的组织，增强推理能力和可解释性，即「GraphforAI」。<br>结合「图智互融」的理念，我们定义了Graph与AI的双向增强逻辑。作为智能体不仅可以解决智能用图的问题，还可以受益于图在智能体系统设计的增强优势，让图的能力在智能体内置化，这就是我们定义的「图原生」。<br>Chat2Graph是行业首个全面践行「图原生智能体」理念的系统：以智能体为蓝图，探索「图智互融」技术创新。系统采用了「单主动-多被动」（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2409. 11393）的混合智能体架构，构建了以单个Leader智能体驱动，多个Expert智能体协作的任务执行体系。<br>系统的核心组件有：<br>图系统层：构建了面向图系统的统一抽象，使用图数据库服务统一管理，并支持未来更多图计算系统的扩展。<br>AI系统层：构建AI基础设施抽象，如智能体框架、RAG、记忆工具、模型服务工具等，提供智能体能力基建和生态扩展。<br>存储服务层：存储智能体的持久化数据，包括元数据、记忆、知识、文件等。<br>推理机：提供LLM服务封装、推理增强、工具调用等基础能力。<br>工作流：负责智能体内部的算子（Operator）编排与SOP抽象，定义智能体工作流程。<br>记忆系统：构建分层的知识精练体系，负责智能体系统的信息存储、检索，包括记忆管理、知识库、环境等。<br>工具库：基于图谱的方式描述工具和智能体行动的关联关系，实现工具的自动化管理和推荐。<br>智能体：智能体系统执行单元的统一抽象，使用角色定义（Profile）描述工作职责，使用工作流描述工作流程。主要包括Leader智能体和Expert智能体两大类型。<br>自动化：系统智能体化能力的抽象，「LessStructure」理念的实践手段。包括自动的任务规划、工作流生成、工具库优化、知识精练、资源调度等能力。<br>系统集成：提供WebUI、RestfulAPI、SDK的集成方式，通过YAML一键配置智能体系统，方便开发者快速接入Chat2Graph的能力。<br>系统运行时，Chat2Graph能够将用户的自然语言指令智能地转化为一系列精确、自动化的图数据构建、数据处理、算法应用和迭代优化的步骤。这极大地降低了用户进行复杂图分析的技术门槛，使得非技术背景的用户也能利用图的强大表达能力进行深度探索和知识发现。<br>关于智能体的标准定义，行业并未形成统一标准，但智能体的关键组件概念基本上已经深入人心：如推理、规划、记忆、知识、行动、工具、协作、环境等等。早在2023年OpenAI安全VP翁荔在文章《LLMPoweredAutonomousAgents》（链接：https :&#x2F;&#x2F;lilianweng. github.io&#x2F;posts&#x2F;2023-06-23-agent&#x2F;）中就提出「Agent&#x3D;规划+记忆+工具+行动」的基本结构。后续随着智能体技术的行业演进，出现了诸多「改进型」范式，如「Agent&#x3D;规划+记忆+工具」，甚至更极端的「Agent&#x3D;LLM+工具」的定义。<br>在设计Chat2Graph的过程中，我们经过长期的深度思考，总结了Chat2Graph对Agent结构的理解。即「Agent&#x3D;推理+记忆+工具」，规划&amp;协作属于高维的推理，知识&amp;环境属于高维的记忆，行动&amp;战略属于高维的工具。接下来我们先按照这个总体理念，介绍Chat2Graph的关键组件设计和实现原理，并在「开放架构」章节解释这个观点的自洽性。<br>5. 3推理系统<br>推理系统整合了LLM的交互能力，从提示工程激发LLM的「推理」能力，到任务拆分「规划」复杂任务，再通过多智能体「协作」完成总体目标，是智能体系统「智能」的统一抽象。<br>5. 3.1推理增强<br>常规LLM推理能力增强有两种主流路线，一种是借助RL（强化学习）增强隐式推理能力的LRM模型路线，另一种是通过提示工程（CoT等）增强LLM显式推理能力的工程路线。</p><p>DualModelReasoner采用一个“思考者”（Thinker）LLM和一个“执行者”（Actor）LLM协同工作的模式，类似于两个LLM在“一言一语”地交叉式地对话。Thinker通常是能力更强、理解和规划能力更出色的LLM，负责理解复杂的用户意图、分解任务、制定计划，并在需要时决定调用哪个工具或子任务，可以将具体的、定义清晰的、步骤性的任务或工具调用请求传递Actor模型执行。Actor模型则是在遵循指令进行格式化输出、执行特定类型的工具调用、快速思考回答更高效的LLM，可以专注于处理工具调用的请求和响应格式化，使得Thinker模型能更集中于核心的推理和规划。<br>关于LLM推理能力增强是走模型路线，还是工程路线，我们认为不是一个选择题。我们期待LLM未来推理能力的持续改进与提升，也不排斥在LLM推理能力不足时期，引入必要的工程手段加以补充。<br>任务规划是一个相对模糊的概念，至少在智能体系统内，有两类规划场景。一类是面向不确定的用户原始问题，如何拆分为具体的子任务，并安排好子任务的执行和依赖关系，即任务拆分，产出为JobGraph。另一类则是针对特定领域的子问题，如何设计合理的流程对任务分阶段处理，即SOP，产出为Workflow。<br>其实这两类场景其实本质是相同的，在Chat2Graph中，JobGraph更侧重于描述智能体间的职责分配，Workflow则更侧重描述单智能体内部的职责，仅仅是对用户目标的拆分粒度在不同的层面而已。当前Chat2Graph的JobGraph由Leader统一完成，而Workflow还是「硬编码」在智能体内部，同时我们也在OSPP（链接：https :&#x2F;&#x2F;summer-ospp. ac.cn&#x2F;org&#x2F;prodetail&#x2F;257280066）中和社区一起共建「自动工作流生成」能力。未来，这两部分规划能力，即JobGraph和Workflow可以做到统一整合。<br>协作当前更多的还是强调多个智能体之间的互动，处理任务、资源的动态分配和调度。不论是采用「单主动-多被动」的统一Leader协调方式，还是多个Expert自由通信的自主方式。亦或采用单进程的串行处理，还是使用远程通信的并发处理。多智能体系统的协作机制都要处理以下几个关键问题：<br>任务分配：将拆分好的子任务合理地分配到对应的智能体执行。<br>执行容错：任务执行结果的评估与反思，并能通过重试自动恢复。<br>重新规划：对不合理的任务拆分的容错能力，能适时的请求重新规划流程。<br>结果交付：能通过合理的协作，对任务产出物生成、加工、优化，交付预期结果。<br>资源调度：通过调度优化资源的使用，降低时间、空间、Token开销，提升质量。<br>相比Workflow的「静态」属性多一些，更侧重规范化流程，JobGraph的「动态」属性则多一些，更侧重任务的灵活性以及能力扩展。尤其是类似A2A协议定义了智能体交互的规范，更需要良好的协作机制，通过引入更开放的生态，扩展系统边界，提升解题能力。<br>记忆系统负责智能体系统中信息的存储、检索和管理，可以与推理机配合构建长上下文、跨会话机制，为整个系统提供持久化的学习和适应能力，提升系统的整体智能水平。Chat2Graph引入了分层「记忆」设计，定义了从原始数据逐步提炼到高层次的智慧洞察的过程，希望使用统一架构兼容「知识」库、外部「环境」信息。<br>与传统的基于仿生理念将记忆划分为感知记忆、短期记忆、长期记忆的划分手段不同，Chat2Graph借鉴了DIKW（链接：https :&#x2F;&#x2F;en. wikipedia.org&#x2F;wiki&#x2F;DIKW_pyramid）金字塔模型，从信息的内容角度出发将记忆划分为四层结构。<br>这是一次新颖的尝试，我们更相信在记忆系统的设计中引入数据工程、知识图谱等传统数据处理方法，而非单纯地走「仿生」的路线。<br>5. 4.2知识管理<br>一般的，知识库被看作外部知识的「封闭式」存储仓库。为了提升知识召回的质量，RAG框架多数情况在对知识库的外围技术做改进，比如查询重写、文档切分、重排序等等，反而忽略了知识内容自身的改进。当然，GraphRAG可以看做一种相对早期的尝试。分层记忆系统的引入，为精细化的知识管理的提供了「开放式」的解决思路。<br>分层记忆系统引入的多级信息抽象，允许我们能从更精细的粒度对知识进行管理。<br>知识精练（KnowledgeRefinement）：原始知识经过逐级的处理、分析、抽象、压缩，形成更高层次的知识，扩展知识生产的能力。<br>知识下钻（KnowledgeDrilling）：在使用高维知识的同时，还可以按需下钻低维知识，让推理上下文粗中有细，强化知识消费的能力。<br>知识延拓（KnowledgeExpansion）：表示同层级知识关联的构建和召回，通过特定方法丰富知识上下文。典型代表是RAG（检索增强生成）。<br>从某种意义上讲，「知识库其实是记忆系统在垂类领域知识上的特化表达」。当前Chat2Graph初步地将RAG作为知识库的实现底座，并正在与MemFuse（链接：https :&#x2F;&#x2F;github. com&#x2F;memfuse&#x2F;memfuse）在社区上通力合作，构建分层、动态、关联的记忆系统架构，最终实现知识库能力整合。<br>5. 4.3外部环境<br>环境指的是智能体执行过程中可交互的外部空间，智能体可以通过工具操作感知环境变化，影响环境状态。本质上，「环境可以被视为\“当前时刻的外部记忆\“，而记忆则是\“历史时刻的环境快照\“」，这种同质性使得环境可以无缝地融入分层记忆模型中。Agent通过工具感知的环境信息其实是L0层的原始数据，并可以进一步的提炼形成更高层次洞察（L1~L3）。反过来，记忆系统中经验积累会直接影响环境中的全局共识和高维洞察。<br>最新的G-Memory（链接：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2506. 07398）的研究与我们的分层记忆系统的理念不谋而合，它设计了三层图结构来管理记忆：<br>交互图（InteractionGraph）：存储细粒度的智能体间的通信日志，提供事实依据。<br>查询图（QueryGraph）：记录任务节点（含状态）以及语义相似或关联的任务关系，并与交互图链接。<br>洞见图（InsightGraph）：存储从多次成功或失败的交互中提炼出的、具有普适性的经验和教训。<br>另外，从智能体与外部环境的关系来看，通过「工具」这座桥梁，可以深层次地打通记忆系统与环境状态，构建智能体的「精神世界」与外部环境的「物理世界」的映射关系，即世界知识模型。<br>工具系统负责智能体系统中「工具」的调用与管理，通过与「行动」关联构建工具库图谱，并能提供「战略」性的指导建议为推理机推荐合适的工具集，扩展智能体行为能力的边界。<br>工具调用早期的形态来源于LLM的FunctionCalling机制，随着LLM能力不断提升，通过提示工程构建通用的工具调用能力已经相当普遍。<br>在Chat2Graph中，推理机可以结合任务目标，从候选工具集中确定所需的工具并触发调用动作。除了对常规意义的外部工具（如脚本、API、MCP）的支持，Chat2Graph还允许将系统的内置服务（文件服务、知识库服务等）注入到工具，以便和系统资源无缝打通。从整个智能体角度来看，这么做提升了工具调用的扩展性和灵活性。<br>随着智能体接入的行业领域不断增长以及工具控制粒度的不断细化，智能体面临的工具规模管理成本和合理工具选型的难度将不断提升。面向大规模工具集的合理工具选型是一个典型的「推荐问题」，而「二分图」是解决推荐问题时常用的图数据抽象，因此构建「行动-工具」的关联图谱就十分合理。<br>在Chat2Graph中，正在建设自动化的工具图谱构建、优化、推荐的能力。比如一键注册工具包、MCPServer到工具图谱，并结合强化学习的思路优化工具的元信息、关联关系和权重等。<br>如果说行动是对工具的初级抽象，那么战略则是对行动的进一步抽象。通过建立行动的高维抽象，描述行动间的顺序依赖和关联关系，为智能体的行为序列推荐提供战略性的指导建议，进一步提升工具图谱的丰富度和推荐能力。这一部分的工作我们还在逐步探索。</p><p>传统的软件工程核心本质在于解决数据和计算的问题，通过设计良好的编程语言高效地操纵CPU和存储，通过合理的数据结构和算法描绘软件的功能逻辑，通过优雅的架构定义软件的数据模型和计算抽象，因此可以说「数据」和「计算」是传统软件工程的基石。基于LLM的AI行业爆发以后，引入了第三块基石——「模型」，将传统软件工程升级为AI软件工程，Agent便是最典型的代表。<br>结合前面对Chat2Graph架构原理的解读，可以进一步得到如下抽象能力矩阵。<br>我们认为，「推理」、「记忆」、「工具」是对AI工程三大基石「模型」、「数据」、「计算」的工程化表达，同时「规划&amp;协作」、「知识&amp;环境」、「行动&amp;战略」是对「推理」、「记忆」、「工具」的进一步抽象，而它们都可以使用Graph统一表达，分别对应「任务图谱」、「知识图谱」、「工具图谱」，甚至在未来这三张Graph还可以进一步融合，这便是我们对「GraphforAI软件工程」的整体理解。<br>基于这样的第一性思考，再结合MCP、A2A这样的标准化协议，可以指导Chat2Graph面向未来的开放设计。甚至可以让Chat2Graph形成自主迭代能力，引导Chat2Graph从AIAgent走向AgenticAI。<br>Chat2Graph当前内置了多个图领域专家，可以通过多智能体协作的方式传统GraphRAG的链路工作。</p><p>另外，基于Chat2GraphSDK也可以实现轻松集成到你的Python应用。</p><p>以上我们全面解读了Chat2Graph践行「Graph+AI」理念的细节，即GraphAgent。关于Graph⋈Agent的未来形态，还有一些关键的点需要持续保持关注。<br>由Manus团队提出的智能体产品设计理念，「LessStructure,MoreIntelligence」是AINative思想的直观表达，正在深刻影响着智能体的演进路径。过度结构化将扼杀智能体的涌现潜力，但「LessStructure」并非简单的「去结构化」，而是就智能体设计这个问题上，人与LLM之间的「信任转移」，即你更相信自己多一些，还是更相信LLM多一些？</p><p>Chat2Graph的架构设计中，「自动化」能力的设计就是对「LessStructure」理念的落实，也是未来走向AgenticAI的关键基础。<br>6. 2MoreConnection<br>相对应的，Chat2Graph提出了「MoreConnection,LessHallucination」的理念，这是GraphNative思想的具象化，也是符号主义的在AI时代的价值主张，更是GraphAgent的精神内核。「MoreConnection」并非单纯意义上的增加连接的规模，而是在智能体系统的关键设计中引入「连接」设计，比如任务图谱、知识图谱、工具图谱，为智能体赋予更确定的语义结构，增强推理的可解释性。<br>结合前面的讨论，这里简单对比一下AIAgent与GraphAgent能力差异。<br>这里多做一步讨论，过往多年，人工智能的研究者们一直不懈地探索表达人类「世界知识」的方法。以「知识图谱」为代表「符号主义」研究鏖战多年，而以「神经网络」为代表的「连接主义」也是到LLM的「ScalingLaw」的出现才迎来转机。不幸的是人们很快就遇到了LLM的「算力&amp;数据」瓶颈，导致LLM只能用有限层级的「深度神经网络」去压缩「世界知识」，带来的直接后果就是「幻觉」。<br>这个时候大家自然想到，「知识图谱」这位“难兄难弟”能不能在关键时刻捞自己一把，弥补掉那部分因为「深度缺失」而遗漏的知识。在和DeepSeek就这个话题沟通时，TA说的一句话倒是让我眼前一亮：“知识图谱不是AI的插件，而是机器认知世界的骨架。”，倒是和我对「图智互融」本质的粗浅理解达成共识了。<br>最后，对去年底年终总结时留下的“小作业”做个回顾：「Agent-LLM&#x3D;?」，意思是去掉LLM，Agent真正剩下的价值是什么？当时写下这个问题的本意是帮助大家去深思“在LLM能力不断增强的情况下，「AI工程」的不变价值是什么？”，不知道你是否还记得当时的答案吗？<br>经过这篇万字文章的「自问自答」，我结合Chat2Graph给出了我们一直坚信的答案：<br>Agent-LLM&#x3D;Memory+Tool<br>或许会有人挑战：“其实Memory的读写也应该看做Tool的一部分”。这里我使用一句话对此释义：<br>记忆是白盒化的工具，而工具是黑盒化的知识。<br>个中缘由，请君自译。<br>参考资料：<br>1. 2024年度Graph+AI开源探索思考：https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;1x6FQWZTa517aX8GDjHeNA<br>2. Chat2Graphv0.1. 0：https :&#x2F;&#x2F;github. com&#x2F;TuGraph-family&#x2F;chat2graph&#x2F;releases&#x2F;tag&#x2F;v0. 1.0</p><p>4. 硅基流动邀请链接：https :&#x2F;&#x2F;cloud. siliconflow.cn&#x2F;i&#x2F;lFPrw34X<br>5. Chat2Graph代码仓库：https :&#x2F;&#x2F;github. com&#x2F;TuGraph-family&#x2F;chat2graph<br>6. Chat2Graph项目文档：https :&#x2F;&#x2F;chat2graph. vercel.app&#x2F;<br>7. ATheoryofFormalismsforRepresentingKnowledge：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2412. 11855<br>8. 访谈李继刚：从哲学层面与大模型对话：https :&#x2F;&#x2F;zhuanlan. zhihu.com&#x2F;p&#x2F;7494277954<br>9. Awesome-Text2GQL：从语料生成到TuGraph-DBChatBot：https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;P7V8Z9hao7lyw0bMdr94cg<br>10. RAG七十二式：2024年度RAG清单：https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;Sy1dSx5RUtD6rjMY7_efkw</p><p>12. Vector|Graph：蚂蚁首个开源GraphRAG框架设计解读：https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;WILvYFiKugroy9Q_FmGriA<br>13. 微软的GraphRAG：https :&#x2F;&#x2F;github. com&#x2F;microsoft&#x2F;graphrag<br>14. GraphRAG+文档结构：打造高性能实体溯源方案：<br>https :&#x2F;&#x2F;mp. weixin.qq. com&#x2F;s&#x2F;EQ3QnWWt1v9_S79MdRaJlw<br>15. AgenticRetrieval-AugmentedGeneration:ASurveyonAgenticRAG：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2501. 09136</p><p>17. WhyDoMulti-AgentLLMSystemsFail?：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2503. 13657<br>18. Don’tBuildMulti-Agents：https :&#x2F;&#x2F;cognition. ai&#x2F;blog&#x2F;dont-build-multi-agents</p><p>20. AdvancesandChallengesinFoundationAgents：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2504. 01990</p><p>22. LLMPoweredAutonomousAgents：https :&#x2F;&#x2F;lilianweng. github.io&#x2F;posts&#x2F;2023-06-23-agent&#x2F;<br>23. AgentsThinkingFastandSlow:ATalker-ReasonerArchitecture：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2410. 08328<br>24. OSPP：https :&#x2F;&#x2F;summer-ospp. ac.cn&#x2F;org&#x2F;prodetail&#x2F;257280066<br>25. DIKW：https :&#x2F;&#x2F;en. wikipedia.org&#x2F;wiki&#x2F;DIKW_pyramid<br>26. MemFuse：https :&#x2F;&#x2F;github. com&#x2F;memfuse&#x2F;memfuse<br>27. G-Memory:TracingHierarchicalMemoryforMulti-AgentSystems：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2506. 07398</p><p>29. GraphRAG-ToolFusion：https :&#x2F;&#x2F;arxiv. org&#x2F;abs&#x2F;2502. 07223</p><p>32. Chat2Graph快速开始：https :&#x2F;&#x2F;chat2graph. vercel.app&#x2F;chat2graph&#x2F;zh-cn&#x2F;quickstart</p><p>·END·<br>欢迎关注TuGraph代码仓库✨<br>TuGraph-DB图数据库<br>https :&#x2F;&#x2F;github. com&#x2F;tugraph-family&#x2F;tugraph-db<br>GeaFlow流式图计算引擎<br>https :&#x2F;&#x2F;github. com&#x2F;tugraph-family&#x2F;tugraph-analytics<br>Chat2Graph图原生智能体系统<br>https :&#x2F;&#x2F;github. com&#x2F;tugraph-family&#x2F;chat2graph</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Agent做PPT的开源实践：代码端看MultiAgentPPT实现思路</title>
      <link href="/2025/06/26/1000001244-2648421393-2-1750908480/"/>
      <url>/2025/06/26/1000001244-2648421393-2-1750908480/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/e2tDbBVmnqY-TPJ-bx5AGw">Agent做PPT的开源实践：代码端看MultiAgentPPT实现思路</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月25日，星期四，北京，晴<br>我们回答文档智能进展，来看一个自动生成PPT的项目，其中流程的设计，以及用到的爬虫代码以及Agent的prompt都可借鉴。</p><p>我们可以看看3个核心问题。<br>1、整体的实现流程是什么？<br>先从工作流的控制看起，如下：<br>其中可以具象化的整体实现流程如下图所示，分成4个Agent，<br>其中：<br>大纲生成Agent，根据用户需求生成初步内容大纲。<br>Topic拆分Agent，将大纲内容细分为多个主题；<br>ResearchAgent，并行工作，多个智能体分别对每个主题进行深入调研；<br>SummaryAgent，汇总输出，将调研结果汇总生成PPT内容，实时流式返回前端。<br>整个后端的逻辑在：https :&#x2F;&#x2F;github. com&#x2F;johnson7788&#x2F;MultiAgentPPT&#x2F;tree&#x2F;main&#x2F;backend。<br>2、其中的数据从哪儿来？<br>既然是要生成内容，尤其是其中生成大纲以及内容，都会用到RAG，所以就会有知识库。<br>那么，知识库如果需要做到实时，那么就需要进行更新，所以可以爬虫，从代码上看，其从weixin_search. py中可以看到，其使用搜索搜索微信公众号文章，先关机关键词搜索搜狗，获取链接，然后使用get_real_url获取真实链接，最后使用真实链接获取公众号内容。<br>其中获取公众号内容如下：<br>3、从底层实现代码看每个子agent的执行逻辑</p><p>其中：slide_outline，使用rag，检索抓取形成的文章内容，然后组织成如下prompt送入LLM进行生成：<br>slide_agent进一步分为第一个问题中的research_topic、split_topic、summary_writer几个工作组件，如下：<br>其中:<br>split_topic专门负责分析写作大纲并将其拆分成独立的研究主题，作用的prompt如下：<br>research_topic，根据拆分的主题，动态创建并行的研究员进行资料搜集，使用的prompt如下：<br>SummaryAgent进行文章撰写和内容整合，作用的prompt如下，使用的XML语言表示：<br>1、https :&#x2F;&#x2F;github. com&#x2F;johnson7788&#x2F;MultiAgentPPT<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>看来看去，它依旧是最好的基于Pytorch的深度学习实战书！！</title>
      <link href="/2025/06/25/1000000136-2247492462-1-1750849224/"/>
      <url>/2025/06/25/1000000136-2247492462-1-1750849224/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/ZD7XFt8E_ba-7HFKwEAY9g">看来看去，它依旧是最好的基于Pytorch的深度学习实战书！！</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>不知道大家知不知道这本书！我前两年在B站有推荐过，作者是前硅谷工程师、PyTorch定期撰稿人和PyTorch核心开发人员，技术背景强大，深度学习领域最通俗易懂的图书之一，在AI领域有着很多的贡献。<br>想要学习Pytorch的操作、看不懂深度学习代码、不知道怎么完成一个深度学习项目的同学都非常适合！<br>很多网友都给出了很高的评价：<br>我在我的B站频道也发布过这本书的带读系列，大家可以搭配着这本书来理解。<br>如果你需要这本书的中英双版PDF，老方法，因网盘易和谐，可以直接扫码添加我的助理让她无偿及时发送给大家。（避免单个微信添加频繁，故备了两个微信，大家随意添加一个即可）<br>该书核心是由三个部分组成：第一部分介绍Pytorch基础知识、第二部分介绍了一个端到端的项目、第三部分介绍Pytorch部署相关知识。<br>市面上很多其它相关书籍内容安排一般是，先介绍深度学习基础知识，例如张量，反向传播等等，然后基于MLP给个简单的例子。后面接着介绍CNN，RNN以及图像和NLP领域内比较有名的模型。<br>但是这本书不一样，这本书的侧重点是在实战代码方面。尤其是第二部分的实战内容，用了整整6章，竟然只介绍了一个项目「肺癌检测项目」，讲解的非常非常详细，从零带你基于Pytorch代码完成一个项目，这对一直不太理解深度学习代码的同学非常有帮助，你跟着走一遍，很多项目代码你就都能看懂了。<br>下方为书的部分内容展示：</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI算法工程师Future </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Research现有方案技术总结：实现架构、特点对比、现存问题及未来方向</title>
      <link href="/2025/06/25/1000001242-2648421362-1-1750822998/"/>
      <url>/2025/06/25/1000001242-2648421362-1-1750822998/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/7TqX0zi8aI-jByetRIISJg">Deep Research现有方案技术总结：实现架构、特点对比、现存问题及未来方向</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月25日，星期三，北京，晴<br>最近的技术综述工作也很多，来关注Deepresearch进展，系统性的看一个是技术总结，其中的技术模式的总结、存在的问题、对比分析结论等，都值得关注。</p><p>对于这份技术总结中，选择5个核心问题来看。<br>1、对于Deepresearch框架等索引有哪些？<br>相关的索引列表在：https :&#x2F;&#x2F;github. com&#x2F;scienceaix&#x2F;deepresearch，对Projects做了很好的整理，如下：<br>2、Deepresearch的三个发展时期<br>原初期探索期（2023年-2025年2月），以n8n、QwenLM&#x2F;QwenAgent等工作流自动化框架为代表。<br>竞争角逐期（2025年2月-3月），DeepSeek-R1开源以及2025年2月OpenAI发布了DeepResearch为标志。</p><p>3、Deepresearch的层次化技术框架<br>包括基座与推理模型、任务规划与执行、工具使用与环境交互、知识生成。<br>4、Deepresearch的实现架构<br>包括四种基础架构模式：单体式、基于流水线的、多智能体以及混合实现。<br>整体大的逻辑在：<br>细分的逻辑可以拆解下：<br>单体模式，将所有深度研究能力整合在一个以核心推理引擎为中心的统一的架构框架内，采用集中控制机制，直接集成专用模块。<br>流水线模式，通过一系列通过明确定义的接口连接的专业处理阶段实现深度研究能力，将研究工作流分解为离散的处理组件，并在各阶段之间进行明确的数据转换。<br>多智能体模式，通过由明确通信协议协调的专门自主智能体生态系统，在具有不同角色和责任的协作智能体之间分配研究功能。<br>混合模式结合多种架构模式，以统一实现中平衡各自的优势。<br>5、现有Deepresearch的一些对比结论<br>对比角度，可以从多个角度进行评估，注意看其中的一些处理策略：<br>1）基础模型与推理效率<br>2）工具集成与环境适应性<br>3）任务规划与执行稳定性<br>4）知识聚合与输出质量<br>5）学术研究情境适应性<br>6）企业决策场景适应性<br>7）个人知识管理适应性<br>5、Deepresearch存在的几个问题<br>包括：信息完整性、隐私保护、来源归属与知识产权，以及可访问性。<br>6、Deepresearch值得做的几个研究方向<br>研究方向包括：高级推理架构、多模态集成、领域特化以及标准化下的人机协作。<br>1、https :&#x2F;&#x2F;arxiv. org&#x2F;pdf&#x2F;2506. 12594<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RAG的2025趋势重点及RAG+抽取场景的来源定位问题思考</title>
      <link href="/2025/06/24/1000001241-2648421338-1-1750738051/"/>
      <url>/2025/06/24/1000001241-2648421338-1-1750738051/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/NT1WsWVE0lhzsa_87cXwaA">RAG的2025趋势重点及RAG+抽取场景的来源定位问题思考</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月24日，星期二，北京，晴<br>我们来看有趣的落地问题。<br>为什么在实际落地过程中，比如信息抽取、RAG等，会有引文生成、来源定位这些需求？底层的逻辑是什么？有哪些实际的例子？在技术上如何做？<br>另外，看看RAG发展温故而知新，看看RAG的一个发展趋势，看下RAG的2025趋势重点<br>1、为什么需要引文生成？<br>目前，包括大模型在内的深度学习方案，生成数据的原理是基于概率模型，可能产生“幻觉”，也就是即虚构事实或无依据的结论，通过引文标注来源，用户可验证答案是否基于真实数据。<br>例如，RAG在生成答案前检索外部知识库，并将检索到的文档片段作为生成依据，这样可以给人员以交互入口。<br>以实际的实际的落地场景为例，在医疗或金融领域，若回答未标注政策条款来源，可能误导决策；而引用具体文件章节（如“《XX政策》第3. 2条”）则增强可信度。<br>而除了这一层，还有人的因素，这些模型的决策过程缺乏可解释性，引文提供“解释层”，让用户理解答案的生成逻辑，这个在B端，G端的需求更为强烈。<br>2、有哪些典型的定位例子<br>先说RAG，定位可以定位到chunk，定位到某个具体的文档页面，这个在RAG的产品或者开源项目中十分场景。<br>一个是magi，知识图谱抽取的引文生成。这个比较早，在知识图谱中，给出抽取实体或者实体关系所来自于的段落，并通过线条的方式进行连接。<br>一个是典型的RAGflow中的RAGchunk定位，通过记录问题答案所在的chunk，chunk所在的文本索引，从而完成定位。<br>当然，也可以过渡到多模态任务上，例如答案定位VQA（VisualQuestionAnswering），结合图像理解和NLP不仅要求系统回答问题，还需要定位图像中支持答案的证据区域。<br>3、从技术上看实现策略<br>以RAG中的引文生成为例，可以拆解为两个层面：一是如何让系统知道答案来自哪个文档（引文生成），二是如何精确定位到文档中的具体信息（来源定位）。<br>第一个问题是来源于大模型的能力，可以通过微调或者强化方式解决，在prompt中将相关的文档进行标记，加入一些数字标引，这个标引直接与chunk相关联。然后提示llm生成引文。<br>第二个问题，一般是通过物理方式进行，由于拿到了上一步关联的chunk，则可以同离线阶段相呼应。<br>例如，离线场景下，文档片段标识符存储，在构建向量数据库时，每个文本片段（chunk）需关联唯一标识符（如文档ID、起始位置、结束位置、URL等）。例如，使用Chroma或FAISS存储向量时，元数据字段可包含doc_id、chunk_index、file_path等信息。<br>而进一步，如果要在原文档中进行渲染，那么则需要进一步适用前端进行。<br>而对于信息抽取中的定位，就很自然的，因为抽取本来就是来源于某个段落，这个段落在原文中就有offset，因此这个只需要预先记录即可。</p><p>1、从2023到2026年的RAG与LLM发展的预判<br>从2024年的文档解析，GraphRAG，会到2025年的多模态RAG以及结构化、非结构化的统一抽取（目前也确实是在往这个方向发展）<br>2、RAG的三个挑战定性不变<br>还是螺纹提，三个：非结构化多模态文档的问答效率低下：现有的LLMOps解决方案仅限于纯文本场景。PDF、PowerPoint演示文稿（PPT）或文本与图像融合的文档无法充分发挥其潜力；纯向量数据库导致召回率和命中率低，RAG的核心在于搜索能力；只有能够根据用户的查询“搜索”出答案才能发挥作用。<br>3、RAG中的文档多模态Embedding<br>所以现在大家都在卷embedding，单模态或者多模态，单模态入qwen3-embedding，多模态也是用的比较多，例如colqwen,colpali。<br>这种好处在于，绕过OCR和chunk，直接做问答，这也是在做加法。<br>4、RAG中的文档解析的演变<br>确保数据质量（输入质量）对于获得高质量结果（输出质量）至关重要，所谓garbagein,garbageout。<br>这个故事讲了很久，典型的路线就是pipeline，关于这块，社区也讲了许多了。<br>预测2025年，基于编码器-解码器架构的研究有望取得进一步进展。这个应验了，今年统一的多模态文档解析模型，该模型将各种非结构化文档转换为文本内容。<br>近期的monkeyocr,dolphin,mineru2. 0等方案也正在朝这方面发展。这一些，都直接促成了当前多模态RAG的发展。<br>1、https :&#x2F;&#x2F;ragflow. io&#x2F;blog&#x2F;the-rise-and-evolution-of-rag-in-2024-a-year-in-review<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>一文万字带你深刻了解深度学习的基础知识：深度学习的发展历程、基本概念和主要应用！</title>
      <link href="/2025/06/23/1000000135-2247492447-1-1750670267/"/>
      <url>/2025/06/23/1000000135-2247492447-1-1750670267/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/Ge1njaraXxE_A0Cofy3diw">一文万字带你深刻了解深度学习的基础知识：深度学习的发展历程、基本概念和主要应用！</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>一、引言<br>1. 深度学习在机器学习中的地位<br>随着计算能力的提升和大量数据的可用性，深度学习已经成为了机器学习领域的一颗耀眼的明星。深度学习是机器学习的一个子领域，它专注于使用人工神经网络解决复杂问题。深度学习技术在语音识别、计算机视觉和自然语言处理等领域取得了显著的成果，极大地推动了人工智能的发展。<br>2. 深度学习的定义<br>深度学习是一种基于人工神经网络的机器学习方法，通过多层神经网络对输入数据进行逐层抽象和表示学习，从而实现对复杂数据结构和非线性关系的建模。深度学习模型通常包含多个隐藏层，每个隐藏层都有许多神经元。这些神经元通过权重连接，模拟了生物神经元之间的信号传递过程。通过大量的训练数据和合适的优化算法，深度学习模型可以自动学习到输入数据中的高层次特征，从而实现对复杂任务的高效解决。<br>在继续之前，这些都是我给深度学习新手整理的学习书籍PDF➕近万人领取过的深度学习入门学习路线思维导图源文件，因网盘易和谐，如果你也需要的话可以直接扫码添加我的助理让她无偿及时发送给你最新网盘链接！<br>长按即可扫码添加（避免单个微信添加频繁，故备了两个微信，大家随意添加一个即可）<br>3. 深度学习的重要性与应用<br>深度学习技术在众多领域取得了显著的成绩，改变了我们处理问题的方式。以下是一些深度学习的主要应用场景：<br>1. 计算机视觉：深度学习模型在图像识别、目标检测和图像分割等任务中取得了超过传统方法的性能，极大地推动了计算机视觉领域的发展。<br>2. 自然语言处理：深度学习技术在自然语言处理任务中取得了突破性进展，如机器翻译、文本分类、情感分析、文本生成等。预训练语言模型（例如GPT和BERT等）基于深度学习技术，已成为自然语言处理领域的核心技术。<br>3. 语音识别与合成：深度学习使得语音识别技术的准确率大幅提升，为智能语音助手和语音识别服务提供了强大的技术支持。同时，深度学习技术还能够实现语音合成，生成极具真实感的人工语音。<br>4. 无人驾驶与机器人：深度学习在无人驾驶汽车的环境感知、决策规划等方面发挥了关键作用。此外，深度学习技术也为机器人的智能化发展提供了强大的支持，使得机器人能够更好地理解和适应复杂环境。<br>5. 推荐系统：深度学习技术在推荐系统中的应用，可以帮助企业更好地理解用户行为和需求，实现个性化推荐，从而提高用户体验和商业收益。<br>6. 游戏智能：深度学习技术在游戏领域的应用，可以使游戏AI更具智能化和挑战性，为玩家带来更好的游戏体验。<br>7. 医疗诊断与药物研究：深度学习技术在医疗诊断中的应用，可以辅助医生进行更准确的疾病诊断。此外，深度学习技术还可以用于药物研究，帮助科学家更快地发现新药物，从而改善人类健康。<br>8. 金融风控与交易：深度学习技术在金融领域的应用，可以帮助企业进行风险评估和控制，提高交易效率，降低金融风险。<br>深度学习技术已经成为众多领域中的关键技术，对人工智能的未来发展具有深远影响。在后续文章中，我们将更深入地探讨深度学习的原理、算法和实践应用。<br>二、深度学习的发展历程<br>1. 早期的神经网络：神经网络最早可以追溯到上世纪40年代和50年代的简单线性感知器。当时的神经网络仅包含一个输入层和一个输出层，无法进行复杂的任务处理。尽管如此，神经网络的概念为人工智能的发展奠定了基础。<br>2. 反向传播算法的引入：1986年，Rumelhart、Hinton和Williams提出了反向传播算法（Backpropagation）。这一算法通过将误差从输出层传播回输入层来更新神经网络中的权重，使得多层神经网络的训练成为可能。<br>3. 卷积神经网络的出现：1989年，LeCun等人提出了卷积神经网络（ConvolutionalNeuralNetworks,CNN）。卷积神经网络通过卷积操作提取局部特征，具有局部连接、权值共享等特点，适用于图像等高维数据的处理。<br>4. 深度学习的革命：ImageNet比赛与AlexNet：2012年，Krizhevsky、Sutskever和Hinton提出了AlexNet，一种深度卷积神经网络，该网络在当年的ImageNet图像分类比赛中大幅度提高了分类准确率，引发了深度学习领域的革命。<br>5. 循环神经网络与长短时记忆网络：循环神经网络（RecurrentNeuralNetworks,RNN）是一种适用于处理序列数据的神经网络。长短时记忆网络（LongShort-TermMemory,LSTM）作为RNN的一种改进，通过特殊的门结构解决了传统RNN中的梯度消失问题，进一步加强了网络在处理长序列数据时的性能。<br>6. 生成对抗网络的提出：2014年，Goodfellow等人提出了生成对抗网络（GenerativeAdversarialNetworks,GAN），一种基于对抗训练的生成模型。GAN由生成器和判别器组成，通过对抗训练使生成器学会生成逼真的数据。<br>7. 自注意力与Transformer模型：2017年，Vaswani等人提出了Transformer模型，这一模型摒弃了传统的循环神经网络和卷积神经网络结构，完全基于自注意力（Self-Attention）机制。Transformer模型在自然语言处理等领域取得了突破性成果。</p><p>三、深度学习的基本概念<br>1. 人工神经元与激活函数：人工神经元是神经网络中最基本的计算单元，其输入经过加权求和、激活函数等操作后得到输出。激活函数为神经元提供了非线性表达能力，常用的激活函数包括Sigmoid、ReLU、Tanh等。<br>2. 前向传播与反向传播：前向传播是指神经网络从输入层到输出层的信息传递过程，计算网络的预测输出。反向传播则是根据损失函数计算出的误差，从输出层向输入层传播并更新网络权重的过程。<br>3. 损失函数与优化算法：损失函数用于衡量神经网络输出与真实目标之间的差距，如均方误差、交叉熵损失等。优化算法则用于更新神经网络的权重以最小化损失函数，常用的优化算法包括随机梯度下降（SGD）、Adam、RMSprop等。<br>4. 卷积神经网络（CNN）：卷积神经网络是一种深度学习模型，适用于处理图像等高维数据。CNN通过卷积操作提取局部特征，具有局部连接和权值共享等特点，能够有效降低模型参数数量。<br>5. 循环神经网络（RNN）：循环神经网络是一种适用于处理序列数据的神经网络。RNN具有循环连接，能够捕捉序列数据中的时序信息，但在处理长序列时容易出现梯度消失或梯度爆炸问题。<br>7. 长短时记忆网络（LSTM）：长短时记忆网络是RNN的一种改进，通过特殊的门结构解决了传统RNN中的梯度消失问题，能够更有效地捕捉长序列数据中的依赖关系。<br>8. 生成对抗网络（GAN）：生成对抗网络是一种基于对抗训练的生成模型。GAN由生成器和判别器组成，通过对抗训练使生成器学会生成逼真的数据。GAN在图像生成、文本生成等领域表现出强大的能力。</p><p>四、深度学习框架与工具<br>1. TensorFlow：TensorFlow是一个由Google开发的开源深度学习框架，具有高度的灵活性和可扩展性。其核心功能包括：<br>-数据流图（DataFlowGraphs）：TensorFlow使用数据流图表示计算过程，有助于优化计算资源和并行处理。<br>-自动微分：TensorFlow支持自动微分，方便实现梯度下降等优化算法。<br>-多平台支持：TensorFlow支持多种硬件平台，包括CPU、GPU和TPU等。<br>-高级API：TensorFlow提供了Keras作为高级API，使得构建和训练神经网络变得更加简单。<br>2. PyTorch：PyTorch是由Facebook开发的开源深度学习框架，以动态计算图和易用性著称。其核心功能包括：<br>-动态计算图（DynamicComputationGraphs）：与TensorFlow的静态计算图不同，PyTorch支持动态计算图，使得模型结构更加灵活。<br>-自动微分：PyTorch也支持自动微分，方便实现各种优化算法。<br>-多平台支持：PyTorch支持多种硬件平台，包括CPU、GPU等。<br>-简洁易用：PyTorch提供了丰富的API，使得构建和训练神经网络更加简单和直观。<br>3. Keras：Keras是一个高层神经网络API，支持多种后端引擎，如TensorFlow、MicrosoftCognitiveToolkit、Theano等。其核心功能包括：<br>-高级API：Keras提供了简洁的API，使得构建和训练神经网络变得更加容易。<br>-模型复用：Keras支持模型的序列化和反序列化，方便模型的保存和加载。<br>-预训练模型：Keras提供了大量预训练模型，如VGG、ResNet等，可以直接用于迁移学习。<br>4. 其他深度学习框架：此外，还有一些其他的深度学习框架，如Caffe、MXNet等。Caffe是一个由加州大学伯克利分校开发的深度学习框架，以图像处理任务为主。MXNet是由ApacheSoftwareFoundation开发的深度学习框架，支持多种编程语言和硬件平台。<br>5. GPU加速与分布式计算：随着深度学习模型规模的增大，计算需求也在不断提高。GPU加速成为了深度学习领域的关键技术，NVIDIA的CUDA平台为深度学习框架提供了强大的GPU计算能力。此外，英伟达还推出了针对深度学习的专用硬件，如Tesla系列和A100等。分布式计算也成为了深度学习领域的重要技术，可以将计算任务分布在多个计算节点上，从而加速模型的训练和推理过程。TensorFlow和PyTorch等框架都提供了对分布式计算的支持。<br>总结：<br>深度学习是人工智能领域的一个重要分支，近年来取得了显著的成果。从发展历程、基本概念、主要应用、挑战与未来发展趋势、框架与工具等方面，本文对深度学习进行了全面的梳理。深度学习技术在计算机视觉、自然语言处理、语音识别与合成、推荐系统、无人驾驶汽车、游戏智能、生物医学等领域取得了重大突破，为人类生活带来了巨大的便利和价值。<br>五、深度学习的挑战与未来发展<br>1. 计算资源与能耗问题<br>随着深度学习模型的复杂度不断提高，计算资源和能耗问题成为了一个亟待解决的挑战。大型深度学习模型需要大量的计算资源进行训练和推理，而这会导致能源消耗和环境压力的增加。未来，研究人员需要寻找更高效的模型结构和算法，降低模型的计算复杂度，提高计算效率，减少能耗。<br>2. 模型可解释性与透明度<br>深度学习模型的可解释性和透明度是另一个重要挑战。当前的深度学习模型往往被视为“黑盒”，难以理解其内部运作机制。为了建立用户和监管机构的信任，研究人员需要开发新的理论和方法，提高模型的可解释性和透明度。<br>3. 数据偏见与伦理问题<br>深度学习模型的训练和推理依赖于大量数据，然而数据往往存在偏见。这些偏见可能导致模型在应用时产生歧视、不公平等问题。研究人员需要关注数据偏见和伦理问题，开发新的算法和方法，确保模型在应用时能够遵循伦理原则。<br>4. 深度学习在小样本学习、无监督学习、迁移学习等方面的研究进展<br>在小样本学习、无监督学习和迁移学习等方面，深度学习模型还有很大的提升空间。研究人员需要进一步研究这些领域的理论和方法，提高模型在这些场景下的性能。<br>5. 端到端学习与自监督学习的趋势<br>端到端学习是一种直接从原始数据到目标输出的学习方法，减少了人工设计特征和模型结构的复杂性。自监督学习则是一种在无监督数据上进行学习的方法，通过自身的结构和约束来提取有用的特征和知识。这两种方法在未来可能会取得更多的突破，推动深度学习领域的发展。<br>6. 人工智能与深度学习的整合<br>深度学习作为人工智能领域的一个重要分支，在未来可能会与其他人工智能技术更加紧密地整合。例如，深度学习与知识图谱、规划、优化等技术的结合，可以为各种复杂问题提供更智能、更有效的解决方案。此外，多模态学习、跨领域学习等研究方向也将为人工智能与深度学习的整合提供更广泛的应用场景。<br>小结<br>深度学习作为一种强大的机器学习方法，已经在计算机视觉、自然语言处理等领域取得了显著的成果。然而，面临计算资源与能耗、模型可解释性、数据偏见等挑战，深度学习仍有很大的提升空间。在未来，研究人员需要关注这些问题，开发更高效、更可解释、更公平的深度学习方法。同时，深度学习与其他人工智能技术的整合将为解决实际问题提供更多可能性。<br>六、结论<br>1. 深度学习的重要性与应用前景<br>深度学习已经成为人工智能领域的核心技术之一，广泛应用于计算机视觉、自然语言处理、语音识别、推荐系统等多个方面。随着深度学习技术的进一步发展，更多创新应用将不断涌现，改变我们的工作和生活方式。深度学习的前景充满希望，对于个人和企业来说，都具有重要的战略价值。<br>2. 学习深度学习的意义与价值<br>掌握深度学习技术，将有助于解决实际问题，提升个人的职业竞争力。在未来的职业市场中，具备深度学习技能的人才将成为各行各业的热门人选。学习深度学习不仅可以提高你的技术水平，还可以帮助你开拓视野，激发创新思维，为你的职业生涯增色不少。<br>在本专栏的后续文章中，我们将深入探讨深度学习的各种算法原理，如卷积神经网络、循环神经网络、生成对抗网络等。同时，我们还将分享一些深度学习在实际问题中的应用案例，以及如何使用各种深度学习框架进行模型训练与部署。希望大家通过阅读本专栏的文章，能够获得深度学习领域的全面了解，并在实际应用中取得成功。请继续关注我们的专栏，与我们一起探索深度学习的奥秘！</p>]]></content>
      
      
      
        <tags>
            
            <tag> AI算法工程师Future </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>GraphRAG新方向思考：文档为中心的多模态变体及MultimodalDocGraph实现思路</title>
      <link href="/2025/06/23/2648421322-2648421322-1-1750658458/"/>
      <url>/2025/06/23/2648421322-2648421322-1-1750658458/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/UtSjX_D2k-Cp7iJT-CNqtQ">GraphRAG新方向思考：文档为中心的多模态变体及MultimodalDocGraph实现思路</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月23日，星期一，北京，晴<br>我们继续来看GraphRAG的趋势，谈谈自己的一些想法，也是周末的思考，做个分享。</p><p>而到后面，随着文档解析方面工作的陆续开展，针对文档本身可以做的事情越来越多，所以，我们可以进一步提出一个更为成熟的点，叫做文档为中心多模态GraphRAG，底层依赖的知识库叫做MultimodalDocGraph。<br>当然，这个事情很容易做工程实现，所以自然可以看一个工程的实现项目，看了下代码，也看看。<br>为什么要说这个多模态GraphRAG，尤其是面向文档场景，或者以文档为核心的GraphRAG，这是我们在实际落地过程中所遇到的一个难题例子，文档在进行表述时候，图表会作为一个链接元素被引用于文本描述当中，在RAG中常常会出现这类情况：一个问题召回出来的片段里，有xxxxxx,详见表1。这种问题本质上属于多跳情况。<br>所以，如上所述，解决方式，采用与知识图谱Entity-linking的方式，在原文中进行图表的链接。【但不局限于文图，通常还包括reference参考的链接】，这样能够将不同的模态之间联系起来，然后能够找回更为完整的信息，提升RAG检索性能。<br>所以，当时我想，索性是否直接可以有个MultimodalGraphRAG的概念，在Graph的基础上，进一步将Graph中的节点元素扩展到多模态元素。<br>对于具体定义，我们可以定一下：多模态GraphRAG（MultimodalGraphRetrieval-AugmentedGeneration）是一种结合图结构推理、多模态数据融合与检索增强生成的前沿技术，旨在解决复杂场景下的语义理解与生成问题。<br>其核心在于通过图结构显式建模跨模态实体关系，提升RAG的性能，而其中最为重要的是这个是个重点，需要将不同模态的信息组织起来。<br>例如，医学实体“肺癌”关联CT图像、病理报告文本和患者语音描述，在节点类型设计上，可以设计实体节点（如“肺癌”）、属性节点（如“发病率”）、模态节点（如CT图像哈希值）；边类型的设计上，包括语义关系（“治疗”“属于”）、模态关联（“图像描述”“音频注释”）。<br>就拿文档这个场景来讲，其通过解析，可以拿到图片、表格、段落、公式、代码块、参考文献等各式各样的元素，尤其是其中的图片或者公式，其实很自然地就成为了多模态知识库的构建要素，对于图片，可以增加对图片的summary或者caption描述，对于公式也可以进一步解读，对于表格，也可以增加对其结构信息的描述文本。<br>而进一步的，通过将图片、表格、公式等进行文本化后，有可能基于这个做实体抽取跟关系抽取，这样一来，就可以形成一个以文档为核心的多模态知识图谱。</p><p>关系可以是：(例如，张三，媳妇儿，翠花),(铁矿石，belongs_to，铁矿石图片base64),(“赣州是江西的南大门”,related_to,赣州卫星图片base64),(“赣州”,locate_in,“赣州是江西的南大门”)，其中的rel，又可以进一步分成多种，比如层级结构的关系。<br>说到上述的思想，其实是很容易撞车的，很容易想到，并且做出来，但具体效果怎样其实很难讲，但从代码端是很好实现的。<br>这里看一个实现的项目，叫RAG-Anything，https :&#x2F;&#x2F;github. com&#x2F;HKUDS&#x2F;RAG-Anything<br>核心看几个点，看了下代码，讲几点：<br>1、总体结论如何？<br>1）文档处理方式很抽象，不合理，会慢死，有的改；<br>2）多模态图谱构建设计思路不错，考虑的很细，后续可以通过实体获取到图像信息，进而拿到图像描述信息，很好的link思路。但这块会带来很多噪声，因为一个实体会存在多个图像对应关系，后续需要剪枝，这块收益很难讲【图像的收益未知，且依赖于多模态大模型的能力，容易出现幻觉，假设性很强】。<br>3）是个大框架，但很难讲是否有实际用处，可自行测试。<br>2、文档解析的逻辑怎么看？<br>文档解析中，文档处理的的具体执行逻辑其实有点为了统一处理而处理的目的（需要进一步思考）。<br>根据文件类型选择合适的解析器，如果文件是PDF格式，调用MineruParser. parse_pdf方法进行解析。</p><p>如果文件是文本格式（如. txt、.md），也是先转换成PDF，然后调用MineruParser. parse_text_file方法进行解析。<br>3、多模态元素解析流程怎么看？<br>用于处理不同类型的模态内容（如图像、表格、方程等），ImageModalProcessor处理图像内容，需要将图像编码为base64格式；TableModalProcessor处理表格内容，解析表格结构；EquationModalProcessor处理方程内容，解析方程文本。每个模态的prompt都旨在生成一个详细的描述和一个简洁的实体信息。<br>详细描述提供了对内容的全面分析，而实体信息则提供了一个简洁的总结，强调内容的重要性和目的。这些内容将被存储到知识图谱和向量数据库中，以便后续的知识检索和分析。<br>4、chunk切分及图谱构建怎么看？<br>纯文本部分进行实体、关系抽取，构图。多模态部分利用对应要素作为chunk提取实体和关系，然后为每个提取到的实体（entity_name）与“模态实体”（modal_entity_name）建立“属于”关系。<br>最终构成chunk、modal_entity、entity三种实体、,,,4种关系的图谱。<br>文档为中心的多模态GraphRAG及MultimodalDocGraph是个很好的故事，这个可以讲一个比较好的故事，多模态、kg、文档解析、rag都通了。<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>代码RAG第二弹：代码类的GraphRAG怎么做？一个示例项目</title>
      <link href="/2025/06/23/1000001239-2648421306-1-1750651904/"/>
      <url>/2025/06/23/1000001239-2648421306-1-1750651904/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/Ng-XY23k0OlNcqC-PnVnMg">代码RAG第二弹：代码类的GraphRAG怎么做？一个示例项目</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月23日，星期一，北京，晴</p><p>核心点几个：<br>1、怎么做代码切分？<br>chunk阶段基于AST做切分，解析Python文件以提取类、函数、方法及其关系；<br>2、怎么做成知识图谱？<br>存储上，使用Memgraph将代码库结构存储为知识图谱，这里的知识图谱架构设计如下：<br>其中：<br>节点类型包括：项目：代表整个存储库的根节点；包：语言包（Python：__init__. py等）；模块：单独的源代码文件（.py等）.js. ts.rs. go；类：所有语言的类&#x2F;结构&#x2F;枚举定义；功能：模块级功能和独立功能；方法：类方法和相关函数；文件夹：常规目录；文件：所有文件（源代码和其他）；ExternalPackage：外部依赖项</p><p>3、用来做啥？<br>这个主要还是面向基础小白使用，用来做代码分析：<br>如上图，可以支撑的问题如下：<br>“显示所有名称中包含‘用户’的类”、“查找与数据库操作相关的函数”、“User类有哪些方法？”、“显示处理身份验证的函数”、“列出所有TypeScript组件”、“查找Rust结构及其方法”，实际上这个在代码领域，这种用法意义不是很大。<br>4、怎么查？<br>利用GoogleGemini将自然语言翻译成Cypher查询，这里主要依靠prompt实现，例如：<br>1、https :&#x2F;&#x2F;github. com&#x2F;vitali87&#x2F;code-graph-rag<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Agent技术实践：9个MCP工程实践项目指引</title>
      <link href="/2025/06/22/1000001238-2648421295-2-1750558633/"/>
      <url>/2025/06/22/1000001238-2648421295-2-1750558633/</url>
      
        <content type="html"><![CDATA[<p><a href="https://mp.weixin.qq.com/s/nSMIyGjVbAl8JegMT66uHw">Agent技术实践：9个MCP工程实践项目指引</a></p><blockquote><p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p></blockquote><p>今天是2025年6月22日，星期日，北京，晴<br>今天来看看Agent话题，关于9个MCP工程实践项目，尤其是直观图，从可视化的图中观察实际的实现流程，给出的链接里面也有手把手教学的解释，很不错。<br>1、100%localMCPclient<br>100%本地MCP客户端，MCP客户端是人工智能应用程序（例如Cursor）中的一个组件，用于建立与外部工具的连接，学习如何完全在本地构建它。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;building-a-100-local-mcp-client&#x2F;<br>2、MCP-poweredAgenticRAG<br>MCP驱动的代理式RAG，学习如何创建一个MCP驱动的代理式RAG，能够搜索向量数据库，并在需要时回退到网络搜索。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;mcp-powered-agentic-rag&#x2F;<br>3、MCP-poweredfinancialanalyst<br>MCP驱动的金融分析师，构建一个MCP驱动的人工智能代理，能够从Cursor或Claude桌面获取、分析并生成有关股市趋势的见解。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;hands-on-building-an-mcp-powered-financial-analyst&#x2F;<br>4、MCP-poweredVoiceAgentMCP<br>驱动的语音代理，这个项目教你如何构建一个MCP驱动的语音代理，它能够查询数据库，并在需要时回退到网络搜索。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;an-mcp-powered-voice-agent&#x2F;<br>5、AunifiedMCPserver<br>统一的MCP服务器，这个项目构建一个MCP服务器，通过MindsDB和CursorIDE提供的统一界面，使用自然语言查询并与200多个数据源进行聊天。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;build-an-mcp-server-to-connect-to-200-data-sources&#x2F;<br>6、MCP-poweredsharedmemoryforClaudeDesktopandCursor<br>为Claude桌面和Cursor提供MCP驱动的共享内存，开发人员独立使用Claude桌面和Cursor，没有任何上下文共享，学习如何添加一个共同的内存层，以便在不丢失上下文的情况下跨操作。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;build-a-shared-memory-for-claude-desktop-and-cursor&#x2F;<br>7、MCP-poweredRAGovercomplexdocsMCP<br>驱动的复杂文档上的RAG，学习如何使用MCP为具有表格、图表、图像、复杂布局等复杂文档的RAG应用提供动力。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;mcp-powered-rag-over-complex-docs&#x2F;<br>8、MCP-poweredsyntheticdatageneratorMCP<br>驱动的合成数据生成器，学习如何构建一个MCP服务器，它可以生成任何类型的合成数据集。它使用Cursor作为MCP主机，并使用SDV生成逼真的表格合成数据。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;hands-on-mcp-powered-synthetic-data-generator&#x2F;<br>9、MCP-powereddeepresearcher<br>MCP驱动的深度研究，ChatGPT有一个深度研究功能，它可以帮助你深入了解任何主题。学习如何构建一个100%本地的替代品。<br>地址：https :&#x2F;&#x2F;www. dailydoseofds.com&#x2F;p&#x2F;hands-on-mcp-powered-deep-researcher&#x2F;<br>老刘，NLP开源爱好者与践行者，主页：https :&#x2F;&#x2F;liuhuanyong. github.io。<br>对大模型&amp;知识图谱&amp;RAG&amp;文档理解感兴趣，并对每日早报、老刘说NLP历史线上分享、心得交流等感兴趣的，欢迎加入社区，社区持续纳新。<br>加入社区方式：关注公众号，在后台菜单栏中点击会员社区加入。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 老刘说NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微信公众号聚合平台_按公众号区分</title>
      <link href="/2024/08/31/wei-xin-gong-zhong-hao-ju-he-ping-tai-an-gong-zhong-hao-qu-fen/"/>
      <url>/2024/08/31/wei-xin-gong-zhong-hao-ju-he-ping-tai-an-gong-zhong-hao-qu-fen/</url>
      
        <content type="html"><![CDATA[<h2 id="老刘说NLP"><a href="#老刘说NLP" class="headerlink" title="老刘说NLP"></a>老刘说NLP</h2><ul><li><a href="https://mp.weixin.qq.com/s/hzioWalNp5pPbDN05ifpag">6个无代码LLM、Agent、RAG开源工具及推理大模型用于时间序列预测工作</a></li><li><a href="https://mp.weixin.qq.com/s/R-u7N_PheZ6MEPcMjvjAgw">NLP之文本纠错开源大模型：兼看语音大模型总结</a></li><li><a href="https://mp.weixin.qq.com/s/U5W_YYdLAFKJj2JlvdYTNA">再看大模型数据合成开源工具–DataFlow及自然场景文档解析评估问题</a></li><li><a href="https://mp.weixin.qq.com/s/BbT0XCGbjwJ6mXb2EuVyGg">Agent做多模态RAG方案-MDocAgent及文档解析中的图像前处理问题</a></li><li><a href="https://mp.weixin.qq.com/s/v6cIIMALyutu74NDpuLONQ">继续看真实场景下文档解析的8个另外问题：公式输出重复、阅读顺序评测等</a></li><li><a href="https://mp.weixin.qq.com/s/6Pu6PbD5ipPTMQrWZXKpOg">聚焦RAG＆KG＆LLM＆文档解析：老刘说NLP技术社区对外纳新</a></li><li><a href="https://mp.weixin.qq.com/s/SlZhiw6_QbPqpoIQNDN0aQ">Dify落地知识库场景的小思考及多模态RAG结合图像信息的几种策略评估</a></li><li><a href="https://mp.weixin.qq.com/s/YjotrXspCQr2G7C2Y7soog">GraphRAG的索引动态更新解法-分桶+局部更新及“上下文工程”新概念？</a></li><li><a href="https://mp.weixin.qq.com/s/QAV5dTNBbBqeUfMP6qAN5A">落地方案：Cursor的代码库索引及文档解析中的跨页表&#x2F;段落合并实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/HYd2EkU01O3IgQn2ENaEkw">好落地前沿精读：Hunyuan-A13B推理模型、qwen3多尺寸及Jina多模态向量模型</a></li><li><a href="https://mp.weixin.qq.com/s/30eTvYCRFX2CgPsvDXXpfw">落地角度看Agent搭建的稳妥到激进路线及VLLM图片分辨率策略</a></li><li><a href="https://mp.weixin.qq.com/s/TKev6oPft5I1VOlXqHwONQ">技术前沿之Graph+Agent：Chat2Graph如何重构GraphRAG范式？</a></li><li><a href="https://mp.weixin.qq.com/s/e2tDbBVmnqY-TPJ-bx5AGw">Agent做PPT的开源实践：代码端看MultiAgentPPT实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/7TqX0zi8aI-jByetRIISJg">Deep Research现有方案技术总结：实现架构、特点对比、现存问题及未来方向</a></li><li><a href="https://mp.weixin.qq.com/s/NT1WsWVE0lhzsa_87cXwaA">RAG的2025趋势重点及RAG+抽取场景的来源定位问题思考</a></li><li><a href="https://mp.weixin.qq.com/s/UtSjX_D2k-Cp7iJT-CNqtQ">GraphRAG新方向思考：文档为中心的多模态变体及MultimodalDocGraph实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/Ng-XY23k0OlNcqC-PnVnMg">代码RAG第二弹：代码类的GraphRAG怎么做？一个示例项目</a></li><li><a href="https://mp.weixin.qq.com/s/nSMIyGjVbAl8JegMT66uHw">Agent技术实践：9个MCP工程实践项目指引</a></li><li><a href="https://mp.weixin.qq.com/s/N7C-1IRgJYZyyNYiFexC2Q">代码类型的RAG做chunk切分怎么做？兼看改进AST方案</a></li><li><a href="https://mp.weixin.qq.com/s/ZwEj2Kc9Le1uOi1E7EVXJw">表格RAG项目解读：一个过滤+澄清补充的数据工程式思路</a></li><li><a href="https://mp.weixin.qq.com/s/vTmWFO7w9IbJZkTIApFBGA">多模态RAG前沿速读：三看SimpleDoc双线索实现思路</a></li></ul><h2 id="AI算法工程师Future"><a href="#AI算法工程师Future" class="headerlink" title="AI算法工程师Future"></a>AI算法工程师Future</h2><ul><li><a href="https://mp.weixin.qq.com/s/usBgK-O9f2EnwByPPzfgqg">研究生期间准备踏踏实实搞科研？那在这之前有本事先把这本同样踏踏实实的书看完吧。</a></li><li><a href="https://mp.weixin.qq.com/s/JB4vU1d1zNdyZ4SHJAcaVg">这本书可以说是最适合只需要浅尝辄止下机器学习深度学习数学知识的人！！</a></li><li><a href="https://mp.weixin.qq.com/s/ZD7XFt8E_ba-7HFKwEAY9g">看来看去，它依旧是最好的基于Pytorch的深度学习实战书！！</a></li><li><a href="https://mp.weixin.qq.com/s/Ge1njaraXxE_A0Cofy3diw">一文万字带你深刻了解深度学习的基础知识：深度学习的发展历程、基本概念和主要应用！</a></li><li><a href="https://mp.weixin.qq.com/s/-g8Y_ACQXFGZLfKUZur_ug">浙大DAILY实验室打造！入门学习AI大模型的首推书！Github已11k！通义app开发人员盛赞！</a></li><li><a href="https://mp.weixin.qq.com/s/yIxo2MjUpD9hV6GNUolwwA">我宣布！这个系列的深度学习入门书才是真神！！！</a></li><li><a href="https://mp.weixin.qq.com/s/8BGmzXsJ27j-SX5X0LbUFw">「白话解读」小白也能理解！一文让你彻底看懂10大最受欢迎的深度学习神经网络模型！！！</a></li><li><a href="https://mp.weixin.qq.com/s/i7hoTg6cAwt3D6wciHD_fg">百试百灵！硕博五个月从零基础到发出一篇深度学习论文的详细流程分享！25年新方法！</a></li><li><a href="https://mp.weixin.qq.com/s/SOKIGj0QOZn7WXw6w_o28g">这本书简直神！让我轻松掌握了如何使用机器学习方法来处理各种类型的信号数据！！！</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 开源项目 </tag>
            
            <tag> 微信公众号聚合平台 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>微信公众号聚合平台_按时间区分</title>
      <link href="/2024/07/29/wei-xin-gong-zhong-hao-ju-he-ping-tai-an-shi-jian-qu-fen/"/>
      <url>/2024/07/29/wei-xin-gong-zhong-hao-ju-he-ping-tai-an-shi-jian-qu-fen/</url>
      
        <content type="html"><![CDATA[<h2 id="2025-07-06"><a href="#2025-07-06" class="headerlink" title="2025-07-06"></a>2025-07-06</h2><ul><li><a href="https://mp.weixin.qq.com/s/hzioWalNp5pPbDN05ifpag">6个无代码LLM、Agent、RAG开源工具及推理大模型用于时间序列预测工作</a></li></ul><h2 id="2025-07-05"><a href="#2025-07-05" class="headerlink" title="2025-07-05"></a>2025-07-05</h2><ul><li><a href="https://mp.weixin.qq.com/s/R-u7N_PheZ6MEPcMjvjAgw">NLP之文本纠错开源大模型：兼看语音大模型总结</a></li></ul><h2 id="2025-07-04"><a href="#2025-07-04" class="headerlink" title="2025-07-04"></a>2025-07-04</h2><ul><li><a href="https://mp.weixin.qq.com/s/U5W_YYdLAFKJj2JlvdYTNA">再看大模型数据合成开源工具–DataFlow及自然场景文档解析评估问题</a></li><li><a href="https://mp.weixin.qq.com/s/usBgK-O9f2EnwByPPzfgqg">研究生期间准备踏踏实实搞科研？那在这之前有本事先把这本同样踏踏实实的书看完吧。</a></li></ul><h2 id="2025-07-03"><a href="#2025-07-03" class="headerlink" title="2025-07-03"></a>2025-07-03</h2><ul><li><a href="https://mp.weixin.qq.com/s/BbT0XCGbjwJ6mXb2EuVyGg">Agent做多模态RAG方案-MDocAgent及文档解析中的图像前处理问题</a></li></ul><h2 id="2025-07-02"><a href="#2025-07-02" class="headerlink" title="2025-07-02"></a>2025-07-02</h2><ul><li><a href="https://mp.weixin.qq.com/s/v6cIIMALyutu74NDpuLONQ">继续看真实场景下文档解析的8个另外问题：公式输出重复、阅读顺序评测等</a></li></ul><h2 id="2025-07-01"><a href="#2025-07-01" class="headerlink" title="2025-07-01"></a>2025-07-01</h2><ul><li><a href="https://mp.weixin.qq.com/s/6Pu6PbD5ipPTMQrWZXKpOg">聚焦RAG＆KG＆LLM＆文档解析：老刘说NLP技术社区对外纳新</a></li><li><a href="https://mp.weixin.qq.com/s/SlZhiw6_QbPqpoIQNDN0aQ">Dify落地知识库场景的小思考及多模态RAG结合图像信息的几种策略评估</a></li></ul><h2 id="2025-06-30"><a href="#2025-06-30" class="headerlink" title="2025-06-30"></a>2025-06-30</h2><ul><li><a href="https://mp.weixin.qq.com/s/YjotrXspCQr2G7C2Y7soog">GraphRAG的索引动态更新解法-分桶+局部更新及“上下文工程”新概念？</a></li></ul><h2 id="2025-06-29"><a href="#2025-06-29" class="headerlink" title="2025-06-29"></a>2025-06-29</h2><ul><li><a href="https://mp.weixin.qq.com/s/QAV5dTNBbBqeUfMP6qAN5A">落地方案：Cursor的代码库索引及文档解析中的跨页表&#x2F;段落合并实现思路</a></li></ul><h2 id="2025-06-28"><a href="#2025-06-28" class="headerlink" title="2025-06-28"></a>2025-06-28</h2><ul><li><a href="https://mp.weixin.qq.com/s/HYd2EkU01O3IgQn2ENaEkw">好落地前沿精读：Hunyuan-A13B推理模型、qwen3多尺寸及Jina多模态向量模型</a></li><li><a href="https://mp.weixin.qq.com/s/JB4vU1d1zNdyZ4SHJAcaVg">这本书可以说是最适合只需要浅尝辄止下机器学习深度学习数学知识的人！！</a></li></ul><h2 id="2025-06-27"><a href="#2025-06-27" class="headerlink" title="2025-06-27"></a>2025-06-27</h2><ul><li><a href="https://mp.weixin.qq.com/s/30eTvYCRFX2CgPsvDXXpfw">落地角度看Agent搭建的稳妥到激进路线及VLLM图片分辨率策略</a></li></ul><h2 id="2025-06-26"><a href="#2025-06-26" class="headerlink" title="2025-06-26"></a>2025-06-26</h2><ul><li><a href="https://mp.weixin.qq.com/s/e2tDbBVmnqY-TPJ-bx5AGw">Agent做PPT的开源实践：代码端看MultiAgentPPT实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/TKev6oPft5I1VOlXqHwONQ">技术前沿之Graph+Agent：Chat2Graph如何重构GraphRAG范式？</a></li></ul><h2 id="2025-06-25"><a href="#2025-06-25" class="headerlink" title="2025-06-25"></a>2025-06-25</h2><ul><li><a href="https://mp.weixin.qq.com/s/7TqX0zi8aI-jByetRIISJg">Deep Research现有方案技术总结：实现架构、特点对比、现存问题及未来方向</a></li><li><a href="https://mp.weixin.qq.com/s/ZD7XFt8E_ba-7HFKwEAY9g">看来看去，它依旧是最好的基于Pytorch的深度学习实战书！！</a></li></ul><h2 id="2025-06-24"><a href="#2025-06-24" class="headerlink" title="2025-06-24"></a>2025-06-24</h2><ul><li><a href="https://mp.weixin.qq.com/s/NT1WsWVE0lhzsa_87cXwaA">RAG的2025趋势重点及RAG+抽取场景的来源定位问题思考</a></li></ul><h2 id="2025-06-23"><a href="#2025-06-23" class="headerlink" title="2025-06-23"></a>2025-06-23</h2><ul><li><a href="https://mp.weixin.qq.com/s/Ng-XY23k0OlNcqC-PnVnMg">代码RAG第二弹：代码类的GraphRAG怎么做？一个示例项目</a></li><li><a href="https://mp.weixin.qq.com/s/UtSjX_D2k-Cp7iJT-CNqtQ">GraphRAG新方向思考：文档为中心的多模态变体及MultimodalDocGraph实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/Ge1njaraXxE_A0Cofy3diw">一文万字带你深刻了解深度学习的基础知识：深度学习的发展历程、基本概念和主要应用！</a></li></ul><h2 id="2025-06-22"><a href="#2025-06-22" class="headerlink" title="2025-06-22"></a>2025-06-22</h2><ul><li><a href="https://mp.weixin.qq.com/s/nSMIyGjVbAl8JegMT66uHw">Agent技术实践：9个MCP工程实践项目指引</a></li></ul><h2 id="2025-06-21"><a href="#2025-06-21" class="headerlink" title="2025-06-21"></a>2025-06-21</h2><ul><li><a href="https://mp.weixin.qq.com/s/N7C-1IRgJYZyyNYiFexC2Q">代码类型的RAG做chunk切分怎么做？兼看改进AST方案</a></li></ul><h2 id="2025-06-20"><a href="#2025-06-20" class="headerlink" title="2025-06-20"></a>2025-06-20</h2><ul><li><a href="https://mp.weixin.qq.com/s/ZwEj2Kc9Le1uOi1E7EVXJw">表格RAG项目解读：一个过滤+澄清补充的数据工程式思路</a></li></ul><h2 id="2025-06-19"><a href="#2025-06-19" class="headerlink" title="2025-06-19"></a>2025-06-19</h2><ul><li><a href="https://mp.weixin.qq.com/s/vTmWFO7w9IbJZkTIApFBGA">多模态RAG前沿速读：三看SimpleDoc双线索实现思路</a></li><li><a href="https://mp.weixin.qq.com/s/-g8Y_ACQXFGZLfKUZur_ug">浙大DAILY实验室打造！入门学习AI大模型的首推书！Github已11k！通义app开发人员盛赞！</a></li></ul><h2 id="2025-06-18"><a href="#2025-06-18" class="headerlink" title="2025-06-18"></a>2025-06-18</h2><ul><li><a href="https://mp.weixin.qq.com/s/yIxo2MjUpD9hV6GNUolwwA">我宣布！这个系列的深度学习入门书才是真神！！！</a></li></ul><h2 id="2025-06-16"><a href="#2025-06-16" class="headerlink" title="2025-06-16"></a>2025-06-16</h2><ul><li><a href="https://mp.weixin.qq.com/s/8BGmzXsJ27j-SX5X0LbUFw">「白话解读」小白也能理解！一文让你彻底看懂10大最受欢迎的深度学习神经网络模型！！！</a></li></ul><h2 id="2025-06-13"><a href="#2025-06-13" class="headerlink" title="2025-06-13"></a>2025-06-13</h2><ul><li><a href="https://mp.weixin.qq.com/s/i7hoTg6cAwt3D6wciHD_fg">百试百灵！硕博五个月从零基础到发出一篇深度学习论文的详细流程分享！25年新方法！</a></li></ul><h2 id="2025-06-12"><a href="#2025-06-12" class="headerlink" title="2025-06-12"></a>2025-06-12</h2><ul><li><a href="https://mp.weixin.qq.com/s/SOKIGj0QOZn7WXw6w_o28g">这本书简直神！让我轻松掌握了如何使用机器学习方法来处理各种类型的信号数据！！！</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> 开源项目 </tag>
            
            <tag> 微信公众号聚合平台 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
