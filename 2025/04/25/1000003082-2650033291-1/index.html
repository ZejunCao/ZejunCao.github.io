<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Google首席科学家万字演讲回顾AI十年：哪些关键技术决定了今天的大模型格局？, ZejunCao&#39;Blogs">
    <meta name="description" content="Google首席科学家万字演讲回顾AI十年：哪些关键技术决定了今天的大模型格局？

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

来源：数字开物Google首席科学家JeffDean今年4月于在苏黎世联邦理工学院发表关">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Google首席科学家万字演讲回顾AI十年：哪些关键技术决定了今天的大模型格局？ | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000003082_2650033291_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Google首席科学家万字演讲回顾AI十年：哪些关键技术决定了今天的大模型格局？</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                <span class="chip bg-color">人工智能学家</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-04-25
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/O3qbcryl2A7dsj2e6bADXw">Google首席科学家万字演讲回顾AI十年：哪些关键技术决定了今天的大模型格局？</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>来源：数字开物<br>Google首席科学家JeffDean今年4月于在苏黎世联邦理工学院发表关于人工智能重要趋势的演讲，本次演讲回顾了奠定现代AI基础的一系列关键技术里程碑，包括神经网络与反向传播、早期大规模训练、硬件加速、开源生态、架构革命、训练范式、模型效率、推理优化等。算力、数据量、模型规模扩展以及算法和模型架构创新对AI能力提升的关键作用。<br>以下是本次演讲实录<br>经数字开物团队编译整理<br>01<br>AI正以前所未有的规模和算法进步改变计算范式<br>JeffDean:<br>今天我将和大家探讨AI的重要趋势。我们会回顾：这个领域是如何发展到今天这个模型能力水平的？在当前的技术水平下，我们能做些什么？以及，我们该如何塑造AI的未来发展方向？<br>这项工作是与Google内外的众多同仁共同完成的，所以并非全是我个人的成果，其中许多是合作研究。有些工作甚至并非由我主导，但我认为它们都非常重要，值得在此与大家分享和探讨。<br>我们先来看一些观察发现，其中大部分对在座各位而言可能显而易见。首先，我认为最重要的一点是，机器学习彻底改变了我们对计算机能力的认知和期待。回想十年前，当时的计算机视觉技术尚处初级阶段，计算机几乎谈不上拥有“视觉”能力。语音识别虽然可用，但效果远非理想。而基于语言模型的语言理解能力也相当有限。然而，在过去的12到14年间，我们持续观察到一个现象：用于训练模型的计算资源、数据量以及模型规模的不断扩大，通常能带来更好的性能。这几乎成了一条定律，在过去15年里我们反复验证了这一点：更大的模型、更多的数据，确实能提升计算机在我们所关心的核心能力上的表现。<br>此外，算法和模型架构的改进也至关重要。这并非仅仅是简单地投入更多硬件资源的问题。事实上，在过去十年中，算法与模型架构层面的创新所带来的影响，甚至超过了硬件本身的进步。最后，这一切发展共同导致的结果是：我们期望在计算硬件上运行的计算类型正在发生深刻变化。我们对于如何构建计算硬件以支持当前及未来的应用场景的思考方式，也正在从传统的以CPU为中心的计算模式发生转变。<br>首先，我将快速浏览一系列关键技术进展。<br>02<br>关键技术里程碑：奠定现代AI模型的基础<br>JeffDean:<br>显然，源自上世纪的一项关键基础技术是神经网络。当前在最大规模的机器学习以及我们所见的计算机能力方面的几乎所有进展，都基于神经网络计算。这些网络由人工神经元构成。它们的设计在某些方面借鉴了生物神经元的工作机制，但即便以我们目前对生物神经元的理解来看，人工神经元也只是对其非常粗糙的模拟，而且生物神经元的很多机制我们仍未完全理解。尽管如此，它们仍是构成现代AI的基础模块之一。<br>另一项关键技术是反向传播，它是一种优化神经网络权重的方法。通过将模型实际输出与期望输出之间的误差进行反向传播，该算法能够有效地更新神经网络的权重，以最小化模型在训练数据上的错误。然后，得益于神经网络的泛化能力，模型就能推广应用于它在训练过程中未曾见过的那些问题或具体样本。所以说，反向传播和神经网络这两项技术，确实是深度学习革命的核心要素。<br>在2012年，我和几位同事进行了一项研究，核心理念是：如果我们能训练出规模空前的大型神经网络，其性能或许会远超小型网络。基于这个假设，我们决定尝试使用无监督学习算法来训练一个超大规模的神经网络。我们最终训练出的这个网络，其规模大约是2012年已知最大神经网络的60倍，动用了16,000个CPU核心。当时，我们的数据中心里还没有GPU，只有大量常规的CPU服务器。我们观察到，采用这种无监督学习方法进行预训练，再结合一些监督学习进行微调后，模型在相对而言竞争不算非常激烈的ImageNet22k分类任务上，实现了高达70%的性能相对提升。大家平时听到的ImageNet结果大多是基于其1000个类别的子集。而22k这个版本可能更有意思，因为它包含了22,000个极为细粒度的类别。这项成果是一次相当显著的进步，也印证了我们的初始假设：只要投入足够的训练算力，更大规模的模型确实能拥有更强的能力。<br>我们开发了首个大规模神经网络训练基础设施项目，名为Disbelief(DISTbelief)。这个名字一方面因为它是分布式系统，计算任务分布在多台机器上执行；另一方面也因为当时我们的一些同事对其可行性持怀疑态度，算是个双关语。实际上，当你训练这类大型模型，且模型大到单台计算机无法容纳时，存在几种并行化计算的思路。第一种是模型并行：神经网络通常包含许多层神经元，可以将模型按层(水平)或层内(垂直)进行切分，将模型的不同部分部署到不同的计算节点上，并在节点间管理因模型切分产生的通信需求。另一种方式是数据并行：即在不同机器(或机器组)上部署模型的多个副本，并将训练数据分配给不同的模型副本进行处理。这种方式还可以与模型并行结合使用(即每个模型副本本身就分布在多台机器上)。<br>在Disbelief系统中，我们采用了一个集中式的架构：一个参数服务器负责接收来自不同模型副本计算出的梯度更新，并将这些更新应用到全局模型参数上。但我们采用了一种并非严格遵循数学最优化的方式，即完全异步的更新机制。具体来说，不同的模型副本获取最新的参数副本，处理一小批数据，计算出相应的梯度，然后将其发送回参数服务器。然而，当某个副本的梯度到达服务器时，全局参数可能已经被其他副本在此期间提交的梯度更新过了。这种做法显然不符合标准梯度下降算法的数学要求，但实践证明这种方法是有效的。正是这种方法使我们能够，即使用CPU也能将模型训练扩展到非常大的规模。<br>2013年，我们利用Disbelief框架，大规模训练了一种名为Word2Vec的词嵌入模型，旨在生成词语的密集向量表示。这项工作的一个重要成果是，通过将词语表示为高维向量，若采用特定的训练方法，这种向量表示会展现出两种非常有用的特性。其中一种训练方法是利用中心词的向量表示来预测其上下文中的词语。另一种方法则相反，利用上下文词语来预测中心词。两种方法的效果大致相当。<br>当以这种方式训练得到词嵌入向量后，你会发现这些高维向量表示具有两大特性。首先，经过大规模语料训练后，在这个高维向量空间中，语义相近的词语其向量表示也趋于邻近。就好像所有与‘猫科动物’(如猫、美洲狮、老虎)相关的词都被聚集到了这个(比如)一千维空间中的某个区域。其次，更有趣的是，向量空间中的方向具有了语义意义。例如，从代表‘国王’的向量到代表‘王后’的向量，其向量差与从‘男人’到‘女人’或从‘公牛’到‘母牛’的向量差，它们的方向大致相同。这意味着有趣的语言学规律或关系，通过向量间的方向关系，在训练过程中自发地涌现出来。<br>2014年，我的三位同事IlyaSutskever、OriolVinyals和QuocLe开发了一种基于神经网络的序列到序列学习模型。其核心思想是处理一个输入序列(例如文本、语音)，并生成一个对应的输出序列。一个典型的应用场景就是机器翻译：例如，模型首先通过编码器逐词读取输入的英文句子，从而构建出一个概括整个句子信息的密集向量表示(通常称为上下文向量)。接着，模型利用这个上下文向量，通过解码器开始逐词生成(解码)对应的法文句子。通过在大量的英法平行句对语料上进行训练，模型就能学会如何完成翻译任务，这完全是基于这种端到端的序列到序列神经网络架构。将编码器生成的上下文向量作为解码器的初始状态，这种方法被证明是有效的。并且随着所使用的LSTM(长短期记忆网络)规模的增大，实验表明，模型的翻译性能也随之提升。<br>大约在2013年，我开始担忧起来，因为随着我们为语音、视觉以及某种程度上的语言构建越来越大的神经网络，我开始进行一些演算：如果语音识别的效果变得更好，人们可能会广泛使用它。而如果我们想为系统中的大量用户提供服务，这可能会带来问题。所以我做了一个非常粗略的估算：假设我们有1亿用户开始每天对着手机说话三分钟。那时，模型的规模很大，无法在设备端运行，必须部署在我们的数据中心。我发现，部署一个更优的语音模型——当时我们确实有一个更好的模型，能将错误率降低40%，这对于语音识别来说是巨大的性能提升——会遇到困难。我们知道，如果能将这个模型服务于众多用户，效果会更好。但是，我的计算结果显示，对于1亿用户，每人每天使用三分钟，我们需要将Google当时拥有的计算机数量翻倍，才能支持这项语音识别模型的改进，而这仅仅是我们众多产品中的一项改进而已。<br>于是，我开始与我们技术基础设施团队中具备硬件专业知识的同事交流，我们一致认为，为神经网络推理构建更定制化的硬件是合理的。这就是TPU系列的由来。其最初的版本是专门为推理场景设计的。因此，它使用了非常低的精度，其乘法器仅支持8位整数运算。但其核心目标是构建一个在低精度线性代数方面表现卓越的计算单元，它将能高效服务于多种基于神经网络的模型，并且不需要现代CPU中那些使设计变得复杂化的附加特性，例如分支预测器或各种类型的缓存。相反，我们可以专注于构建尽可能快、尽可能小的低精度密集线性代数计算单元。事实证明，一个规模相当大的团队最终研发出的TPU，在处理这类任务时，比同期的CPU和GPU快15到30倍，同时能效提升了30到80倍。顺便提一下，这篇介绍TPU的论文现在是ISCA50年历史上被引用次数最多的论文，考虑到它在2017年才发表，这一点相当了不起。但这确实开启了我们为机器学习模型探索专用计算硬件的征程。<br>接着，我们认为，扩大部署规模并同时关注训练场景，而不仅仅是推理，将非常有意义。因此我们开始构思一种系统，更确切地说，是类似机器学习超级计算机的系统。这些系统在大量芯片之间具备极高速的互连，所有芯片都通过这种定制的高速互连紧密地连接起来。至今，我们已经推出了五代TPUPods，它们在推理和训练两方面都表现优异。这些Pods将数千个芯片连接起来。初代Pod包含256个芯片，随后扩展到1,000个，再到4,000个，而最新的Pod则集成了大约8,000或9,000个芯片，所有这些芯片都通过定制的高速网络连接。从TPUv4开始，这些系统采用了一种非常独特的光网络。利用巧妙的光交换技术和镜面调整，即使两个各包含64个芯片的机架在数据中心机房地面上物理位置并不相邻，也能让它们在网络拓扑上如同紧挨着一样。关于这些技术的细节，大家可以查阅那篇ISCA论文。<br>我们上周刚刚发布了该系列的最新版本，代号Ironwood，我们不再使用数字序号命名，这有时会让我搞混。IronwoodPod的规模相当大，包含9216个芯片，每个芯片的算力可达4614TFLOPS。因此，单个Pod的总算力达到了42.5TFLOPS，这是指低精度浮点运算能力，具体来说是8位浮点精度。这相较于上一代产品是一个显著的飞跃。与2018年的首个训练Pod相比，IronwoodPod的计算能力在大约七年的时间里提升了约3600倍。<br>而且重要的是，通过许多巧妙的电路设计、采用更先进的制程工艺以及使用比初代TPUV2更低精度的运算，与2018年的首个训练Pod相比，我们实现了每浮点运算能效大约30倍的提升。<br>另一个非常重要的趋势是，机器学习领域的开源工具极大地促进了一个更广泛的社区参与进来，不仅改进这些工具本身，还利用它们来解决横跨众多不同学科的、各式各样的机器学习问题。例如TensorFlow、PyTorch以及JAX(Google开发的另一款开源框架，略带函数式编程风格，大约在2017或2018年推出)。我认为，这三个软件包在提升机器学习技术的易用性、以及在不同框架内实现算法表达方式标准化方面，极大地推动了整个领域的进步。<br>在2017年，我的几位同事有了一项非常重要的发现。在循环模型中，处理过程是高度序列化的：模型一次处理一个Token，更新其内部状态，然后才能处理下一个Token。这种固有的顺序性极大地限制了模型处理大规模数据时的并行能力和学习效率。因此，他们提出了一个巧妙的想法：不再采用这种逐步推进并更新单一内部状态的方式，而是保存处理过程中产生的所有内部状态。然后，引入一种称为注意力的机制，该机制允许模型在处理后续Token时，能够回顾并“关注”所有先前处理过的Token的状态。例如，当处理第117个Token时，模型可以访问并权衡前117个Token对应的所有状态，判断哪些状态中的表征信息与当前任务(通常是预测下一个Token)最相关。<br>这篇提出Transformer模型的论文产生了巨大的影响。其影响力巨大的部分原因在于，研究者们最初在机器翻译任务上证明了：相比当时最先进的LSTM或其他模型架构，Transformer仅需1&#x2F;10到1&#x2F;100的计算量和1&#x2F;10的模型大小，就能取得更优的性能。需要注意的是，性能对比图通常采用对数刻度，因此图上看似微小的差距，实际代表着性能上的巨大提升。<br>所以，这项工作极其重要。如今几乎所有备受关注的现代大语言模型，都以Transformer架构或其变体作为基础模型。<br>大约在2018年，一种理念开始变得非常流行(尽管可能并非始于当年)：即大规模语言建模可以利用自监督数据来完成。以任意一段文本为例，我们可以利用文本的一部分来预测其另一部分。通过这种方式，文本本身就提供了“正确答案”，从而产生了海量的训练数据。这已经被证实是极其有效的，并且是现代语言模型性能如此强大的主要原因之一：我们可以不断地输入更多文本数据进行训练，从而持续提升模型质量。<br>目前主要有两种训练目标。第一种是自回归目标：模型根据已有的单词前缀来预测下一个单词。当前许多流行的模型都采用这种形式。这种方式可以从文本中生成大量的训练任务，例如给定“苏黎世是”，预测下一个词；给定“苏黎世是那个”，预测下一个词；给定“苏黎世是最大的”，预测下一个词。模型需要利用其看到的左侧上下文信息来预测缺失的单词。<br>另一种是类似完形填空的训练目标(有时称为掩码语言模型,MaskedLanguageModel)。例如，从“苏黎世是瑞士最大的城市”中生成训练样本“苏黎世[空白]，最大的[空白]在[空白]”。同一个句子还可以生成不同的训练样本，让模型填充不同的空白，比如“苏黎世是那个[空白]城市，[空白]瑞士”。<br>这两种训练目标都非常有用。但自回归目标往往应用更广，因为它更符合某些应用场景的自然流程，例如在操作聊天机器人进行对话时。在这种场景下，模型只能根据已经发生的对话内容(左侧文本)来生成接下来的回应，未来的对话(右侧文本)尚未发生，是未知的。<br>2021年，我的另一些同事开发出一种将图像处理任务整合进基于Transformer模型框架的方法。在此之前，处理图像任务的主流方法是使用各种形式的卷积神经网络(CNN)。他们的核心思路是：首先将图像分割成多个小块。然后，借鉴Word2Vec将单词嵌入为密集向量表示的思想，将这些图像像素块也通过类似方式转换成高维向量来表示。这些图像块嵌入的具体内容，例如颜色、纹理、方向等特征，是通过模型学习得到的。一旦获得了图像块嵌入，就可以将它们输入到标准的Transformer模型的后续层进行处理，就像处理词嵌入一样。这样，原本主要用于文本的Transformer模型就能处理图像数据了。<br>正如稍后将提到的，在训练多模态模型时，这种方法可以很自然地融合文本和图像信息。模型可以同时接收文本Token和图像块作为输入。视觉模型负责生成图像块的嵌入，而文本模型(或其早期部分)负责生成文本Token的嵌入，然后将这些不同来源的嵌入一起送入Transformer进行处理。通过可视化注意力操作，我们可以观察到，当模型被要求描述图像内容时(例如识别图中的飞机或狗)，其注意力机制确实会聚焦于图像中的相关区域。而当图像内容比较复杂或模糊时(例如图中有一条蛇混杂在很多干扰物中)，注意力会变得不那么集中，模型会审视图像的更广泛区域以寻找判别性的视觉线索。这项工作对于统一基于Transformer的文本处理和图像处理框架起到了至关重要的推动作用。<br>另一项创新是，在2017年，我和一些同事开发了一种构建稀疏模型的方法，特别是混合专家模型(MoE)。其核心思想是构建一个容量极大的模型，但在处理每个Token或样本时，并不激活整个模型，而是只激活其中一小部分——即所谓的“专家”。例如，在我们最初的论文中，模型每层有多达2048个专家，但每次只激活其中的两个。这样做的好处是，模型拥有巨大的潜在容量来存储和利用大量知识，但计算开销却相对较低。选择激活哪些专家的决策过程本身也是通过反向传播进行端到端学习的。这使得模型能够发展出功能专门化的专家，例如，有些专家可能擅长处理日期和时间，另一些专家擅长处理地理信息，还有一些则可能专注于生物学相关的上下文。<br>事实证明，这种方法非常有效。与Transformer带来的改进类似，MoE实现了显著的算法优势：在达到相同准确率的前提下，所需的训练计算成本大约降低了8倍(如图中的线A所示)；或者，在消耗相同训练成本的情况下，可以获得更高的准确率(如图中的线B所示)。通常，在解读这类展示计算预算与准确率得分关系的图表时，进行水平比较可以看出：达到相同的准确率需要减少多少计算量(效率提升)。而进行垂直比较则可以看出：在相同的计算量下，模型的质量能提升多少(效果提升)。<br>我们持续在稀疏模型上投入了大量工作，因为我们认为这是一个非常重要的整体方向：拥有这些性能优越、容量庞大的模型，但实际运行时可能只激活模型中1%、2%或5%的参数。<br>2018年，我们开始思考能为这些大规模分布式机器学习计算提供哪些更好的软件框架。我们清楚需要训练更大规模的模型。图示的这些带有黄点的小方块，可以看作是一个TPUpod。我们希望能够训练这样一个模型：在软件层面连接许多TPUpod，并依赖底层的分布式系统来管理芯片间所需的通信机制。例如，当同一个小方块内的两个黄色芯片需要通信时，它们会使用极高速的TPU网络。当左上角方块中的芯片需要与同一栋建筑内某个pod中的芯片通信时，则会使用该建筑内的数据中心网络。如果需要跨建筑通信，就会用到同一数据中心设施内连接不同建筑的网络。甚至可以通过更大范围的广域网链接(如图中那个大的橙红色箭头所示)将不同区域的TPUpod连接起来。这种优秀的、可扩展的软件能够简化大规模计算的执行过程。事实上，Pathways为机器学习开发者或研究人员提供的抽象层特点之一在于：你只需要一个单一的Python进程。JAX本身引入了设备的概念。通常，如果你只在一台包含四个TPU芯片的机器上运行，JAX会视其为一个拥有四个芯片的进程。但是，当你通过Pathways运行JAX时，整个训练任务中的所有芯片对JAX而言都会呈现为统一的设备。这样一来，开发者面对的仍是单一的Python进程，但其底层仿佛是一个包含成千上万（例如10,000或20,000个）TPU设备的庞大资源池。你可以在这个资源池上运行计算，Pathways则负责将这些计算任务映射到实际的物理设备上执行。<br>就在上周，我们将内部使用了大约六年的Pathway系统，正式向云客户开放，供使用我们云TPU产品的客户使用。<br>我的一些同事还有另一项观察：在推理时进行更深入的思考（或增加计算步骤）非常有益。这就像小学三年级数学老师要求学生解答问题时要“写出演算过程”一样，因为这样更有可能按正确的顺序执行步骤，从而正确地解决问题。事实证明，大语言模型也是如此。如果你只给模型一个简单的示例问题，比如：“Shawn有5个玩具，圣诞节他从妈妈和爸爸那里各得到了2个，现在他有多少个玩具？”答案是9。这是输入中的单样本示例。然后，你问模型一个新问题：“John照顾10只狗，每只狗每天需要半小时散步和处理排泄。他每周花多少小时照顾狗？”模型在这个问题上给出了错误的答案50。但是，如果你通过在给出的示例问题中明确展示解题步骤来鼓励模型“展示其思考过程”，就像这样：“Shawn开始有5个玩具。如果他从妈妈和爸爸那里各得到2个玩具，那么他就多了4个玩具。5+4&#x3D;9，所以答案是9。”这看起来很简单，但事实证明，这种方式极大地提高了模型的准确性，因为模型被鼓励去思考解题的每一个步骤，从而以更细化的步骤解决问题。<br>可以看到，随着模型规模的增大，如果只使用标准提示，解题准确率会有所提高，但如果使用思维链提示，准确率则会显著提升。这项结果是基于一个大致相当于八年级数学水平问题的基准测试得出的。因此，提示模型展示思考过程能够提高其在推理任务上的准确性。这也可以看作是一种增加推理阶段计算量的方法，因为模型现在需要生成额外的Token来展示中间步骤，直至得出最终格式的答案。<br>2014年，JeffHinton、OriolVinyals和我共同开发了一种称为知识蒸馏的技术，其核心思想在于“蒸馏神经网络中的知识”。其思路是：你有一个性能优越的大模型(教师模型)，并希望将其知识迁移到另一个不同的模型中，通常是迁移到一个更小的模型(学生模型)里。训练小模型的典型方式是执行下一个Token预测任务。假设你看到的前缀是“performtheconcertofor[空白]”，而正确的下一个词是“violin”。你可以用这个目标来训练你的语言模型：如果模型正确预测‘violin’，效果就很好；如果猜错了，则会基于训练目标产生反向传播误差。这种方法效果尚可。但如果能利用教师模型，让它不仅告诉你正确答案(“violin”)，还能提供一个概率分布，指明它认为在当前语境下哪些词是更合理的答案(例如，violin0.4,piano0.2,trumpet0.01,而airplane的概率极低——“Concertoforairplane”几乎不可能)，那么你就能获得更丰富的训练信号。回顾原始训练方式中的损失函数或目标设定：对于“violin”这个正确答案，目标向量仅在对应‘violin’的位置为1，其余皆为0(硬目标)。而蒸馏法则能提供一个更丰富的概率分布(软目标)。这种极为丰富的梯度信号使我们能在小模型的每个训练样本中注入更多知识，从而使其能够更快地收敛。以一个基于语音识别的对比实验为例，我们关注的核心指标是测试帧准确率，即模型是否正确预测了音频帧中的声音，同时也会考察训练帧准确率。使用全部训练数据的基线模型，其测试帧准确率达到58.9%。如果我们将训练集缩减到仅有3%的数据，训练帧准确率反而会上升，因为模型对这极小部分数据产生了过拟合。但此时，测试帧准确率会急剧下降，因为过拟合的模型在未见过的新测试样本上表现不佳。然而，如果我们使用蒸馏过程产生的软目标来训练，并且同样只用3%的训练数据，结果显示，其训练帧准确率相当不错，并且测试帧准确率几乎与使用全部数据训练的模型持平！这是一个极佳的特性，因为它意味着可以将大型神经网络的知识有效迁移至小型神经网络，使小模型的性能几乎能与大模型媲美。这篇关于蒸馏的论文曾被NeurIPS2014拒绝。我们后来在一个研讨会上发表了它，并上传到了arXiv，如今它已有24,000次引用。所以，这个结果相当不错。<br>2022年，我和一些同事研究了在TPUpod上映射计算任务以实现高效推理的不同方法。其中涉及多种可选策略变体。例如，是将权重固定在网络的一个维度上）？还是将权重同时固定在两个维度上，使其分布于二维处理器网格中？或是将权重收集起来，传输到计算所需的单元？具体的技术细节并非关键，重点在于存在多种不同的实现路径。事实上，如何选择最优策略取决于诸多因素。批处理大小便是一个关键影响因素，它极大地影响了不同策略的优劣。同时，延迟约束也是重要的考量点。我们探讨了几种技术，例如：WeightStationary、XWeightGathered、XYWeightGathered，甚至还有XYZWeightGathered。图表底部的小点线展示了不同批处理大小下的最优策略。可以看到，最优策略随批处理大小变化而变化。这也意味着，根据你选择的策略，硬件的浮点运算单元利用率也会相应改变，而最优策略的选择又取决于批处理的大小。对于极小的批处理，最优策略是2DWeightStationary——哦抱歉我说反了，应当是小批次采用2DWeightStationary，大批次则采用2DWeightGathered。这表明，在模型分区、推理执行以及规模化部署方面，存在着诸多复杂的权衡与选择。<br>2023年，我的一些同事开发了一种称为推测解码的技术。其核心思路是利用一个小型“草稿模型”，其规模通常比目标大模型小10到20倍。这种方法基于一个前提：许多Token的预测对于小模型而言相对容易。因此，借助这个极小的草稿模型进行顺序预测，其速度远超直接使用大模型。其具体流程是：首先，用小模型预测后续的K个Token。接着，让大模型也对这K个Token进行一次性预测。若小模型预测的前n个Token（n≤K）与大模型的预测结果一致，便可以直接采纳这n个Token，将生成过程向前推进n步。本质上，若仅使用那个庞大且缓慢的大模型，它将按部就班地逐个Token进行预测。但采用推测解码后，可以看到草稿模型能快速地一次性预测四五个词，随后由大模型进行验证和修正预测。只要草稿模型生成的Token序列与大模型的验证结果相匹配，解码过程就能一次性前进多个Token。通过让大模型一次性处理K个Token的预测，实际上是分摊了加载模型权重所需的内存开销，因为单次权重加载支撑了K个Token的预测，而非仅仅一个Token。<br>03<br>驱动模型进步的综合因素<br>JeffDean:<br>模型质量的显著提升，是多种因素共同作用的结果。更好的加速器硬件功不可没，无论是TPU还是近年来针对机器学习应用大幅改进的NVIDIAGPU。软件框架至关重要，它提供了良好的层次结构，使开发者能专注于性能和抽象本身，上层开发者则可基于此构建实用功能，无需过多关注底层细节。模型架构同样进步巨大，尤其是在Transformer、视Transformer和MOE模型方面，这些已在最先进的模型中广泛应用。训练算法层面，无监督学习、自监督学习、异步训练、蒸馏等技术不断发展。模型预训练后的监督微调，以及基于人类反馈或其他计算反馈的强化学习(RL)，也都是极其重要的方面。此外，思维链、推测解码和推理时间计算扩展等技术，在当今时代均扮演着关键角色。<br>04<br>Gemini项目构建领先的多模态模型<br>JeffDean:<br>在此介绍我们持续训练的Gemini模型，以及这些创新技术在Gemini各版本中的应用。Gemini项目由GoogleDeepMind、GoogleResearch及Google其他部门协作发起。我们于2023年2月启动，旨在训练全球最强的多模态模型，并应用于Google的各项服务。这些模型能以多种方式助力Google的产品，并通过我们的云API对外开放。自2023年2月以来，我们取得了一系列进展：2023年12月发布Gemini1.0，随后不久发布Gemini1.5，并持续推出新版本。<br>我们从一开始就致力于打造多模态模型，因为我们认为纯文本模型的功能局限，不如能理解语言、视觉输入、音频并能生成这些内容的模型实用。早期版本虽不能生成音频输出，但可接收音频、视频、图像和文本输入，并生成图像和文本输出。后续版本已增加生成音频输出的能力。<br>Gemini1.5引入了极长的上下文长度，允许用户输入长达数百万Token的内容。例如，一份千页文档约等于一百万Token，这意味着可以将50篇研究论文、一本很厚的书或多本书同时放入模型的上下文窗口。对于采用注意力机制的Transformer模型而言，输入数据信息呈现清晰是一大优势，使模型能更有效地提取信息、总结和推理，其能力远超处理其他类型数据。<br>Gemini2.0等模型构建于众多创新技术之上。我们使用TPU，利用pathways架构进行跨数据中心训练(覆盖不同城市区域)，并结合JAX框架。词语和图像数据的分布式表示极为重要。同时，Transformer模型、稀疏专家混合技术和蒸馏技术也得到应用，此外还融合了许多其他技术，共同构成了我们的模型训练与服务方案。<br>大约一个月前发布的Gemini1.5Pro是我们的最新模型，因其在多个基准测试中取得显著进步而广受好评，其编码能力相较于之前的Gemini模型大幅提升。由LMArena(一个伯克利附属的研究生团队组织)运营的平台可用于比较不同模型的质量。用户输入提示后，平台随机选择两个后台模型生成响应，并匿名展示给用户选择偏好，由此进行大语言模型间的“头对头”比较。通过上万次此类用户选择，可以相当准确地评估模型的相对实力(至少反映了LMArena用户的偏好)。这种评估方式十分有效，与模型的实际能力高度相关。Gemini1.5Pro因此在Elo评分上较我们之前的模型有了显著提高。<br>Gemini1.5Pro在网络上的众多独立评估中表现优异，并在一些偏学术的基准测试中取得佳绩。(我们在《纽约时报》的Connections游戏上表现尚需努力。)这些排行榜涵盖了编码、数学、多模态能力等广泛领域。我们致力于打造在众多不同领域都表现出色的通用模型。<br>用户对这款模型普遍满意，虽然有些评价或有溢美之词，但用户的喜爱是显而易见的。<br>特别地，其长上下文处理能力对编码任务极为有益，加之模型推理能力的显著增强。百万甚至两百万Token的上下文使得庞大的代码库能完整放入上下文窗口，允许模型执行复杂任务，如代码重构或引入具有特定功能属性的新特性。这也使得处理其他类型数据成为可能。例如，一位用户输入了包含1000首诗歌的数据集(23万Token)，并提出一系列需基于所有诗歌进行推理的问题，模型出色的表现令用户印象深刻，因为这类任务确有难度。<br>我们高度关注的一个指标是来自LMArena平台的Elo分数(Y轴)，分数越高代表用户评价中模型的能力越强、质量越高。X轴表示不同商业模型的成本。理想的模型应位于图表右上角区域。我们提供一系列不同质量与成本权衡的模型。例如，Flash模型价格较低，约每百万Token15美分。最新的Gemini1.5Pro模型因计算量更大、运行成本更高而相对昂贵，但其质量使其性价比依然很高。我们致力于在质量与成本的帕累托前沿(Paretofrontier)提供多样化选择，并持续推动模型向图表右上角区域发展。<br>05<br>Gemini的组织与技术实践<br>JeffDean:<br>关于我们的组织方式：Gemini是一个规模庞大的项目。Gemini1.5论文的作者列表很长，足以体现其大规模团队协作的性质，每位成员都贡献卓著。我们面临的挑战是如何构建高效的团队结构，确保众多成员能为一个模型项目有效贡献力量。<br>我们采用的策略之一是设立不同领域方向，成员大致归属其一。有人专注于预训练过程，有人负责数据，有人负责安全，有人负责评估。这并非严格界限，成员通常对某些领域有更强的归属感。项目设有整体的技术负责人，包括我本人、OriolVinyals和NoamShazeer。我们还有能力出众的项目管理和产品管理团队。Gemini本质是模型研发，但其产品意义重大，因需部署到Google的众多产品和服务界面。因此，与各产品团队沟通，了解其功能需求，明确模型表现优异及不足之处，并收集反馈，至关重要。<br>我们将这些领域大致归为三类：一是模型开发，含预训练，即在大规模文本及多模态数据上训练模型；二是后期训练，在预训练后，利用少量数据，通过强化学习或监督微调等技术引导模型展现特定行为(如回应礼貌、提高数学解题准确率)；三是设备上模型，如在手机上运行的Gemini模型，其特性与数据中心模型不同。<br>核心领域贯穿Gemini项目的多个方面，包括：训练数据、评估、基础设施、用于研究及生产模型训练与推理系统的代码库、模型服务以及Gemini内部的长期研究。我们关注Gemini外部的相关研究，同事们会建议将有潜力的技术纳入下一代Gemini的考量。最后是能力领域，关注模型的特定方面：能否确保安全与行为得当？是否擅长编码？视觉或音频任务表现如何？AIAgent行为是当前重点。国际化也很重要，目标是让模型在数百种语言中良好运行，而非仅限几种。以上便是我们大致划分的领域。<br>我们团队大约三分之一的成员在旧金山湾区，我本人在山景城。大约三分之一在伦敦，其余三分之一分布在苏黎世、纽约市、巴黎、波士顿、班加罗尔、特拉维夫和西雅图等多个地方，这些是除前两个地区外人员较为集中的地点。时区差异确实给协作带来了挑战。例如，加州西海岸与欧洲伦敦之间，在工作日内有效的“黄金协作时间”非常有限，可能每天仅有两三个小时是双方都方便进行会议的。超出这个时间窗口，总有一方会感到不便。特别是我们班加罗尔的同事，他们很难找到与其他地区都能重合的理想协作时段。<br>然而，这毕竟是一项全球性的事业，成员遍布世界各地也带来益处。例如，当模型进行大规模训练时，总有人处于清醒状态，能够实时监控训练进程。很多时候，你向伦敦的同事提出问题时他们可能已经下班，但第二天早上你会发现问题已得到解答，相关工作也已推进。因此，分布式协作既有优势，也充满挑战。<br>为了实现高效的分布式协作，我们大量利用虚拟GoogleChat空间进行各种规模的讨论和信息共享。我个人就加入了大约200个这样的群组，因此早晨醒来时，经常会收到若干条来自伦敦同事的消息，他们正在积极工作并分享进展。我们还建立了一套相对规范化的“评论请求”(RFC)流程。RFC通常是一份1到10页的文档，阐述某项工作、研究思路、已有成果或计划进行的实验。大家通过Google文档的协作功能提供反馈。对于部分RFC，我们有正式流程来评估其价值，决定是否将其纳入下一代模型训练或新的训练方案中。此外，我们还设有排行榜和通用基线(commonbaselines)，依靠可靠数据来决策如何改进模型。<br>这套机制涉及多轮、大量的小规模实验。我们将那些在小规模测试中显现潜力的方案，推进到更大规模进行验证，观察其效果是否稳定并符合预期趋势。基本上每隔几周，我们会将那些在最大规模上被成功验证的实验整合到一个新的候选基线(candidatebaseline)中。接着运行该候选基线，评估其是否优于之前的基线，并检查新整合的各项改动之间是否存在非预期的相互作用。然后不断重复此迭代过程。这基本上就是我们的工作模式，尤其是在开发预训练方案时所遵循的流程。<br>除了人员规模扩展的挑战，计算硬件规模的扩展也相当棘手。举一个例子：静默数据损坏(SDC)。尽管我们已尽最大努力，但鉴于当前机器学习系统的庞大规模和训练任务的巨大体量，硬件错误在所难免，并且有时硬件自身无法检测到这些错误。由于整个系统高度耦合，源自单个故障芯片的不正确计算结果可能扩散并污染整个模型，导致系统非确定性地产生错误结果。这种情况可能发生在特定硬件上，也可能由背景辐射等因素随机触发于任何硬件。在大规模并行训练中，尤其使用同步随机梯度下降法时，此类问题会愈发严重，错误的计算结果极易传播。<br>为此，我们在训练过程中会监控梯度的范数。若观察到范数出现剧烈尖峰(spike)，我们会高度警惕。当然，梯度异常并不一定意味着发生了静默数据损坏。我们检测SDC的方法之一是：回退几个训练步骤，以确定性方式重放计算过程。如果重放得到相同结果，问题很可能源于数据本身，而非硬件故障。但如果得到不同结果，则表明可能存在硬件问题，因为重放过程理应是确定性的。在一个案例中，我们确实观察到了梯度异常，但重放后发现，同样的巨大梯度值再次出现，这表明该异常可能并非由硬件随机错误引起。<br>此外，即使没有观察到明显的异常信号（如梯度尖峰），通过例行或偶然的重放，也可能检测到静默数据损坏(SDCs)。这种情况或许类似于，错误仅翻转了浮点数指数的低位比特，影响较小；而非翻转高位比特。高位比特翻转的后果则严重得多，可能导致期望值为0.7的梯度骤变为10的12次方数量级的巨大误差。<br>06<br>Gemini多模态与长上下文的应用实例<br>JeffDean:<br>接下来，我将举例说明这些模型的能力。首先是代码修复。模型可以帮助修复代码中的错误(bugs)。例如，一位用户上传了他的整个代码库和问题记录，模型识别出一个紧急问题：某处代码调用了同一个处理程序两次。模型随即给出了修复建议：增加一个标志位，用于检查该处理程序是否已被调用，仅在未调用时执行调用。<br>第二个例子是上下文学习。Kalamang是一种全球仅约200人使用的极低资源语言，互联网上几乎没有其书面训练数据。一位研究者撰写了关于Kalamang语法的博士论文。实验表明，若将这本论文作为上下文信息提供给模型，再让其执行英语与Kalamang语的互译任务，模型的表现竟能媲美一位手持同样语法书和词典进行翻译的人类语言学习者。这充分展示了模型强大的上下文学习能力：即便面对训练中从未接触过的主题，只要在上下文中获得相关知识（如此处400页的论文），模型就能在一定程度上理解并应用这些知识完成任务。<br>还有一个有趣的应用：从书架视频生成JSON数据。你或许未曾想过将视频作为此类任务的输入，但模型确实能处理书架视频，识别上面的书籍，并以JSON格式输出结构化的书籍信息。效果相当不错。<br>接下来是视频理解与摘要能力。模型现已能处理相当长的视频，百万Token的上下文长度大约可容纳两小时视频。例如，我们给模型输入一段体育集锦视频（包含图像和音频，时长约11分钟），并给出提示：“请用表格形式，列出视频中每个标志性体育时刻的运动项目、相关队伍&#x2F;运动员、年份，并简述其标志性意义。”模型不仅理解了视频内容，还输出了一个精确包含所有要求信息的结构化表格。这已超越简单的文本摘要，达到了更深层次的文本提取和结构化数据生成水平，完全基于视频上下文。我认为，人们尚未充分认识到利用此类多模态数据所能实现的各种有趣且实用的功能。<br>历史数据数字化是另一个应用实例。我最近看到一个案例，研究人员输入了一百年前的老式表格样式的天气数据（可能为扫描件或图片），直接向模型发出指令：“请将数据转换为JSON格式。”模型成功完成了任务。他们用此方法处理了144个表格，总成本仅10美分，有效“解锁”了这些尘封已久、难以利用的历史天气数据。<br>下一个能力是通过高级自然语言提示生成代码。例如，给Gemini2.5模型这样一个提示：“使用P5js探索Mandelbrot集(Mandelbrotset)。”这是一个非常简洁的自然语言指令。（此处提及现场演示因网络问题未能进行）正常情况下，模型会生成一个精美的、可交互的Mandelbrot集可视化探索程序。<br>07<br>塑造AI的未来：社会影响与责任<br>JeffDean:<br>由于时间关系，我将跳过一些内容，直接探讨一个至关重要的话题：既然我们拥有了这些强大的模型，它们将对社会意味着什么？<br>为此，我与其他八位合著者近期合作撰写了一篇论文，题为《塑造AI对数十亿生命的影响》。我们的作者团队汇集了来自学术界、大型科技公司和初创企业的计算机科学家及机器学习专家。论文旨在探讨：在有目标导向的研究和政策引导下，人工智能可能对世界产生何种影响？我们反对采取消极的“自由放任”态度，被动等待其未知后果（无论是毁灭性灾难还是无限进步）。我们主张采取务实的态度：整个社会，包括研究者、从业者、专家和政策制定者，应共同努力，积极引导和塑造AI的发展，以求最大化其益处、最小化其风险。这篇论文的核心即在于探讨如何通过集体行动实现这一目标。<br>为支撑论点，我们访谈了来自就业、教育、医疗健康、信息媒体等七个不同领域的24位顶尖专家，包括前总统BarackObama、教育家SalKhan、诺贝尔奖得主JohnJumper（我们在他获奖前进行了访谈）、科幻作家NeilStevenson、AnthropicCEODarioAmadei、前国会议员BobWalker等。基于访谈和研究，我们提出了五项旨在确保AI服务于公共利益的指导方针。我认为该论文对AI在就业、教育、医疗等关键领域可能产生的影响，以及我们应如何引导这些影响，进行了深入且有价值的讨论。我们所有人都必须携手合作，确保AI朝着正确的方向发展，这一点至关重要。<br>08<br>大语言模型正成为强大的通用工具<br>JeffDean:<br>最后总结，除了上述内容，我们在论文中还针对一些关键领域提出了未来值得努力实现的具体里程碑，为后续研究和发展指明了方向，这也是论文的动机之一。总而言之，大语言模型正日益成为极其强大且实用的工具。随着投资持续增加、研究人才涌入以及技术成果不断整合，我们必将见证模型能力的飞速提升。<br>这将对众多领域产生深远影响。其中一个最核心的潜在变革是，能将以往由少数专家掌握的深层专业知识，普及给不同领域的广大民众。这无疑是激动人心的前景，但同时也让一些人感到不安，因为专业知识的广泛可及性可能带来新的挑战。然而，只要我们审慎规划、有效引导，我相信，人工智能辅助的未来必将一片光明。<br>09<br>现场互动<br>现场提问：AI安全是我们都非常关注的问题，但对于大型研究实验室之外的人来说，如何进行有益且具影响力的工作尚不明确。从确保AI可控发展的角度看，如果您是刚起步的博士生、有经费的教授或能收购初创公司，您会在AI安全领域优先做什么？<br>JeffDean:我认为AI安全是一个相当宽泛的话题。当前存在许多担忧，主要是关于这些模型日益增长的能力，可能会让一些人做出他们原本无法做到的、带有恶意或从社会角度看不良的事情，或者说是社会不希望发生的事情。我认为，部分问题可以通过技术手段解决，但同时也需要出台基于政策和监管的措施，来对其中的某些方面加以限制。我们在论文中讨论的一个主题是关于错误信息和公共讨论。在这方面，AI模型显然有能力制造更逼真的错误信息，并且让人们能以更低成本进行大规模制造。错误信息并非新鲜事物，一直都可以制造，但现在有了这些工具，使得制造过程更逼真、更快速。这绝对是一个问题。随之而来的一个研究问题是，如何检测那些可能由其他机器学习模型生成的错误信息？此外，我们也可以从一个更积极的角度来看待这个问题。我们在论文中提出的一个观点是，已有早期证据表明，AI模型可以用来促进在线论坛中更具建设性的讨论。所以，这是一个值得探索的领域：如何让AI模型能够鼓励更积极的对话，并在人们的相互交流中识别错误信息。这些是我认为相当有趣的一些方向，但那篇论文里还有很多想法都值得研究。而且我认为，并非所有这些问题的解决方案都必然是纯粹技术性的。<br>现场提问：在日常工作中尝试使用AI或大语言模型时，常常感到失望。这究竟是LLM需要更多训练，还是用户需要学习如何更好地提问？<br>JeffDean:这是个非常好的问题。我倾向于认为两者兼而有之。我的意思是，首先要认识到，这些模型的进展速度非常快。比如，八个月前的Gemini模型远没有现在的Gemini模型那么强大。所以，有时人们对模型能力的印象是基于过去的经验——他们曾尝试让模型做复杂的事情但失败了。但现在，同样的事情可能已经接近实现，甚至可能做得相当不错。因此，一方面是要关注当前模型的能力，而不是八个月前那些堪称“古早”的模型。另一方面，是要熟练掌握如何引导(coax)模型来满足你的需求。这很有趣：通过一个精心设计的大约一页纸的提示(prompt)，你几乎可以基于一个通用模型创造出一个完全不同的应用，这和你用另一个不同的一页纸提示得到的结果会截然不同。例如，一个提示可能会说：“请基于这个视频内容，为我创建一个教育游戏，反映这个讲座视频中探讨的概念。”在某些情况下，模型确实能创建一个功能完备的游戏软件，用以阐释某个讲座或科学视频中的概念。虽然不总是成功，但这大概就是目前技术发展的前沿可能性。当然，对模型进行更多训练也会有帮助，因为模型会因此变得更强。我想大家已经看到了这一点，从Gemini1到1.5再到(可能指未来的)2和2.5，进步是巨大的。我预计Gemini3.0及之后的模型将比当前的模型强大得多。模型能力不断提升是整个行业的普遍趋势。<br>现场提问：业界担忧数据可能成为新的瓶颈。您个人对此有何看法？数据真的是瓶颈吗？如果不是，该如何应对？如何摆脱对抓取整个互联网数据的依赖？<br>JeffDean:是的，我确实没有把数据列出来，但它其实一直都非常非常重要。只是对于很多数据相关的工作来说，通常不像硬件或算法那样有一个明确具体的成果物(artifact)可以展示。数据工作的核心在于高质量数据的策划，我们在Gemini项目中就投入了大量时间做这件事。我确实听到一些担忧，说我们快要用尽高质量数据，导致无法继续提升模型能力。但我目前觉得这种说法不太可信。首先，现在还有海量的数据我们根本没有用于训练。比如，想想全世界所有的视频数据，我们目前只用了一小部分视频数据进行训练，这可能只占YouTube语料库的极小一部分，而且这还仅仅是全球视频数据的一部分。所以我认为，我们远没有到耗尽原始数据的地步。另外，从机器学习研究的角度看：我认为我们还有很多工作可以做，从而让模型能从每单位训练或每个token的训练数据中获得更大的质量提升。比如，我们刚才在一个内部讨论中也谈到，假设用两句话描述两个数如何相加。模型目前只是通过预测下一个token来“吸收”这个信息。但这通常不意味着它真正以一种深入的、算法化的方式理解了加法这个算法。它只是具备了一个用于预测“规则”的下一个token的预测器，但在某种意义上，它对算法本身并未真正理解。所以，如果你思考一下真正希望模型能做什么，那应该是：它能读懂那个算法描述，然后在内部构建一种表示，让它在需要的时候能够运行这个算法。这样的话，就能从那15个token中提取出远超当前方式的价值。所以我认为在这方面还有很大的提升空间。在这个领域，我还想说的另一点是，在像改进ImageNet卷积神经网络那个时代，人们用一百万张图片、一千个类别来训练模型。当时让模型更强大的方法之一，就是对训练数据进行很多很多次的训练轮。而我们现在拥有的文本数据语料库非常庞大，以至于目前的计算资源还无法支持我们进行很多次的训练轮。但随着硬件能力的提升，未来也许就能对数据进行50次训练轮，而不是仅仅3次。这很可能会提升模型的质量，当然具体能提升多少还有待观察。<br>现场提问：下一个重大挑战是什么？我们看到模型在各项基准测试上持续进步，但是否存在某个“非此即彼”式的挑战，即模型目前尚无法逾越的特定能力门槛，例如形式推理或其他可被视为下一个重大突破的能力？<br>JeffDean:我认为存在一个挑战，它并非一个泾渭分明的阶跃，但却极其艰巨。那就是我们期望模型具备的能力：能在一定程度上自主运行，并相对独立地完成我们交给它的复杂任务。例如，你能否让模型帮我规划一个为期两天的苏黎世旅行，因为我正好有几天空闲时间想安排些有趣的活动？但这个指令比较模糊，模型可能需要借助工具来弄清楚苏黎世是什么地方、在那里可以进行哪些活动。目前我们看到，模型能够将复杂任务分解为数个步骤，或许能有限地调用工具来串联不同操作，以完成相对简单的任务。但我们尚未看到模型能处理极其复杂的任务：自主将其分解为50个子步骤，调用多种复杂工具，最终完成一项可能需要耗费普通人两个月时间的庞大工程。我认为，模型当前能以大约60%至70%的准确率完成3到5步的任务，这与我们期望的未来——能以95%的准确率、通过1000个步骤完成相当于一个月工作量的目标相比，存在着巨大的鸿沟。后者正是人们期望系统达到的能力水平，然而它与我们目前的现状，以及那些可以想象但眼下绝对无法实现的能力之间，差距极为悬殊。所以，我认为这更像是一个连续发展的过程，而非某个单一的、可以一蹴而就的突破点。不过，大家将会看到模型的能力持续增强，例如，当它们能以90%的准确率完成10步任务时，这将是一个重要的中间里程碑。<br>关于本期演讲<br>访谈发布时间：2025年4月20日<br>原视频地址：https :&#x2F;&#x2F;youtu.be&#x2F;q6pAWOG_10k?si&#x3D;LLTYuXfHiJdKiZ4r<br>阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”<br>https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828<br>未来知识库是“欧米伽未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。目前拥有超过8000篇重要资料。每周更新不少于100篇世界范围最新研究资料。欢迎扫描二维码或访问https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828进入。<br>截止到3月31日”未来知识库”精选的百部前沿科技趋势报告<br>（加入未来知识库，全部资料免费阅读和下载）<br>牛津未来研究院《将人工智能安全视为全球公共产品的影响、挑战与研究重点》<br>麦肯锡：超级智能机构：赋能人们释放人工智能的全部潜力<br>AAAI2025关于人工智能研究未来研究报告<br>斯坦福：2025斯坦福新兴技术评论：十项关键技术及其政策影响分析报告（191页）<br>壳牌：2025能源安全远景报告：能源与人工智能（57页）<br>盖洛普&amp;牛津幸福研究中心：2025年世界幸福报告（260页）<br>Schwab：2025未来共生：以集体社会创新破解重大社会挑战研究报告（36页）<br>IMD：2024年全球数字竞争力排名报告：跨越数字鸿沟人才培养与数字法治是关键（214页）<br>DS系列专题：DeepSeek技术溯源及前沿探索，50页ppt<br>联合国人居署：2024全球城市负责任人工智能评估报告：利用AI构建以人为本的智慧城市（86页）<br>TechUK：2025全球复杂多变背景下的英国科技产业：战略韧性与增长路径研究报告（52页）<br>NAVEXGlobal：2024年十大风险与合规趋势报告（42页）<br>《具身物理交互在机器人-机器人及机器人-人协作中的应用》122页<br>2025-2035年人形机器人发展趋势报告53页<br>EvaluatePharma：2024年全球生物制药行业展望报告：增长驱动力分析（29页）<br>【AAAI2025教程】基础模型与具身智能体的交汇，350页ppt<br>Tracxn：2025全球飞行汽车行业市场研究报告（45页）<br>谷歌：2024人工智能短跑选手（AISprinters）：捕捉新兴市场AI经济机遇报告（39页）<br>【斯坦福博士论文】构建类人化具身智能体：从人类行为中学习<br>《基于传感器的机器学习车辆分类》最新170页<br>美国安全与新兴技术中心：2025CSET对美国人工智能行动计划的建议（18页）<br>罗兰贝格：2024人形机器人的崛起：从科幻到现实：如何参与潜在变革研究报告（11页）<br>兰德公司：2025从研究到现实：NHS的研究和创新是实现十年计划的关键报告（209页）<br>康桥汇世（CambridgeAssociates）：2025年全球经济展望报告（44页）<br>国际能源署：2025迈向核能新时代<br>麦肯锡：人工智能现状，组织如何重塑自身以获取价值<br>威立（Wiley）：2025全球科研人员人工智能研究报告（38页）<br>牛津经济研究院：2025TikTok对美国就业的量化影响研究报告：470万岗位（14页）<br>国际能源署（IEA）：能效2024研究报告（127页）<br>Workday：2025发挥人类潜能：人工智能（AI）技能革命研究报告（20页）<br>CertiK：Hack3D：2024年Web3.0安全报告（28页）<br>世界经济论坛：工业制造中的前沿技术：人工智能代理的崛起》报告<br>迈向推理时代：大型语言模型的长链推理研究综述<br>波士顿咨询：2025亚太地区生成式AI的崛起研究报告：从技术追赶者到全球领导者的跨越（15页）<br>安联（Allianz）：2025新势力崛起：全球芯片战争与半导体产业格局重构研究报告（33页）<br>IMT：2025具身智能（EmbodiedAI）概念、核心要素及未来进展：趋势与挑战研究报告（25页）<br>IEEE：2025具身智能（EmbodiedAI）综述：从模拟器到研究任务的调查分析报告（15页）<br>CCAV：2025当AI接管方向盘：自动驾驶场景下的人机交互认知重构、变革及对策研究报告（124页）<br>《强化学习自我博弈方法在兵棋推演分析与开发中的应用》最新132页<br>《面向科学发现的智能体人工智能：进展、挑战与未来方向综述》<br>全国机器人标准化技术委员会：人形机器人标准化白皮书（2024版）（96页）<br>美国国家科学委员会（NSB）：2024年研究与发展-美国趋势及国际比较（51页）<br>艾昆纬（IQVIA）：2025骨科手术机器人技术的崛起白皮书：创新及未来方向（17页）<br>NPL&amp;Beauhurst：2025英国量子产业洞察报告：私人和公共投资的作用（25页）<br>IEAPVPS：2024光伏系统经济与技术关键绩效指标（KPI）使用最佳实践指南（65页）<br>AGI智能时代：2025让DeepSeek更有趣更有深度的思考研究分析报告（24页）<br>2025军事领域人工智能应用场景、国内外军事人工智能发展现状及未来趋势分析报告（37页）<br>华为：2025鸿蒙生态应用开发白皮书（133页<br>《超级智能战略研究报告》<br>中美技术差距分析报告2025<br>欧洲量子产业联盟（QuIC）：2024年全球量子技术专利态势分析白皮书（34页）<br>美国能源部：2021超级高铁技术（Hyperloop）对电网和交通能源的影响研究报告（60页）<br>罗马大学：2025超级高铁（Hyperloop）：第五种新型交通方式-技术研发进展、优势及局限性研究报告（72页）<br>兰德公司：2025灾难性网络风险保险研究报告：市场趋势与政策选择（93页）<br>GTI：2024先进感知技术白皮书（36页）<br>AAAI：2025人工智能研究的未来报告：17大关键议题（88页）<br>安联Allianz2025新势力崛起全球芯片战争与半导体产业格局重构研究报告<br>威达信：2025全球洪水风险研究报告：现状、趋势及应对措施（22页）<br>兰德公司：迈向人工智能治理研究报告：2024EqualAI峰会洞察及建议（19页）<br>哈佛商业评论：2025人工智能时代下的现代软件开发实践报告（12页）<br>德安华：全球航空航天、国防及政府服务研究报告：2024年回顾及2025年展望（27页）<br>奥雅纳：2024塑造超级高铁（Hyperloop）的未来：监管如何推动发展与创新研究报告（28页）<br>HSOAC：2025美国新兴技术与风险评估报告：太空领域和关键基础设施（24页）<br>Dealroom：2025欧洲经济与科技创新发展态势、挑战及策略研究报告（76页）<br>《无人机辅助的天空地一体化网络：学习算法技术综述》<br>谷歌云（GoogleCloud）：2025年AI商业趋势白皮书（49页）<br>《新兴技术与风险分析：太空领域与关键基础设施》最新报告<br>150页！《DeepSeek大模型生态报告》<br>军事人工智能行业研究报告：技术奇点驱动应用加速智能化重塑现代战争形态-250309（40页）<br>真格基金：2024美国独角兽观察报告（56页）<br>璞跃（PlugandPlay）：2025未来商业研究报告：六大趋势分析（67页）<br>国际电工委员会（IEC）：2025智能水电技术与市场展望报告（90页）<br>RWS：2025智驭AI冲击波：人机协作的未来研究报告（39页）<br>国际电工委员会（IEC）：2025智能水电技术与市场展望报告（90页）<br>RWS：2025智驭AI冲击波：人机协作的未来研究报告（39页）<br>未来今日研究所2025年科技趋势报告第18版1000页<br>模拟真实世界：多模态生成模型的统一综述<br>中国信息协会低空经济分会：低空经济发展报告（2024-2025）（117页）<br>浙江大学：2025语言解码双生花：人类经验与AI算法的镜像之旅（42页）<br>人形机器人行业：由“外”到“内”智能革命-250306（51页）<br>大成：2025年全球人工智能趋势报告：关键法律问题（28页）<br>北京大学：2025年DeepSeek原理和落地应用报告（57页）<br>欧盟委员会人工智能与未来工作研究报告<br>加州大学伯克利分校：面向科学发现的多模态基础模型：在化学、材料和生物学中的应用<br>电子行业：从柔性传感到人形机器人触觉革命-250226（35页）<br>RT轨道交通：2024年中国城市轨道交通市场数据报告（188页）<br>FastMoss：2024年度TikTok生态发展白皮书（122页）<br>CheckPoint：2025年网络安全报告-主要威胁、新兴趋势和CISO建议（57页）<br>【AAAI2025教程】评估大型语言模型：挑战与方法，199页ppt<br>《21世纪美国的主导地位：核聚变》最新报告<br>沃尔特基金会（VoltaFoundation）：2024年全球电池行业年度报告（518页）<br>斯坦福：2025斯坦福新兴技术评论：十项关键技术及其政策影响分析报告（191页）<br>国际科学理事会：2025为人工智能做好国家研究生态系统的准备-2025年战略与进展报告（英文版）（118页）<br>光子盒：2025全球量子计算产业发展展望报告（184页）<br>奥纬论坛：2025塑造未来的城市研究报告：全球1500个城市的商业吸引力指数排名（124页）<br>FutureMatters：2024新兴技术与经济韧性：日本未来发展路径前瞻报告（17页）<br>《人类与人工智能协作的科学与艺术》284页博士论文<br>《论多智能体决策的复杂性：从博弈学习到部分监控》115页<br>《2025年技术展望》56页slides<br>大语言模型在多智能体自动驾驶系统中的应用：近期进展综述<br>【牛津大学博士论文】不确定性量化与因果考量在非策略决策制定中的应用<br>皮尤研究中心：2024美国民众对气候变化及应对政策的态度调研报告：气候政策对美国经济影响的多元观点审视（28页）<br>空间计算行业深度：发展趋势、关键技术、行业应用及相关公司深度梳理-250224（33页）<br>Gartner：2025网络安全中的AI：明确战略方向研究报告（16页）<br>北京大学：2025年DeepSeek系列报告-提示词工程和落地场景（86页）<br>北京大学：2025年DeepSeek系列报告-DeepSeek与AIGC应用（99页）<br>CIC工信安全：2024全球人工智能立法的主要模式、各国实践及发展趋势研究报告（42页）<br>中科闻歌：2025年人工智能技术发展与应用探索报告（61页）<br>AGI智能时代：2025年Grok-3大模型：技术突破与未来展望报告（28页）<br>上下滑动查看更多</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/04/25/1000003082-2650033291-1/">https://zejuncao.github.io/2025/04/25/1000003082-2650033291-1/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                    <span class="chip bg-color">人工智能学家</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/04/25/1000003861-2247638111-2/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003861_2247638111_2.jpg" class="responsive-img" alt="DeepMind CEO 放话：未来十年赌上视觉智能，挑战 OpenAI 语言统治地位">
                        
                        <span class="card-title">DeepMind CEO 放话：未来十年赌上视觉智能，挑战 OpenAI 语言统治地位</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AI%E5%89%8D%E7%BA%BF/">
                        <span class="chip bg-color">AI前线</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/04/25/1000003082-2650033291-2/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003082_2650033291_2.jpg" class="responsive-img" alt="麦肯锡 &amp; Mozilla：2025 人工智能时代下的开源技术研究报告">
                        
                        <span class="card-title">麦肯锡 &amp; Mozilla：2025 人工智能时代下的开源技术研究报告</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-04-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                        <span class="chip bg-color">人工智能学家</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
