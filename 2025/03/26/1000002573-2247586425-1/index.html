<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="美国机器人“四小龙”：通用机器人仍需十年，专用机器人即将出现，机器人的扩展法则会在五年内被探索出来 | GTC 2025, ZejunCao&#39;Blogs">
    <meta name="description" content="美国机器人“四小龙”：通用机器人仍需十年，专用机器人即将出现，机器人的扩展法则会在五年内被探索出来 | GTC 2025

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

我们这一代人出生得太晚，没能赶上探索地球的地理大">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>美国机器人“四小龙”：通用机器人仍需十年，专用机器人即将出现，机器人的扩展法则会在五年内被探索出来 | GTC 2025 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000002573_2247586425_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">美国机器人“四小龙”：通用机器人仍需十年，专用机器人即将出现，机器人的扩展法则会在五年内被探索出来 | GTC 2025</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/AI%E7%A7%91%E6%8A%80%E5%A4%A7%E6%9C%AC%E8%90%A5/">
                                <span class="chip bg-color">AI科技大本营</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-03-26
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/1cpbHF4AfVwE34M2hayP-A">美国机器人“四小龙”：通用机器人仍需十年，专用机器人即将出现，机器人的扩展法则会在五年内被探索出来 | GTC 2025</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>我们这一代人出生得太晚，没能赶上探索地球的地理大发现时代；我们出生得又太早，可能无法亲身参与星际旅行，探索其他星系。但我们却恰逢其时，躬逢其盛，见证并参与到解决机器人技术难题的伟大历史进程中。相信在不久的将来，所有能够移动的物体都将实现自主化。<br>责编|王启隆<br>出品丨AI科技大本营（ID：rgznai100）<br>今天这篇文章将会回顾英伟达大会重点宣传的一个论坛：《通用机器人的新时代：人形机器人崛起》（ANewEraofGeneralistRobotics:TheRiseofHumanoids），英伟达跟紧物理世界AI和具身智能的新风向，邀请到美国四家顶尖的人形机器人公司老板，参与这场对话。<br>那么问题来了，现在全世界的人形机器人领域都有哪些顶级公司呢？相信很多人和小编一样，只认识国内的宇树机器人，对国外现在的机器人战局不太了解，所以我们先看一张图，了解当前的时局情况：<br>本文的几位对话嘉宾，也都属于图上的几家公司。<br>话不多说，我们立刻开始回顾GTC2025的这场“美国机器人四小龙”的尖峰对话。如果你看完还没过瘾，欢迎关注CSDN《万有引力》栏目将于3月28日19:30进行的最新直播，特别邀请到北京邮电大学人工智能学院副教授陈光（@爱可可-爱生活）、深圳市人工智能与机器人研究院副研究员夏轩、Roboraction.AI首席执行官黄浴，在CSDN&amp;《新程序员》执行总编、《万有引力》主理人唐小引主持下，以“十问具身智能”为切入点，深入探讨当前具身智能技术最新进展、核心挑战与未来方向，共同探索通用机器人的真正边界！</p>
<p>伯恩特（1X）：我是1X公司的CEO和创始人伯恩特·博尼奇（BerntBørnich）。我们致力于通过这些安全、智能的人形机器人创造大量劳动力，并且我们坚信，唯有如此才能真正实现智能化。<br>迪帕克（SkildAI）：我是SkildAI的首席执行官和联合创始人迪帕克·帕塔克（DeepakPathak）。我们正在做的事情是为机器人打造一个通用的大脑。我们的论点是，我们可以拥有一个单一的共享模型，因为机器人领域本身数据稀缺。我们不妨利用从任何平台、任何任务、任何场景中所能获取的一切。所以可以把它想象成一个大规模的基础模型，适用于任何机器人、任何硬件、任何任务、任何场景。<br>普拉斯（Agility）：我是AgilityRobotics的首席技术官普拉斯·维拉加普迪（PrasVelagapudi）。在Agility，我们制造的人形机器人Digit旨在投入实际工作，目前正推向制造业和物流等应用场景。我们认为，将这项技术推向市场并从中学习的最佳途径，是让真正的客户在实际部署中应用它，并从中获得反馈。因此，我们一直专注于将我们的机器人推向市场，真正投入到工作中。<br>艾伦（波士顿动力）：我是波士顿动力（BostonDynamics）的首席技术官艾伦·桑德斯（AaronSaunders）。我早在人形机器人“还不是一个很酷的技术”时就开始研究了。在波士顿动力，我们的使命始终如一，那就是让机器人真正走进现实世界。我们已经交付了几千台机器人，而人形机器人是我们最近发布的重要产品。我们非常希望将我们的产品推向市场，使其能够完成真正有价值的工作，也就是说，将人类从那些肮脏、枯燥和危险的工作中解放出来。这是我们长期以来努力的目标，虽然还有很多工作要做，但我们对未来的发展方向感到非常兴奋。<br>范麟熙（英伟达）：大家好。我是JimFan（范麟熙），英伟达GEARLab（通用具身智能体研究组）的联合负责人，同时也是ProjectIsaacGR00T项目的负责人。GR00T是英伟达旨在构建人形机器人通用大脑——基础模型的宏大项目。GR00T也代表了英伟达下一代物理人工智能计算平台的战略方向。我们的使命是普及物理人工智能。<br>实际上，在黄仁勋的主题演讲中，我们发布了GR00TN1模型的开源计划，这是全球首个开源的人形机器人基础模型。它仅有20亿参数，但性能却非常出色。可以说，大家现在已经将世界最先进的自主人形机器人智能掌握在手中。我还想补充一句，和在座的各位一样，我入行机器人领域也很早，那时它还远没有现在这么受关注，所以我真的非常高兴看到这个领域变得如此热门。非常感谢大家，各位的到来让我倍感荣幸。<br>主持人：机器人技术实际上是人工智能最古老的应用领域。但从历史发展来看，它的发展速度却最为缓慢。不过，我认为现在情况已经大不相同了。那么，各位认为是什么原因促成了这种转变呢？<br>范麟熙（英伟达）：我认为最大的变化是，现在黄仁勋开始关注机器人技术了。黄仁勋有“点石成金”的能力，他涉足的任何领域都会呈现指数级的增长，我们甚至将此称为“黄仁勋定律”（开个玩笑）。<br>我认为机器人技术和人工智能几乎是同时诞生的古老领域。而机器人技术之所以如此具有挑战性，根源在于莫拉维克悖论。这个悖论指出，对人类来说轻而易举的事情，对机器而言却异常困难，反之亦然。例如，像创意写作这样对我们人类来说非常困难的任务，对机器而言可能并没有那么复杂。这就是为什么像LLM这样自然语言处理（NLP）技术，以及计算机视觉技术，在解决问题方面比现在的机器人技术要领先得多。我们目前正面临着这个悖论的挑战。<br>那么，究竟是什么发生了改变呢？我认为有以下几个方面。<br>首先是模型层面。大型基础模型，比如像ChatGPT这样的突破性模型出现，为我们带来了变革。现在我们拥有了能够进行推理的模型，以及能够理解计算机视觉的多模态模型。这些模型对3D视觉世界的开放式词汇理解能力，已经远超过去。这些都是解决机器人技术难题的必要条件，但还不够充分。例如，要拥有一个真正优秀的视觉系统，就必须首先解决视觉问题，然后才能进一步探讨通用机器人的实现。我认为，正是因为模型技术的飞速发展，我们才能够更系统地着手解决机器人技术难题。这是第一个改变。<br>第二点改变在于数据层面。与大语言模型（LLM）不同，我在这里引用一下EliasAskever的观点，他曾说互联网是人工智能的“化石燃料”。然而，机器人技术甚至连“化石燃料”都没有。至少对于LLM而言，我们可以轻易地从互联网上下载文本数据，从维基百科上抓取文本信息。但是，我们从哪里获取电机控制数据呢？我们又从哪里在互联网上抓取机器人的运动轨迹数据呢？答案是无处可寻。因此，我们必须自己生成数据，必须大规模地收集数据。我认为，模拟技术的进步，特别是GPU加速的模拟技术，使得这些问题变得更加容易解决。因为现在我们可以在大约三个小时的计算时间内，生成相当于过去十年积累的训练数据。这确实帮助我们突破了数据匮乏的瓶颈。这是第二个改变。<br>第三点是硬件层面的进步。今天在座的各位，都是杰出的创始人，代表着我们目前所能见到的最顶尖的机器人硬件水平。我认为硬件的性能已经有了显著提升，同时成本也大幅降低。例如，今年我们已经看到了售价在4万美元左右的人形机器人硬件。这相当于一辆汽车的价格。回溯到2001年，NASA建造了Robonaut，首批重要的人形机器人之一，在2001年的美元价值计算，其造价高达150万美元。因此，机器人硬件终于变得更加经济实惠，这将加速其普及和主流化进程。<br>主持人：艾伦，我很想听听你的看法。你在自我介绍中提到，你在机器人技术还“不酷”的时候就入行了。你认为是什么发生了改变？<br>艾伦（波士顿动力）：我补充一些要点。我非常认同“模拟到现实差距”的缩小是一个巨大的进步。长期以来，机器人技术领域一直努力构建能够准确模拟物理特性，同时又具备高效计算能力的模拟环境。我们可以创建非常复杂的模型，在虚拟世界中出色地模拟物理现象，但却无法以实时甚至更快的速度运行这些模拟。因此，对我而言，最大的变革或许在于，我们现在有能力以超越真实世界时间流逝的速度来模拟物理环境。这极大地加速了我们可以进行的模拟实验次数，以及我们利用这些模拟来开发新人工智能技术的效率。<br>此外，零部件的商品化也至关重要。我认为我们应该高度赞扬一些相关产业的贡献。例如，消费电子产业推动了电池和摄像头等技术的发展，这些技术对于机器人感知世界和进行计算至关重要。回想10年甚至15年前，大多数机器人内部充斥着PCB电路板和各种线缆，电池容量却非常有限。而现在情况已经彻底改变，我们可以为机器人配备强大的计算单元，以及微型化、低功耗的传感器。因此，我认为零部件的商品化，不仅仅体现在成本降低上。<br>虽然降低成本目前是一个重要的关注点，但我认为机器人技术创业公司蓬勃发展的原因，在于全球供应链为我们提供了大量关键的、标准化的组件，我们可以像搭积木一样将它们组装起来。这使得机器人技术从业者，从过去需要事无巨细地设计每一个零件，转变为能够站在更高层面，像拼图一样整合现有组件。现在的公司可以将更多精力放在智能层面，专注于开发应用，而不是像过去那样，将大量资本和精力耗费在仅仅让机器站立行走这样的基础问题上。<br>迪帕克（SkildAI）：我想补充一下Jim刚才关于促成变革的几点看法。我想强调的是，机器人技术不仅仅是人工智能的“第一个应用”，它实际上就是人工智能的“本质”。<br>如果我们回顾图灵的原始文献，当他谈论人工智能时，他的设想就是机器人。图灵的意思是，我们应该创造能够学习的机器，而不是像制造一个成年人那样去制造机器，而是要制造像孩子一样能够学习的机器，然后让它不断成长。我们可以把同一个机器人放在不同的环境中，比如教室，随着时间的推移，它就能成长为一个“成年人”。<br>这是一个非常深刻的思想实验，而图灵早在20世纪50年代就提出了这个想法。语言、视觉等等固然重要，但如果我们从自然界的演化历程来看，它们在时间轴上出现的时间，要远远晚于物理行为能力。例如，我们现在用大语言模型（LLM）训练的数据，可能只涵盖了过去100年、200年，最多也就1000年的历史数据。但人类的历史已经超过1000年了。<br>因此，并非是语言能力催生了智能，而是因为我们早已具备了智能的基础设施——我们的大脑，而大脑的进化本身就源于物理层面的推理能力。这正是机器人技术影响如此深远的原因。因为你无需向任何人解释什么是机器人，人们就能本能地理解它，因为我们每天都在进行各种各样的体力活动。各行各业的公司都会受到机器人技术的影响，这才是问题的关键所在。<br>那么，除了Jim提到的那些技术层面的因素之外，还有什么发生了变化呢？我认为根本性的转变在于我们看待机器人技术的方式。长期以来，机器人技术一直被视为一个控制工程的领域。可以说，在三四年前，控制理论仍然是驱动机器人技术发展的核心动力。对于在这个领域工作多年的专家来说，他们应该清楚，传统的控制理论最初并不是为机器人技术而设计的。控制理论的黄金时代是在二战期间，主要应用于飞行器、导弹等军事领域。<br>后来，人们受到图灵思想的启发，开始对机器人技术产生浓厚兴趣。但当时人们能用的工具是什么呢？只能是那些为飞行器和导弹等设计的控制理论。这种状况一直延续了几十年，长达70年之久。但这与图灵的最初设想的精神并不相符。它不是一种“孩子式”的学习方式。我们不会先教孩子微积分，然后再教他们走路。我们不会让他们先理解关节运动的数学原理，然后再学习如何迈步。孩子是通过经验来学习的。因此，我认为“通过经验学习”是机器人技术领域正在发生的最重要的转变。我们现在正见证着整个行业思维模式的转变。我想说，一个重大的变化已经发生，我们已经从“编程经验”转向了“通过经验学习”，这代表着我们思考机器人技术方式的根本性变革。<br>伯恩特（1X）：我非常赞同迪帕克的观点，并想进一步展开讨论。我在这个领域工作了足够长的时间，亲历了经典控制理论主导的时代。<br>我认为，互联网的兴起是促成变革的关键因素之一。仔细想想，互联网就像一场规模空前的人类实验，在过去近30年的时间里，全球数十亿人共同参与，创造了这样一个庞大的数据资源库。正是这些海量数据，使得训练人工智能模型成为可能，这简直太神奇了。现在，我们要做的是呼吁大家在未来30年里继续参与这场实验，只不过这次的角色从数据贡献者变成了机器人。当然，这只是一个玩笑。但互联网数据的确推动了人工智能的快速发展，即使人工智能最初的设想是应用于机器人技术领域。<br>对我而言，现在的核心问题是如何利用现有的海量数据，引导机器人完成一些有实际价值的任务。因为只有当机器人能够执行有用的工作时，我们才能在真实世界中不断学习，而这才是智能的真正来源。我们需要让机器人先达到一个“有用”的临界点。例如，当我们说“去冰箱里给我拿瓶可乐”时，如果机器人能够以一定的成功率完成这个任务，即使不是每次都成功，我们也看到了实现通用机器人的可行路径。因为接下来，我们只需要不断地迭代优化，告诉机器人哪些动作是有效的，哪些是无效的，通过大量的尝试和学习，机器人就能越来越熟练地完成“从冰箱里拿可乐”这类任务。<br>我认为，这正是我们目前在多模态大语言模型浪潮中所看到的趋势。或许我们无法完全通过这种方式彻底解决机器人技术或通用人工智能（AGI）的所有难题，但我相信，我们可以让机器人系统变得足够“有用”，从而创建一个高效的数据飞轮效应。这个数据飞轮将不断驱动机器人智能的提升，而无需我们事无巨细地远程操控机器人完成每一项任务。这或许就是通往真正通用人工智能（AGI），或者至少是非常有用的通用机器人的道路。未来的发展，让我们拭目以待。<br>普拉斯（Agility）：我非常赞同艾伦刚才提到的一些观点，即为什么机器人技术在经历了人工智能的早期发展和在其他领域的广泛应用之后，又重新回归大众视野。<br>机器人技术之所以充满挑战，主要有两个原因。首先，硬件研发非常困难；其次，真实世界是高度非结构化的。回顾人工智能和机器人技术的发展历程，会发现机器人技术在很大程度上是在努力克服硬件难题，例如微型化传感器（MEMS）、高性能执行器和驱动技术、以及高能量密度电池技术等等。这些硬件层面的技术瓶颈都必须逐一突破。即使像Arduino这样的开源硬件平台，也极大地降低了机器人开发的门槛，让更多人能够更容易地在现实世界中创造出可以运动的实体，而无需从零开始造轮子。<br>在人工智能层面，我们一直在循序渐进地从解决结构化问题，过渡到解决日益复杂的非结构化问题。从最初处理结构化的查询和指令，到开发应用程序编程接口（API），再到构建简化的世界模型，直至发展到现在的非结构化世界模型。人工智能平台的每一次迭代升级，都伴随着数据摄取方式的革新，以及对先前结构化方法最佳实践的继承和发展。<br>我们不断地探索，如果逐步放开对人工智能系统的限制，比如直接让算法分析自动驾驶汽车的摄像头视频流，或者让机器人通过自身携带的摄像头自主观察世界，会发生什么？<br>我认为，机器人技术的复兴，是人工智能和硬件技术长期积累、不断突破的必然结果。我们正处在一个关键的转折点，各种技术的进步最终汇聚在一起，使得我们现在有能力去挑战“与非结构化世界进行全面互动”这个终极难题。<br>伯恩特（1X）：我认为你刚才提到的最后一点至关重要。回顾硬件领域的发展，过去几年最显著的进步之一，就是硬件的可靠性大幅提升，我们现在能够制造出在与真实世界互动时不易损坏的硬件。我们这些长期从事机器人研究的人都深有体会，早期的机器人系统非常脆弱，每次实验后都需要花费大量时间进行维修和重建，这大大延长了研发周期。但现在，我们已经能够制造出足够坚固耐用的机器人硬件，使其能够在真实世界中安全可靠地运行和学习，而不会轻易损坏自身或周围环境。我认为，硬件的稳健性是机器人技术走向成熟的必要条件，而实现这一目标，我们走了很长一段路，克服了无数技术难题。<br>主持人：听了各位的真知灼见，以及各位对机器人技术发展现状的思考，我产生了一个很有意思的问题。各位的公司都采取了非常令人兴奋且独特的战略和方法。我很好奇想听听各位对自家公司在以下几个方面的策略和方法的看法：例如人工智能在机器人技术中扮演的角色，从专家模型向通用模型的演进，以及如何应对基础模型爆炸式增长的趋势等等。<br>范麟熙（英伟达）：我可以先谈谈英伟达GR00T项目的策略。我们正在尝试解决一个非常、非常具有挑战性的问题，那就是为各种不同的人形机器人，而不仅仅是为某一款机器人，构建一个通用的“大脑”。我们还希望实现所谓的“跨具身性”。<br>那么，我们是如何应对这个挑战的呢？我认为主要有两条原则。第一条原则是，模型本身的设计要尽可能地简洁。我们追求的是端到端的模型，理想状态是实现“从光子到动作”的直接映射。也就是说，模型直接接收来自摄像头等传感器的像素数据作为输入，然后直接输出连续的浮点数，这些浮点数本质上就是控制机器人电机运动的指令。整个模型结构尽可能简洁，没有任何中间环节。为什么简洁性如此重要？因为如果我们借鉴自然语言处理（NLP）领域的成功经验，NLP可以说是迄今为止人工智能最成功的应用领域之一。<br>我认为，作为机器人技术从业者，我们应该学习NLP领域的成功经验。以ChatGPT为例，在ChatGPT出现之前，NLP领域的研究方向其实有些混乱。文本摘要、机器翻译、代码生成等任务，分别使用完全不同的数据管线（pipeline）、训练协议和模型架构，有时甚至需要使用多个不同的模型。而ChatGPT的出现，彻底颠覆了NLP领域，因为它足够简洁。ChatGPT的核心思想是将任何文本输入映射到任何文本输出，仅此而已。其底层架构是一个Transformer模型，将整数序列映射到另一个整数序列。正是因为这种简洁性，使得我们可以将所有类型的数据、所有类型的问题都统一到一个模型中进行处理。我认为，机器人技术也应该借鉴这种“简洁至上”的思想，尽可能简化模型设计。<br>第二条原则是，数据管线的构建将会非常复杂。也就是说，所有围绕模型构建的配套设施都会非常复杂。这是因为，正如我一开始就强调的，数据是机器人技术发展面临的巨大挑战。我们无法像NLP那样，从YouTube或维基百科上轻松下载大量的电机控制数据或机器人运动轨迹数据。这些数据在互联网上根本无处可寻。<br>因此，对于GR00T项目，我们的数据策略可以概括为一个金字塔结构：<br>在金字塔的顶端，是“真实机器人数据”。这类数据质量最高，因为不存在“领域差异”的问题。我们可以通过远程操作真实机器人，在真实世界中收集数据。但这种数据的规模非常有限，可扩展性不高，因为我们受到物理规律的限制，每台机器人每天最多只能运行24小时。这是无法突破的物理极限。而且在原子世界中，数据规模很难快速扩展。在金字塔的中间层，是“模拟数据”。模拟技术在这里发挥着至关重要的作用。我们大量依赖像Isaac这样的物理引擎来生成大规模的模拟数据。这些模拟数据可以基于真实世界中采集的数据进行生成，也可以通过像Deepak提到的“从经验中学习”的方法来生成。因此，模拟数据构成了我们数据金字塔的中间层。请大家记住，在英伟达成为一家人工智能公司之前，它首先是一家图形技术公司。而图形引擎最擅长什么？物理模拟和渲染。这就是我们的模拟数据策略。<br>在金字塔的底部，我们仍然需要来自互联网的大量多模态数据。但这次我们使用这些数据的方式略有不同。我们利用这些数据来训练视觉-语言模型（Vision-LanguageModels），这些模型可以作为视觉-语言-动作模型（Vision-Language-ActionModels,VOMs）的基础。<br>VOMs模型通过海量的互联网文本、图像、音频等数据进行训练。近年来，视频生成模型也取得了巨大进展，它们甚至可以模拟世界的运行规律，成为“神经模拟器”。因此，金字塔的最底层实际上是“神经模拟”数据，它超越了传统的图形引擎模拟。我们可以通过提示视频生成模型，让其生成我们需要的视频内容，例如，我们可以要求模型“幻觉”出一条新的机器人运动轨迹。<br>由于视频生成模型是在数亿甚至数十亿的互联网视频数据上训练出来的，它们已经学习到了非常丰富的物理世界知识，因此能够生成在物理上合理的机器人运动轨迹，即使这些轨迹是以像素的形式呈现的。<br>然后，我们可以运用特定的算法，例如我们在GR00TN1模型中提出的“潜在动作提取”（LatentActionExtraction）算法，从这些“幻觉”中反向提取出机器人的控制指令，也就是机器人的“梦想”。<br>就像科幻电影《银翼杀手》中提出的问题：“人形机器人会梦见电子羊吗？”我们的机器人也在“做梦”，而我们可以从这些“梦”中提取出有价值的潜在动作，并将这些数据反馈到我们的数据金字塔中，用于模型的训练和优化。通过这些复杂的数据策略，我们将各种来源的数据进行整合和压缩，最终提炼成一个简洁的模型——一个从光子输入到动作输出的端到端模型。一个仅有20亿参数的模型，就足以胜任各种各样的机器人任务。以上就是GR00T项目数据策略的概览。<br>艾伦（波士顿动力）：Jim（范麟熙）描绘的未来图景非常令人兴奋。我们拥有一个简单而强大的模型，虽然参数量不大，但却几乎可以解决所有问题，实现从像素输入到运动控制的直接映射。<br>但在通往这个理想愿景的道路上，我认为我们还需要关注一些现实问题，例如，如何确保我们交付到真实世界的产品具备足够的“确定性”。当我们向客户交付产品时，我们需要充分了解机器人在各种意外情况下会如何表现。我们需要考虑功能安全，以及在现有功能基础上添加新功能时，如何避免系统性能退化。<br>你刚才提到了一个非常重要的观点，那就是将复杂性转移到数据层面，转移到我们收集的数据中。我认为我们目前还处于构建高质量数据集的早期阶段。因此，波士顿动力秉持的一个重要策略是，在追求这种潜力巨大的终极目标的同时，不要轻易抛弃我们现有的所有工具和技术积累。因为在通往通用机器人的道路上，我们还有很多实际问题需要解决，其中之一就是如何维护客户对机器人的信任。为了赢得并保持客户的信任，我们需要综合运用我们所掌握的所有工具和技术。<br>因此，我认为，虽然基于人工智能的新技术为机器人技术带来了令人兴奋的变革，我们有理由相信这些技术将彻底改变机器人技术的未来格局，但与此同时，我们也需要保持清醒的认识，机器人技术领域过去70年积累的各种传统工具和技术仍然非常重要。在解决现实世界的实际问题时，尤其是在操作大型、高功率机器人，或者在人类身边工作时，这些传统技术仍然是不可或缺的。因为一旦我们失去了客户的信任，就很难再挽回。因此，我认为，我们既要拥抱新技术，也要充分利用现有的成熟技术，我们需要一个庞大的“工具箱”来应对未来的挑战。<br>迪帕克（SkildAI）：我非常赞同Jim（范麟熙）的观点，我们SkildAI的理念也非常相似，致力于构建一个尽可能简洁的模型。当然，我们目前还无法确切描述这个模型最终会是什么样子，所以我不会说它已经“非常简单”，但我们的目标是构建一个相对简洁的模型，并将重心放在数据上。<br>如果我们借鉴早期和近期大语言模型（LLM）发展的经验，我认为有一个经常被低估的关键因素，那就是“多样性”的重要性。回顾LLM的发展初期，许多公司尝试训练模型，例如，训练一个能够创作优秀诗歌的模型。他们可能会使用世界上所有最优秀的诗歌作品进行训练，但结果往往不尽如人意。因为，除非你使用包含各种各样、甚至与诗歌创作看似无关的数据进行训练，否则模型就难以真正理解“智能”的本质，因为真正的智能正是来源于这种多样性。<br>我们现在观察到，至少在我们的模型实验中，多样性对于机器人技术同样至关重要。即使在我们目前非常小规模的数据集上，我们发现限制模型性能提升的瓶颈，更多地来自于数据的多样性不足，而不是数据规模不够大。因此，关键在于如何尽可能地收集涵盖各种任务、各种环境的数据，最好是包含尽可能多的噪声和动态变化的数据，这样模型才能真正理解“任务”的本质。<br>我最喜欢举的一个例子是“打开洗衣机”。当我们面对一台洗衣机时，我们人类会立刻明白，我们的目标是将衣物放入洗衣机内筒的圆形入口。我们会尝试打开洗衣机门，首先寻找把手，如果找不到把手，可能会尝试寻找其他开关或按钮，如果还是打不开，可能会尝试将旋钮调回“零”位。我们对洗衣机的工作原理有着深刻的理解，因此即使面对一台全新的洗衣机，我们也能够很快掌握其使用方法。但目前的机器人系统却完全不具备这种能力。它们只能学习并重复特定的动作序列。这就是为什么我们认为，让机器人大规模地进入真实世界，获取各种各样真实世界的数据至关重要。<br>我想在这里分享一个可能有些“反传统”的观点，这也非常值得我们深入探讨。我们认为，机器人必须能够与人类近距离共处，甚至进入家庭环境，而安全性必须是机器人设计中固有的特性。我们需要从一开始就确保机器人的能量输出不会过大，从而避免对人类造成潜在的危险。同时，我们也需要思考如何将这些基于人工智能的新方法与传统的控制理论工具箱相结合。<br>我想在这里补充一点，与大语言模型（LLM）或视觉模型不同，当我们在机器人技术领域探讨“发展路径”时，我们总是需要同时考虑两个方面：硬件的发展路径和软件的发展路径。但在语言领域，或者GPU领域，我们似乎很少听到这样的问题。因为GPU的发展路径已经被黄仁勋规划好了。但在机器人领域，硬件和软件是两个相互独立又紧密联系的组成部分。<br>这就引出了一个重要的问题：未来机器人领域会走向“大一统”吗？比如，未来是否会只存在一种通用机器人平台，例如1X机器人？或者波士顿动力的机器人？我们最终会部署哪种类型的机器人？如果未来各种类型的机器人并存，那么它们的大脑是否可以实现共享和通用？我认为，要解答这些问题，我们需要深入思考以下两个方面。<br>首先，从人类自身的经验来看，我们已经证明了一个大脑可以控制各种不同的“硬件”。例如，在座的各位，即使是第一次接触VR设备，只要戴上VR头显、穿上动作捕捉服或戴上手套，就能立刻学会控制各种不同的机器人。大家无需了解机器人的电机细节，也无需知道电机是如何工作的。这已经充分证明，一个通用的大脑是可以存在的，它可以控制各种不同的机器人硬件平台。这是第一个方面，意味着我们可以利用来自不同硬件平台的数据进行模型训练。<br>第二个方面，正如大家所知，目前机器人领域面临着数据匮乏的难题。但我们往往忽略了一个特殊的数据来源，那就是我们人类自身。我们人类虽然不是机械机器人，不是由电力驱动的，而是生物机器人，但从根本原理上来说，我们和机械机器人遵循着相似的规律。例如，我们有运动神经元和感觉神经元。感觉神经元负责将传感器（例如眼睛、耳朵、皮肤等）收集的信号传递到大脑，而运动神经元则负责将大脑发出的指令传递到肌肉，驱动肢体运动。<br>如果我们认同“一个通用大脑可以控制所有硬件”的观点，那么我们为什么要把生物硬件（人类自身）排除在外呢？如果我们不将人类排除在外，我们实际上可以利用大量的人类活动视频数据。例如，我们可能没有1X机器人打开冰箱的视频数据，但人类每天都会无数次地打开冰箱。互联网上有数万亿的人类打开冰箱的视频。至少我们认为，这些人类活动视频数据对于机器人技术的发展至关重要。通过学习人类肢体的运动方式，我们可以更好地理解如何控制人形机器人。当然，仅仅依靠人类视频数据是不够的，还需要结合模拟数据进行训练，因为我们不能仅仅通过观看视频来学习如何与世界互动。但将这两者结合起来，将是一个非常有潜力的发展方向。<br>伯恩特（1X）：我认为这个观点非常重要。我想快速补充一点，我认为我们非常赞同迪帕克的看法。所有类型的数据都非常有用，我们也在积极使用各种数据进行模型训练。我只是想澄清一下，刚才的讨论中似乎将两个不同的概念混淆了。<br>主持人：没问题。我能感觉普拉斯也有很多想法想表达。<br>普拉斯（Agility）：作为一个长期从事机器人远程操作的人，我可以肯定地说，虽然人脑确实非常擅长远程操作各种不同的机器人平台，但不同平台的操作性能差异是客观存在的。硬件平台的差异确实会对机器人的性能产生显著影响。<br>例如，我曾经远程操作过1X机器人，那是一种非常棒的体验。我也远程操作过一些工业机器人，体验就没那么好了。硬件的差异，例如机器人的结构设计、传感器配置、惯性特性等等，都会直接影响机器人的操作性能。我认为，在追求通用机器人的道路上，我们不能忽视硬件的重要性。我们需要根据具体的应用场景和任务需求，设计和制造出合适的硬件平台，使其更易于控制，具备更精准的感知能力，以及更优良的运动性能，从而在真实世界中高效可靠地完成任务。<br>范麟熙（英伟达）：我举个例子，艾伦在过去十年里用波士顿动力的机器人惊艳了世界。这充分说明了机器人的动力学特性至关重要，大家可以明显感受到波士顿动力的机器人运动方式与众不同。另外，我们今天讨论的议题中，还缺少一个重要的机器人应用案例，那就是达芬奇手术机器人（Leonardo’srobot）。达芬奇手术机器人的应用已经催生了一个市值超过千亿美元的庞大产业，而达芬奇机器人本质上就是通过远程操作来完成手术的。这非常了不起。这意味着，没有人会质疑人脑的强大能力，以及硬件平台的重要性。<br>因此，我认为我们刚才讨论的这些问题，实际上都指向了机器人技术发展中硬件和软件这两个关键要素。不同的公司可能会采取不同的技术路径，但在通往通用机器人的道路上，硬件和软件的协同发展是必不可少的。因此，未来的发展方向，不是“非此即彼”的选择，而是在真实世界数据、人类数据、模拟数据的基础上，不断扩展机器人技术的应用边界。<br>伯恩特（1X）：我认为这也可以从“自下而上”和“自上而下”两个角度来理解。刚才我们更多地是从“自上而下”的角度，讨论通用的控制架构。<br>但我认为，从“自下而上”的角度，探讨如何让机器人学习精细操作技能，例如灵巧的抓取和操作物体，也同样非常重要。至少从我们目前的经验来看，即使是远程操作，我们也难以实现像人手那样快速而灵巧的操作。我们目前还没有找到一种有效的远程操作系统，能够实现快速、精准、并提供良好触觉反馈的精细操作。<br>但令人惊喜的是，机器人可以通过自主学习，掌握非常出色的灵巧操作技能。例如，如果我们只是给机器人提供一些物体，让它自由地与这些物体进行交互，机器人就可以通过自主探索和学习，逐渐掌握精细操作的技巧。这就引出了一个问题，我们是否可以提升远程操作界面的抽象层次，让操作者不再需要直接控制机器人的每一个细微动作，例如精确地控制手指的捏合力度和角度，而是可以通过更高级的指令，例如“抓取这个物体”、“将物体放置到指定位置”等，来引导机器人完成任务，并将精细操作的任务交给机器人自主完成？<br>艾伦（波士顿动力）：我认为在讨论“大脑”与“硬件”的关系时，我们往往会忽略一个关键因素，那就是我们想要让机器人完成的任务类型。如果我们的目标是让机器人处理一些尺寸较小、惯性不明显的物体，例如桌面上的小物件，那么我们或许可以将机器人的“大脑”与“身体”相对独立地进行设计。但现实情况是，我们希望机器人能够完成的任务，远不止是简单的桌面操作。如果我们希望机器人能够搬运大型、重型、结构复杂的物体，或者接触锋利的金属部件，或者在高温环境中工作，从而将人类从危险的制造环境中解放出来，那么我认为硬件平台的设计就至关重要，并且硬件和软件必须协同进化。<br>我认为，那种认为我们可以完全将“大脑”与“身体”分离，构建一个通用的硬件平台，然后通过应用程序编程接口（API）连接任何软件“大脑”的想法，在很大程度上是理想化的。在实际应用中，硬件和软件需要紧密配合，协同进化。例如，执行器的性能，包括其精度、响应速度、摩擦力等特性，都会直接影响机器人在模拟环境中的建模精度，以及最终的控制效果。<br>我们需要更多的时间，才能充分理解像GR00T这样的通用模型，在不同类型的机器人平台上部署时，会产生怎样的差异。因为我们目前还没有足够的数据来证明，一个通用的模型可以完美地适配所有类型的机器人平台，并在所有平台上都表现出完全一致的行为。如果我只是想让机器人拿起一包薯片，然后移动并放下，硬件平台的差异可能并不重要。但如果我希望机器人能够精确地抓取一个高精度零件，并将其精确地组装到另一个高精度孔中，硬件平台的差异就可能至关重要。因此，对于“大脑”和“硬件”是否可以完全分离这个问题，我认为目前还没有定论，这很大程度上取决于我们希望机器人完成的具体任务类型。<br>范麟熙（英伟达）：或许可以这样理解，未来机器人技术的发展趋势是“一个硬件平台，搭载多种不同的大脑”。英伟达的目标是打造一个通用的硬件平台，让众多公司在这个平台上开发各种不同的机器人“大脑”。<br>我认为艾伦提出了一个非常有趣且极具挑战性的问题，那就是“跨具身性”。“跨具身性”对于模型而言意味着什么？或许我们可以思考一下我们人类自身。我认为人类实际上非常擅长“跨具身性”。例如，当我们玩电子游戏时，实际上就是在进行一种“跨具身性”的体验。当我们操控游戏中的角色时，无论是驾驶赛车，还是扮演一个奇特的非人类角色，在经过一段时间的练习后，我们都能逐渐掌握如何通过手柄或键盘来控制游戏中的虚拟身体，并最终熟练地操控角色完成各种游戏任务。<br>因此，人脑在“跨具身性”方面具有非常强大的适应能力。我认为“跨具身性”是一个可以解决的问题，我们只需要找到合适的参数配置，来使模型具备这种能力。我同意Aaron的观点，目前讨论完全“零样本跨具身性”还为时尚早。也就是说，我们还无法做到将一个预训练好的通用模型，直接部署到任何一个新的机器人平台上，就能让机器人神奇般地完美运行。我们离这个目标还很遥远。但总有一天，我们能够实现这一目标。<br>我认为，实现“跨具身性”的关键途径之一，是拥有足够多样化的机器人硬件平台，包括真实机器人和模拟机器人。我们之前的研究团队曾进行过一项有趣的研究，虽然还只是一个探索性的项目，我们称之为“Metamorph”。在这个项目中，我们在模拟环境中程序化地生成了大量结构各异的简单机器人，这些机器人具有各种不同的关节连接方式，有些像蛇，有些像蜘蛛，形态各异，非常奇特。我们总共生成了数千种不同的机器人模型。然后，我们使用一种“机器人语法”来对机器人的身体进行“标记化”（Tokenize），本质上是将机器人的具身性转换为一个整数序列。<br>一旦我们将机器人的具身性表示为整数序列，我们就可以借鉴自然语言处理（NLP）领域的Transformer模型。正如论文“AttentionisAllYouNeed”所揭示的，Transformer模型的核心机制是注意力机制。我们将Transformer模型应用于这数千种不同的机器人具身性表示，我们发现模型实际上能够泛化到第一千零一种新的机器人具身性。<br>当然，这只是一个非常初步的实验性研究，还非常不成熟。但我相信，如果我们能够找到一种通用的“具身性描述语言”，并拥有足够多不同类型的真实机器人和模拟机器人，对它们进行标记化处理，并生成大量的数据，那么所有不同的具身性都将可以被映射到一个通用的向量空间中。如此一来，当面对一种全新的机器人具身性时，模型或许就能够将其识别为已知的具身性分布中的一个点，从而实现“跨具身性”的泛化能力。<br>我还想补充一点，研究“跨具身性”不仅仅是一种学术上的好奇心，它正逐渐成为一个非常现实的问题。我认为，在座的各位硬件公司创始人，都面临着一个共同的挑战，那就是如何解决机器人产品的代际兼容性问题。我们在上一代机器人上收集的数据，以及基于这些数据训练的模型，往往难以直接应用于新一代的机器人产品，即使是同一家公司推出的V2、V3版本机器人，模型性能也会显著下降甚至完全失效。更不用说，即使是同一代机器人产品，由于制造工艺的差异、零部件的细微偏差、以及物理世界的各种不确定性因素，不同个体机器人之间的性能也存在差异。因此，即使是同一代机器人，也存在“跨具身性”的问题，更不用说跨代机器人，以及不同公司设计的机器人产品了。我认为这正逐渐成为一个日益突出的现实问题，而我们目前的研究还只是触及了问题的表面。<br>艾伦（波士顿动力）：目前机器人硬件的多样性还远远不够。如果我们只关注人形机器人领域，会发现大家都在使用非常相似的硬件平台，基本上都是在模仿人类的身体结构。在波士顿动力，我们决定只为我们的人形机器人Atlas的机械手配备三根手指，这与当时普遍追求完全拟人化机械手的趋势背道而驰。<br>但我们发现，人类非常擅长将自身的运动技能迁移到三指机械手上。即使是远程操作员，在经过几个小时的训练后，也能够熟练地使用三指机械手完成几乎所有用五指机械手才能完成的任务。<br>因此，我认为在机器人硬件设计领域，还有巨大的探索空间。我认为，目前大家都在致力于构建通用的基础模型，因此在硬件设计方面可能还不够大胆创新。但我相信，一旦我们看到通用模型在泛化能力方面取得突破，就会有更多人开始尝试突破现有的人形机器人硬件框架的束缚，探索更多样化的机器人形态。这可能会带来好的结果，也可能带来坏的结果。或许我们最终会创造出一些与人类形态差异很大，甚至有些“恐怖谷”效应的机器人。<br>但我认为，仅仅在机械臂和末端执行器（夹爪）的设计方面，就蕴藏着巨大的创新机会。例如，AgilityRobotics的机器人Digit，其夹爪设计就与其他人形机器人截然不同，但它仍然能够完成许多相同类型的任务。因此，我认为机器人硬件的多样化设计，将是未来几年一个非常令人兴奋的研究方向。<br>范麟熙（英伟达）：Aaron，如果你能给我一千个不同的Atlas机器人，我就能帮你彻底解决“跨具身性”的问题。怎么样，成交吗？<br>艾伦（波士顿动力）：可以，说到做到。<br>主持人：听起来你们已经回答了我的下一个问题，我原本想更具体地探讨硬件方面的问题。非常感谢各位的精彩分享。但我还是想继续深入探讨硬件这个话题，因为它确实是各位都非常有洞察力，并且能从独特视角分析的一个有趣挑战。<br>刚才Jim（范麟熙）提到，即使是同一批次生产的机器人，性能也可能存在差异。这是否意味着，硬件方面目前最大的挑战之一，就是机器人个体之间的性能差异？<br>范麟熙（英伟达）：我认为机器人个体之间的性能差异，确实是目前面临的挑战之一。这也促使我们开展“跨具身性”方面的研究，探索如何弥合这些性能差异。但我认为，这个问题或许更适合由在座的产品专家来解答。<br>艾伦（波士顿动力）：我认为这又回到了我之前提到的“工具箱”的概念。在解决机器人个体性能差异的问题上，传统的机器人技术工具仍然可以发挥重要作用。<br>例如，如果我们能够为机器人开发出精密的校准方法，如果我们能够充分了解和准确描述机器人的各项性能参数，如果我们能够在关节层面进行精细的控制，也就是在人工智能层之下的底层控制方面做好充分的工作，那么机器人个体之间的性能差异就不会成为一个难以逾越的障碍。<br>我认为，如果一个机器人的性能参数无法准确标定，没有经过精密的校准，个体之间存在很大的性能差异，然后我们只是简单地为其配备一个控制器，无论是基于人工智能的策略，还是传统的控制算法，最终机器人的输出行为都会表现出很大的不确定性。但如果我们能够投入精力，在机器人标定和控制方面做好充分的工作，就可以最大限度地缩小个体之间的性能差距。普拉斯，你在这方面有什么看法吗？<br>普拉斯（Agility）：我认为解决机器人个体性能差异的另一个关键，在于将机器人真正地部署到真实世界中，在实际的制造环境中进行应用，观察和分析机器人性能的各种变异性。通过实际应用，我们可以获得大量宝贵的经验和数据，这些数据可以反过来指导我们改进机器人的设计和制造流程。<br>举个例子，我们AgilityRobotics的人形机器人Digit，其跌倒后的“恢复行为”是完全通过机器学习训练出来的。我们已经在真实世界的生产环境中部署了Digit机器人，并在实际生产线上运行。我们用于训练Digit机器人“恢复策略”的领域随机化和数据多样性，正是来源于我们在真实世界中获得的经验，以及我们机器人fleet中所有Digit机器人的性能差异数据。事实证明，我们之前在领域随机化方面投入了大量的精力，并对机器人的“恢复策略”进行了充分的鲁棒性强化。<br>当我们把训练好的“恢复策略”迁移到我们最新发布的Digit机器人，它比之前的型号重了10公斤，框架也更大，令人惊讶的是，这个策略竟然能够“一次性”成功迁移到全新的机器人平台上，无需任何调整。尽管新机器人在运动学结构、有效载荷等方面都与之前的型号有所不同，但“恢复策略”仍然能够完美适配。<br>这正是因为我们之前在“模拟到现实”的迁移过程中，花费了大量时间进行稳健性强化，深入研究了足部接触等各种细节问题。因此，我确实认为，随着经验的积累，我们在解决“跨具身性”问题方面会越来越得心应手。我们不必总是像过去那样，需要仔细研究机器人的制造序列号，才能进行软件适配。随着我们不断地实践和积累真实世界的经验，我们会逐渐理解在训练管线中需要捕捉的关键要素，从而提升模型的通用性和泛化能力。<br>伯恩特（1X）：我认为，当你将机器人部署规模从数百台扩展到数千台时，个体差异的问题就会变得更加突出。当你的机器人数量达到数千甚至数十万台时，为每一台机器人单独调整软件堆栈是不现实的。因此，解决机器人个体差异问题，实现软件的通用性和可移植性，是机器人技术走向大规模应用的必然趋势。<br>迪帕克（SkildAI）：我基本上同意你们两位的观点。我非常赞同艾伦关于“校准非常重要”的看法。但我也认为，领域随机化实际上是一个非常有趣的概念，虽然可能有点深奥。当你进行领域随机化时，你实际上是在教你的系统什么呢？你是在教它变得“保守”。你是在告诉系统，即使我不确定接下来会发生什么，只要我采取保守的策略，结果总是安全的。<br>这种“保守性”在一定程度上掩盖了系统的真实动力学特性。因此，最终的控制效果，很大程度上取决于你想要达成的目标。如果你过度依赖领域随机化，可能会牺牲系统的性能，但换来的是更强的鲁棒性。相反，如果你的机器人校准做得非常出色，你就可以最大限度地发挥系统的潜力，获得更高的性能。因此，从长远来看，精密的机器人校准仍然至关重要。<br>此外，我认为目前还有一些非常令人兴奋的研究方向，例如将机器人的历史运行数据融入到模型的上下文信息中。对于每一台机器人，我们都收集其运行时的历史数据，并将这些数据作为模型的上下文输入。这样，模型就可以在运行过程中，根据自身的历史经验，学习和适应自身的动力学特性。这种方法的效果出乎意料地好。这真的很酷，鱼与熊掌兼得，既能保证稳健性，又能提升性能。<br>范麟熙（英伟达）：我们最近发布的一项研究成果，就采用了类似的思想，我们称之为RMA，即“快速电机自适应”（RapidMotorAdaptation）。我们对“跨版本模型不兼容”这个问题，采取了一种略有不同的解决思路。我们很难期望未来只存在一种机器人平台，或者只有一家机器人公司能够垄断整个市场。就像汽车行业，手机行业一样，市场上有各种各样的公司和产品。<br>但关键在于，对于汽车、手机，甚至包括GPU这样的硬件产品，尽管英伟达生产了各种各样的GPU，但我们有CUDA这样的软件层，可以将软件与底层硬件隔离开来。操作系统也是如此。那么，机器人领域的“CUDA”或“操作系统”又是什么呢？当涉及到解决机器人技术的通用性问题时，我认为，与其他领域不同，我们不应该仅仅构建一个“只能在特定机器人平台上运行”的“大脑”，而应该构建一个“能够自适应不同机器人平台”的“大脑”。这才是关键的区别。人类的大脑之所以强大，不仅仅在于它能够完成各种各样的任务，更在于它能够“学习”完成各种各样的任务。<br>我们大脑中蕴含的是一个强大的“学习引擎”，它可以在运行过程中不断学习和适应。例如，当我们听到新的信息时，我们的大脑会立即进行学习和理解；当我们身处新的环境时，我们的大脑会迅速适应新的环境。我认为，这才是人工智能应用于机器人技术领域，与其他应用领域最根本的区别。<br>对于机器人技术而言，我们真正需要部署的，是这种“微型学习引擎”。这是因为，机器人所处的环境是动态变化的。例如，即使是人类自身，我们的身体状态也在不断变化。如果我进行高强度锻炼，一个小时后，我的手臂肌肉会感到酸痛。这时，如果我再去拿起牙刷，或者拿起水瓶，我会发现我的身体状态已经和锻炼前不同了。我的肌肉需要输出更大的力矩，才能完成同样的动作。我们的大脑能够实时地适应这些微秒级、分钟级、甚至小时级的身体变化。我认为，这才是人工智能模型应用于机器人领域的核心差异，也是与人工智能在其他领域的应用最本质的区别。<br>在其他领域，人工智能的策略相对简单：训练模型，部署模型，迭代训练，迭代部署。我们无需过多考虑模型的自适应能力，因为硬件平台的升级换代，例如英伟达GPU的性能提升，已经为软件提供了足够的性能保障。但在机器人领域，情况则完全不同。我们需要部署的是能够自主学习和适应环境变化的“学习引擎”。这使得机器人技术成为人工智能一个非常独特且极具挑战性的应用领域。<br>伯恩特（1X）：我认为，总的来说，机器人AI和数字AI之间的界限，最终会逐渐消失。我们现在经常问“人工智能能为机器人技术做些什么？”，但我们很少反过来思考“机器人技术能为人工智能做些什么？”。实际上，当机器人在真实世界中采取行动，并获得反馈时，它所产生的数据，对于人工智能的发展至关重要。当我们提出一个假设，然后在真实世界中执行一个动作，观察动作的结果，并从中学习，这正是我们人类学习知识的方式。<br>我们最近看到，人工智能在推理模型方面取得了显著进展，例如在数学和代码生成方面表现出色，因为这些领域的结果是可验证的。我们可以验证数学题的答案是否正确，可以验证代码是否能够成功编译运行。而机器人技术，则为我们提供了一个在更广泛的领域内进行“验证”和“学习”的平台。这正是我们人类学习的方式。<br>范麟熙（英伟达）：我完全同意你的观点。一个很好的例子就是“幻觉”问题。幻觉是大语言模型（LLM）面临的一个重大挑战。但大家有没有听说过机器人会产生“幻觉”？我们似乎很少讨论这个问题。为什么？因为机器人很难产生真正的“幻觉”。<br>例如，如果我“幻觉”出一个不存在的物体，或者“幻觉”出我可以用手穿过墙壁，当我试图在真实世界中执行这些“幻觉”动作时，会立刻发现这些“幻觉”与现实不符。我可以尝试推动眼前的瓶子，如果我“幻觉”出瓶子会悬浮在空中，但当我真的去推它时，它会掉到桌子上。通过与真实世界的互动，我可以立即验证我的“幻觉”是否正确，并从中学习和纠正错误。因此，与真实世界的“互动”，是消除“幻觉”的有效手段。而当我们仅仅从维基百科等被动数据源中学习时，我们很难验证所有信息的真伪，除非是数学或编程这类结果可验证的领域，幻觉问题相对较少。<br>伯恩特（1X）：是的。所以，关键在于我们需要获取更多的数据。正如你所说，我们需要“颠倒金字塔”的数据结构。不是“翻转”，而是“颠倒”。我们需要让机器人数据在互联网数据中占据更大的比例。这样，我们就可以解决目前人工智能面临的许多问题。而实现这一目标的关键，仍然是需要更多的GPU算力——这永远是最终的答案，对吧？我们今天在座的各位，都离不开GPU的支持。<br>其实我认为机器人也可能会产生某种形式的“幻觉”，只不过它表现形式不同。机器人的“幻觉”可能表现为，机器人的预期行为结果与真实世界中实际发生的结果之间存在偏差。这种偏差同样是可以验证的，就像代码生成模型生成的代码无法编译运行时，我们也可以验证代码存在“幻觉”一样。机器人的“幻觉”可能会表现为，机器人规划了一条在物理上不可行的运动轨迹，或者生成了一个无法在真实世界中实现的动作序列。<br>范麟熙（英伟达）：但我的意思是，机器人的“幻觉”是可以被消除的，因为机器人可以与真实世界进行互动。而对于那些无法与真实世界互动的系统，例如大语言模型，幻觉问题可能永远无法根除。例如，如果我问你“你现在住在哪里？”，如果我无法验证你的回答，我就永远无法判断你是否在“幻觉”，也无法纠正我的错误认知。但在机器人技术中，由于机器人可以与真实世界进行互动，我们通常可以通过互动来纠正“幻觉”。<br>伯恩特（1X）：我这里有一个非常实际的例子。实际上是去年发生在我们公司的事情。当时，我们办公室里一直存在一个“马桶座圈没人放下”的问题。为了解决这个问题，我们部署了我们之前研发的一款机器人Eve。<br>Eve机器人虽然是轮式机器人，但仍然具备一定的移动能力。我们让Eve机器人自主进入办公室的卫生间，去检查马桶座圈是处于“抬起”状态还是“放下”状态。我们在这个任务中使用了GPT-4模型。结果发现，GPT-4模型在判断马桶座圈状态时，准确率只有50%，完全是随机猜测。它根本无法准确判断马桶座圈是“抬起”还是“放下”。<br>这确实是一个比较极端的例子，因为GPT-4模型通常在图像识别方面表现非常出色。但在这个特定场景下，它却完全失效了。不过，我们随后让Eve机器人执行了一个自主策略：如果检测到马桶座圈是“抬起”状态，就将其放下。这是一个完全自主的策略。Eve机器人会在办公室里自主巡逻，检查卫生间，如果发现马桶座圈是“抬起”状态，就会将其放下。<br>这个项目非常有趣，我们从中获得了许多乐趣，也引发了很多笑声。但更重要的是，这个项目实际上是在真实世界中构建了一个“闭环反馈系统”。通过与真实世界的互动，模型可以获得“座圈已放下”的反馈信号。机器人可以“知道”座圈已经放下了，因为它自己亲手放下的。这样，模型就可以将真实世界的反馈与之前的“幻觉”进行比较和纠正。这类似于我们在其他领域使用人工智能与API或编译器等工具进行交互时构建的“闭环反馈系统”。<br>在那些系统中，人工智能系统会生成一些输出结果，然后我们通过一个验证阶段来验证结果的正确性，并将验证结果反馈回系统，用于模型的迭代优化。只不过在机器人技术中，这个“闭环反馈”的周期会更长一些，因为反馈信号需要通过物理世界才能传递回来。<br>范麟熙（英伟达）：目前的问题是，我们还不知道如何在通用场景下构建这种闭环反馈系统。我们可以针对特定的任务，例如“放下马桶座圈”，设计一个特定的解决方案。但现在的问题是，我们如何才能找到一种通用的方法，将所有任务都与真实世界进行“grounding”（锚定），从而构建一个通用的闭环反馈系统？我们目前还没有找到答案。<br>伯恩特（1X）：在真实世界中进行学习的速率，注定会非常缓慢。我们可以在真实世界中学习各种技能，因为真实世界会给我们提供反馈信号。例如，如果我们不小心掉落了物体，重力会使物体坠落，我们可以通过观察物体坠落的结果，来判断我们的动作是否正确。但是，物理机器人在真实世界中进行探索和学习的效率，仍然非常有限。这又回到了“数据混合”的问题。我们可以在真实世界中进行一些非常有趣的小规模实验，但我们需要进行多少次这样的实验，才能积累足够的数据，来训练出一个通用的机器人模型？我认为，关键问题仍然是，我们是否能够承担得起生成足够多的真实世界数据的成本？<br>范麟熙（英伟达）：但我们还有模拟技术啊。模拟技术同样具有吸引力。我认为，我们需要将真实世界数据和模拟数据结合起来，构建一个混合数据驱动的学习系统。<br>伯恩特（1X）：我同意你的观点。而模拟技术，同样需要更多的GPU算力支持。<br>主持人：好的，我知道时间快到了，我想用最后一个问题来结束今天的讨论。我非常好奇各位对未来两到五年机器人技术发展趋势的看法。这是一个非常宽泛的问题，各位可以自由发挥，畅所欲言。伯恩特，请你先来谈谈你的看法。<br>伯恩特（1X）：两到五年，考虑到机器人技术领域目前的发展速度，这是一个相当长的时间跨度。但我还是想“作弊”一下，先预测一下更长远的未来。<br>我认为，在未来十年内，机器人技术将迎来彻底的爆发。十年后，机器人技术将对社会产生颠覆性的影响，就像几百年前电力普及一样。现在，我们已经习惯了每天早上醒来，随手打开电灯开关，电力已经成为我们生活中不可或缺的一部分。<br>我认为，在未来的社会中，机器人将会在体力劳动和脑力劳动领域，扮演着与电力同样重要的角色。这将是一个非常激动人心的时代，我们有幸生活在这个时代，并有机会共同塑造未来的社会形态。在未来的社会中，人类将可以从繁重的体力劳动和重复性的脑力劳动中解放出来，从而有更多的时间和精力去追求那些真正使我们成为“人类”的事物。<br>所以，五年内实现这个目标——我希望如此，但这可能有些过于乐观。我们会朝着这个目标努力。我认为，目前没有人能够准确预测未来五年机器人技术会发展到什么程度。这很大程度上取决于社会对机器人的接受程度，以及我们扩大机器人生产规模的速度。<br>我们目前正处于一个关键的临界点，机器人技术已经开始变得“有用”了。例如，我们1X公司的机器人，虽然还不够完美，还不能完全取代人类完成所有任务，但它在家庭环境中已经能够发挥一定的作用，并且能够为人们带来乐趣。我认为，我们可以从这个“有用”的临界点出发，加速机器人技术的发展进程。我希望机器人技术的发展，不会像自动驾驶汽车那样，比我们预期的要晚十年甚至更久。但我确实认为，在未来三到五年内，机器人技术将会逐渐普及，走进千家万户。即使不是每个人都能拥有机器人，人们也会认识拥有机器人的朋友或邻居，机器人将逐渐成为社会生活中不可或缺的一部分，广泛应用于家庭、工厂、物流等各个领域。<br>迪帕克（SkildAI）：我接着伯恩特的话来说。有一句名言，人们总是高估短期内的进步，而低估长期内的进步。这句话好像是比尔·盖茨或者其他人说的，我引用一下。<br>但我认为，机器人人工智能与大语言模型（LLM）或视觉模型（VLM）最大的不同之处在于，LLM或VLM往往需要将问题几乎完全解决，才能真正发挥其应用价值。例如，无论是代码生成，还是通用文本写作，或者其他任何NLP应用，模型都必须达到非常高的性能水平，才能真正“有用”。早期的NLP系统虽然也取得了一些进展，但在性能达到质的飞跃之前，其应用价值非常有限。但机器人人工智能则有所不同。我们不必完全解决机器人技术的所有难题，机器人技术就已经可以开始发挥其应用价值了。<br>我想强调的是，即使在今天，已经有成千上万甚至数百万台机器人部署在世界各地。我们今天使用的许多产品，都是由机器人制造出来的。机器人技术已经存在于我们的生活中，并且正在发挥着重要作用。那么，机器人技术发展的关键是什么呢？我认为关键在于任务的“专业化”。能够解决所有任务、在所有场景下都通用的机器人，可能还需要很长时间才能实现，所以我不会对通用机器人的未来做出预测。<br>但我们将会看到，越来越多的“任务专家型”机器人涌现出来。这些机器人可能只能解决少数特定任务，甚至只能完成一项特定任务。即使如此，它们也具有巨大的应用价值。因为在许多领域，我们都面临着劳动力短缺的难题，很难找到足够的工人来完成特定的任务。我今天和一家公司交流，他们甚至不得不重新聘请已经退休的员工，来缓解劳动力短缺的困境。因此，我认为“专业型”机器人将会更快地走向成熟和普及，而“通用型”机器人则还需要更长的时间。但与语言模型不同，专业型机器人的应用价值，从诞生的第一天就开始显现。<br>普拉斯（Agility）：迪帕克说的非常对。如果自动驾驶汽车没有安全风险，那么自动驾驶技术在2015年就已经“解决”了。在2015年，我们已经可以乘坐自动驾驶汽车在道路上行驶，而且表现还相当不错。从某种意义上来说，自动驾驶技术已经解决了，但这并不是我们人类期望的“完全解决”。<br>我认为，挑战的一部分在于，技术普及不仅仅是一个技术问题，它还涉及到安全、社会接受度等诸多因素。因此，在未来三到五年内，我们可能会看到某些领域的机器人应用快速普及，而在另一些领域，机器人的普及速度可能会远低于我们的预期。但我认为，最重要的一点是，我们正在见证机器人技术从过去的“单一用途”向“多用途”转变。人们开始期望机器人能够执行多种不同的任务，即使还不是“通用机器人”，至少也应该是“多用途机器人”。这种期望正在逐渐成为社会的主流认知。<br>而我们通过基于人工智能的新型机器人平台所展示的，正是一台硬件平台可以高效地完成多项任务的能力。我认为，这种“多用途”的趋势，将在未来三到五年内持续发展。人们对机器人的期望值正在不断提升，越来越多的人开始认同“多用途机器人”的理念。现在在座的各位，都已经看到了这种趋势，并对此充满信心，这非常好。因为你们正在将这种期望传递给社会，推动社会文化朝着“多用途机器人”的方向发展。人们会开始思考，为什么我不能拥有一台可以在家中完成三四项不同任务的机器人？或者，为什么我的仓库或物流中心不能部署能够完成五到十项不同任务的机器人？这应该是未来的发展方向。我认为，正是人们对“多用途机器人”的强烈需求，驱动着投资和研发资源不断涌入这个领域，最终推动我们实现“多用途机器人”的愿景。<br>艾伦（波士顿动力）：当人们问到“未来机器人技术会如何发展？”这类问题时，他们往往期待得到一个非常具体、明确的答案，例如“我将在某个确定的日期拥有一台机器人，它可以完成所有我想让它做的事情”。<br>但我认为，这种期望与现实之间存在着巨大的差距。我们对于“机器人应该达到什么程度才算成功？”这个问题，并没有一个统一的标准。我经常反问自己，我们什么时候才能拥有一款人形机器人，它对我们人类的价值，能够像汽车一样重要？我不知道答案。我们的汽车每天都在各种极端天气条件下可靠运行，考虑到汽车的制造成本，以及所消耗的材料和能源，汽车的价格实际上非常低廉。即使是汽车这样成熟的产品，其价值也远不能与我们对人形机器人的期望相提并论。<br>因此，我认为，机器人技术的真正普及，还需要十年甚至更长的时间。这或许是技术专家们比较保守的预测。如果问创业公司的创始人，他们可能会说明年就能实现通用机器人。但如果问技术专家，我们通常会说，还需要大约十年时间。“十年”只是一个模糊的时间概念，意味着我们很难在短期内准确预测未来机器人技术会发展到什么程度。我认为，我们更应该关注的是机器人技术进步的速度，以及各个公司在不同应用领域取得的“滩头阵地”。今天在座的各位公司，都在不同的领域建立了自己的优势，并取得了显著的进展。随着时间的推移，这些“滩头阵地”将会不断扩大，最终连接成一片广阔的陆地。机器人技术的发展，不会是一蹴而就的，而是一个循序渐进的过程。<br>我认为，没有人能够准确预测五年后机器人技术会发展到什么程度。但我们有理由相信，机器人技术将会持续发展壮大。很快，各个公司在不同领域取得的“滩头阵地”将会开始相互交汇融合，最终汇聚成一股强大的力量，推动机器人技术实现质的飞跃，就像自动驾驶汽车一样。<br>回顾自动驾驶汽车的发展历程，人们常常诟病自动驾驶技术发展速度低于预期。很多人批评自动驾驶领域的预测过于乐观。我认为，这很大程度上是由于一些业内人士，过分夸大了自动驾驶技术的发展速度。<br>但我个人认为，即使是现在，自动驾驶技术也已经为我们带来了巨大的便利。例如，我的汽车就配备了自动车道保持辅助系统，以及自动紧急制动系统，这些功能大大提升了驾驶安全性。所有这些神奇的功能，都源于我们对“自动驾驶汽车”的梦想和追求。而且，现在我们已经可以在一些城市乘坐自动驾驶出租车了。所以，自动驾驶技术的普及，虽然比最初的预测晚了一些，但它终究还是到来了。<br>人形机器人的发展道路，可能也会与自动驾驶汽车类似，需要经历一个相对漫长的发展过程。我认为，只要整个机器人技术社区保持热情，积极投入研发，并认识到这是一场“持久战”，我们最终一定能够实现通用机器人的梦想。<br>在实现通用机器人之前，我们首先要致力于开发出能够在特定商业场景中创造价值的“专业型”机器人。我认为，在未来一两年内，我们就能看到更多这样的“专业型”机器人涌现出来。AgilityRobotics已经在向市场交付能够应用于物流领域的机器人产品。当这些机器人能够完成10项、15项、甚至20项不同的任务时，那将是未来五年内机器人技术发展的重要里程碑。而要真正解决我们在各个行业领域所面临的所有问题，实现我们对通用机器人的所有美好愿景，我认为我们还需要继续努力，持续投入研发，机器人技术行业还需要经历数十年的发展和积累，才能最终克服所有挑战，实现最终目标。<br>范麟熙（英伟达）：我非常赞同迪帕克说的，人们总是高估短期内的进步，而低估长期内的进步。因此，我想从短期和长期两个维度，来展望一下机器人技术未来的发展趋势。<br>我认为，在未来两到五年内，从技术层面来看，我们将能够充分研究“具身智能的扩展定律”。大语言模型（LLM）发展史上最重要的突破之一，就是“ChinchillaScalingLaw”（Chinchilla扩展定律）的提出。这个定律揭示了，随着我们不断增加计算资源投入，扩大训练数据规模，增加模型参数数量，模型的智能水平也会呈现指数级的增长。<br>我认为，目前机器人技术领域，还没有出现类似的“扩展定律”，因为机器人技术的扩展规律要复杂得多。我们可以从多个维度进行扩展，例如模型规模、硬件规模、模拟数据规模、互联网数据规模、以及神经模拟数据规模等等。例如，当我们生成越来越多的视频数据时，神经模拟数据的扩展规律是什么？我们还需要深入研究所有这些扩展规律，从而找到机器人技术发展的“ScalingLaw”。或许在五年后，或者更短的时间内，我们就能绘制出一张图表，清晰地展示出，当我们购买更多GPU算力时，机器人的性能会提升多少。我们将在短期内，对这个问题给出定量的解答。<br>现在，让我们展望一下20年后的未来。每次我在实验室熬夜，看到机器人因为一些奇怪的原因而发生故障时，我都会感到非常沮丧。这时，我就会开始思考20年后的机器人技术会发展到什么程度，这能让我重新振作起来，继续投入工作。<br>我认为，在20年后的未来，有两件事让我感到非常兴奋，并且我认为这两件事离我们并不遥远。第一件事是“机器人技术加速科学研究”。我有一些在生物医学领域工作的朋友，他们告诉我，做一个生物医学实验非常耗时耗力。大量的博士生需要长时间待在实验室里，照看实验动物，处理各种细胞培养皿。如果我们能够将这些实验流程自动化呢？如果我们能够实现“自动化科学”呢？这将极大地加速科学研究的进程，并降低科研成本。或许，未来医学研究的成本将不再是动辄数十亿美元，科研效率将大幅提升，因为我们拥有了通过智能技术加速物理世界运行的“API”。<br>我希望，GR00T项目能够发展到Version10或者更高的版本，最终实现这个目标。这是我非常期待的一件事。<br>另一件事是“机器人技术自动化机器人技术自身”。我们为什么不让机器人来修理机器人呢？我们现在看到，有许多大型工厂在生产机器人，那么，为什么不让机器人自己来组装下一代机器人呢？我认为这并非遥不可及的科幻幻想。实际上，在大语言模型（LLM）领域，他们又一次走在了我们前面。在LLM领域，人们正在积极研究AutoML（自动化机器学习），探索是否可以通过提示大语言模型，让其自主进行深度研究，例如，让LLM自动设计出下一代Transformer模型，或者找到更优的智能架构。目前已经有许多研究人员在积极探索这个方向。或许大语言模型会率先在这个领域取得突破，然后我们可以借鉴他们的成功经验，让物理世界也实现这种递归式的自我改进。<br>我认为这种情况一定会发生，而且不会是在一百年以后，而是在20年后就会实现。这绝对是未来发展的必然趋势。最后，我想用一个充满希望的展望来结束今天的讨论。我认为，我们这一代人，我们所有在座的各位，我们出生得太晚，没能赶上探索地球的地理大发现时代；我们出生得又太早，可能无法亲身参与星际旅行，探索其他星系。但我们却恰逢其时，躬逢其盛，见证并参与到解决机器人技术难题的伟大历史进程中。相信在不久的将来，所有能够移动的物体都将实现自主化。<br>*本文由CSDN精编整理。<br>*本场对话源自GTC2025，日程为北京时间2025年3月20日5:00AM-6:00AM。<br>点击链接回顾：<br>1.黄仁勋：全世界都搞错了ScalingLaw<br>2.杨立昆：这些领域，我全都不看好<br>3.诺姆：未来要看「单位成本智能」<br>4.人形机器人的崛起时刻<br>【活动分享】2025全球机器学习技术大会（ML-Summit）将于4月18-19日在上海举办。大会共12大主题、50+位来自学术界和一线技术实战派的顶尖专家，聚焦下一代大模型技术和生态变革技术实践。详情参考官网：http :&#x2F;&#x2F;ml-summit.org&#x2F;。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/03/26/1000002573-2247586425-1/">https://zejuncao.github.io/2025/03/26/1000002573-2247586425-1/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/AI%E7%A7%91%E6%8A%80%E5%A4%A7%E6%9C%AC%E8%90%A5/">
                                    <span class="chip bg-color">AI科技大本营</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/03/26/1000002573-2247586425-2/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000002573_2247586425_2.jpg" class="responsive-img" alt="超越 Suno，全球首个 CoT 音乐模型Mureka O1 来了！">
                        
                        <span class="card-title">超越 Suno，全球首个 CoT 音乐模型Mureka O1 来了！</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-03-26
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AI%E7%A7%91%E6%8A%80%E5%A4%A7%E6%9C%AC%E8%90%A5/">
                        <span class="chip bg-color">AI科技大本营</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/03/26/1000003176-2247546976-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003176_2247546976_1.jpg" class="responsive-img" alt="87万年薪的“氛围编码”岗火了，连代码都不用写？Karpathy：不会Swift也能1小时开发iOS应用！">
                        
                        <span class="card-title">87万年薪的“氛围编码”岗火了，连代码都不用写？Karpathy：不会Swift也能1小时开发iOS应用！</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-03-26
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%A8%8B%E5%BA%8F%E5%91%98%E5%A5%BD%E7%89%A9%E9%A6%86/">
                        <span class="chip bg-color">程序员好物馆</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
