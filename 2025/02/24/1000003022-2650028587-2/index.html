<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡, ZejunCao&#39;Blogs">
    <meta name="description" content="AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

来源：CreateAMindhttps :&amp;#x2F;&amp;#x2F;di">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000003022_2650028587_2.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                                <span class="chip bg-color">开源项目</span>
                            </a>
                        
                            <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                                <span class="chip bg-color">微信公众号聚合平台</span>
                            </a>
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                <span class="chip bg-color">人工智能学家</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-24
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/mmgAGjzGqE4SWRmx0_UBKg">AGI理论比较：主动推理、强化学习、控制论、贝叶斯大脑、效用决策、有限理性、情感动机、动态体内平衡</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>来源：CreateAMind<br>https :&#x2F;&#x2F;direct.mit.edu&#x2F;books&#x2F;oa-monograph&#x2F;5299&#x2F;Active-InferenceThe-Free-Energy-Principle-in-Mind<br>10章：ActiveInferenceasaUnifiedTheoryofSentientBehavior<br>Ingeneralweareleastawareofwhatourmindsdobest.<br>—MarvinMinsky<br>本章是主动推理的深入总结及对大量不同理论进行了深入比较。（2万字）<br>10.1简介<br>10.2各章总结<br>10.3连接点：主动推理的综合视角<br>10.4预测大脑、预测心智和预测处理（次优）<br>10.4.1预测处理<br>10.5感知<br>10.5.1贝叶斯大脑假设（次优）<br>10.6动作控制<br>10.6.1意念运动理论<br>10.6.3最优控制理论<br>10.7效用和决策<br>10.7.1贝叶斯决策理论（次优）<br>10.7.2强化学习（次优)<br>10.7.3PlanningasInference<br>10.8行为和有限理性<br>10.8.1有限理性自由能理论<br>10.9Valence,Emotion,andMotivation<br>10.10稳态动态平衡和内感受处理Homeostasis,Allostasis,andInteroceptiveProcessing<br>10.11注意力、显着性和认知动态Attention,Salience,andEpistemicDynamics<br>10.12规则学习、因果推理和快速泛化RuleLearning,CausalInference,andFastGeneralization<br>10.13主动推理和其他领域：开放方向<br>10.13.1社会和文化动态<br>10.13.2机器学习和机器人技术<br>10.14总结<br>10.1简介<br>在本章中，我们总结了主动推理的主要理论要点（来自本书的第一部分）及其实际实现（来自第二部分）。然后，我们将这些点联系起来：我们从前面章节中讨论的特定主动推理模型中抽象出来，专注于框架的集成方面。主动推理的好处之一是它为有感知力的生物体必须解决的适应性问题提供了完整的解决方案。因此，它为感知、行动选择、注意力和情绪调节等问题提供了统一的视角，这些问题通常在心理学和神经科学中被单独处理，并在人工智能中使用不同的计算方法来解决。我们将在控制论、行动思想运动理论、强化学习和最优控制等既定理论的背景下讨论这些问题（以及更多问题）。最后，我们简要讨论如何将主动推理的范围扩展到涵盖本书未深入讨论的其他生物、社会和技术主题。<br>10.2总结<br>本书系统地介绍了主动推理的理论基础和实际实现。在这里，我们简单总结一下前九章的讨论。这提供了一个机会演练主动推理的关键结构，这将在本章的其余部分中发挥作用。<br>在第1章中，我们介绍了主动推理作为理解有感知力的生物的规范方法，这些生物其环境构成了的动作感知循环的一部分（Fuster2004）。我们解释说，规范性方法从第一原理开始，得出并测试有关感兴趣现象的经验预测在这里，生物体在与生物体进行适应性（行动‑感知的环境互动循环）时持续存在在他们的环境。<br>在第2章中，我们阐述了主动推理的低级之路。这条道路始于这样的想法：大脑是一台预测机器，具有生成模型：世界上隐藏的原因如何产生感觉的概率表示（例如，从苹果反射的光如何刺激视网膜）。通过反转这个模型，它可以推断出其感觉的原因（例如，考虑到我的视网膜以某种方式受到刺激，我是否看到了一个苹果）。这种感知观点（又名感知即推理）的历史根源在于亥姆霍兹的无意识推理概念，以及最近的贝叶斯大脑假说。主动推理通过将动作控制和规划纳入推理范围内（也称为控制即推理、规划即推理）扩展了这一观点。最重要的是，它表明感知和行动并不是典型的可分离过程，而是实现相同的目标。我们首先更非正式地描述这个目标，作为模型与世界之间差异的最小化（通常减少到意外或预测误差最小化）。简而言之，人们可以通过两种方式最小化模型与世界之间的差异：改变自己的想法以适应世界（感知）或改变世界以适应模型（行动）。这些可以用贝叶斯推理来描述。然而，精确推理通常很棘手，因此主动推理使用（变分）近似（请注意，精确推理可能被视为近似推理的特殊情况）。这导致了对感知和行动的共同目标的第二个更正式的描述，即变分自由能最小化。这是主动推理中使用的核心量，并且可以根据其组成部分（例如，能量和熵、复杂性和准确性、或意外和发散）进行分解。最后，我们引入了第二种自由能：预期自由能。这在规划时尤其重要，因为它提供了一种通过考虑替代政策预期产生的未来结果来对替代政策进行评分的方法。这也可以根据其组成部分（例如，信息增益和实用价值、预期的模糊性和风险）来分解。<br>在第3章中，我们阐述了主动推理的大道。这条替代道路始于生物有机体保持完整性和避免消散的的必要性，这可以被描述为避免令人惊奇的状态。然后我们引入了马尔可夫毯子的概念：有机体内部状态和世界外部状态之间统计分离的形式化。至关重要的是，内部和外部状态只能通过中间（主动和感觉）变量（称为毯子状态）相互影响。这种统计上的分离由马尔可夫毯介导的对于赋予有机体一定程度的独立于外部世界的自主权至关重要。要理解为什么这是一个有用的观点，请考虑以下三个后果。<br>首先，具有马尔可夫毯的有机体似乎在贝叶斯意义上模拟外部环境：其内部状态平均对应于关于世界外部状态的近似后验信念approximateposteriorbelief。其次，自主性是由以下事实保证的：有机体的模型（其内部状态）不是无偏的，而是规定了一些必须维持的存在先决条件（或先验偏好），例如，对于鱼来说，处于水中。第三，有了这种形式主义，就可以将最优行为（相对于先验偏好）描述为感知和行动的（贝叶斯）模型证据的最大化。通过最大化模型证据（即不证自明），生物体确保它实现其先前的偏好（例如，鱼留在水中）并避免令人惊讶的状态。反过来，模型证据的最大化在数学上（大约）等价于变分自由能的最小化因此我们再次（以另一种方式）达到第2章中讨论的主动推理的相同中心结构。最后，我们详细介绍了最小化意外与汉密尔顿最少行动原则之间的关系。这证明了主动推理与统计物理学第一原理之间的正式关系。<br>在第4章中，我们概述了主动推理的形式方面。我们关注从贝叶斯推理到易于处理的近似的转变变分推理以及有机体通过感知和行动最小化变分自由能的最终目标。由此得到生物用来理解其世界的生成(世界)模型的重要性。我们引入了两种生成(世界)模型，使用离散变量或连续变量来表达我们对数据如何生成的信念。我们解释说，两者都提供相同的主动推理，但它们分别适用于在离散时间（如部分观察的马尔可夫决策问题）或连续时间（如随机微分方程）中表述事态的情况。</p>
<p>在第6章中，我们提供了设计主动推理模型的秘诀。我们看到，虽然所有生物都会最大限度地减少其变分自由能，但它们的行为方式不同，有时甚至相反，因为它们被赋予了不同的生成模型。因此，区分不同（例如，更简单和更复杂）生物的只是它们的生成模型不同。有丰富的可能的生成模型，它们对应于不同的生物（例如神经元）实现，并在不同的环境和生态位中产生不同的适应性或适应不良行为。这使得主动推理同样适用于表征简单的生物，如感知和寻求营养梯度的细菌，像我们这样追求复杂目标并参与丰富文化实践的复杂生物，甚至不同的个体在某种程度上，人们适当地表征了各自的特征生成模型。进化似乎已经发现了越来越复杂的大脑和身体设计结构，使生物体能够处理（和塑造）丰富的生态位。建模者可以对这一过程进行逆向工程，并根据感兴趣的生物所占据的利基类型，以生成模型的形式指定其大脑和身体的设计。这对应于一系列的设计选择（例如，使用离散或分类变量的模型、浅层或分层模型）我们在本章中对其进行了解包。<br>在第7章和第8章中，我们提供了离散和连续时间的主动推理模型的大量示例，这些示例解决了感知推理、目标导向导航、模型学习、动作控制等问题。这些示例旨在展示这些模型下的各种紧急行为，并详细说明如何在实际中指定它们的原则。<br>在第9章中，我们讨论了如何使用主动推理进行基于模型的数据分析，并恢复个体生成模型的参数，从而更好地解释任务中主体的行为。这种计算表型分析使用了本书其余部分讨论的相同形式的贝叶斯推理，但以不同的方式：它有助于设计和评估其他人（主观）模型的（客观）模型。<br>10.3连接点：主动推理的综合视角<br>几十年前，哲学家丹尼特感叹认知科学家投入了太多精力来建模孤立的子系统（例如感知、语言理解），而这些子系统的边界往往是任意的。他建议尝试对“整个鬣蜥”进行建模：一种完整的认知生物（也许是一个简单的生物）和它需要应对的环境生态位（Dennett1978）。<br>主动推理的一个好处是，它提供了生物体解决其适应性问题的方式的首要原则。本书所追求的规范方法假设可以从变分自由能最小化原理出发，并得出有关特定认知过程的含义，例如感知、行动选择、注意力和情绪调节及其神经元基础。<br>想象一个简单的生物，它必须解决诸如寻找食物或住所之类的问题。当施展为主动推理时，该生物的问题可以是用积极的术语描述，即采取行动来征求偏好的感觉（例如，与食物相关的感觉）。在某种程度上，这些偏好的感觉被包含在其生成模型中（作为先验信念），有机体正在有效地收集其模型的证据，或者更寓言性地，为其存在收集证据（即最大化模型证据或不证自明的证据）。这个简单的原理对传统上孤立地考虑的心理功能产生了影响，例如感知、行动控制、记忆、注意力、意图、情感等等。例如，感知和行动都是自我证明的，从某种意义上说，生物可以通过改变其信念（关于食物的存在）或通过改变世界，将其期望（给定其生成模型）与其感知的东西结合起来。（追求与食物相关的感觉）。记忆和注意力也可以被认为是优化同一目标。长期记忆是通过学习生成模型的参数来发展的。当信念是关于过去和未来的外部状态时，工作记忆就是信念更新。注意力是对感官输入精确度的信念的优化。规划（和意图）的形式可以通过吸引（某些）生物在替代未来中进行选择的能力来概念化，这反过来又需要时间深度的生成模型。这些预测了一系列行动将产生的结果，并对这些结果持乐观态度。这种乐观主义表现为相信未来的结果将导致首选的结果。深度时间模型还可以帮助我们理解复杂形式的展望（其中对当前的信念用于推导对未来的信念）和回顾（其中对当前的信念用于更新对过去的信念）。内感受调节和情绪的形式可以通过诉诸内部生理学的生成模型来概念化，该模型预测未来事件的allostatic后果。<br>正如上面的例子所示，从情感行为规范理论的角度研究认知和行为有一个重要的结果。这种理论并不是从组装单独的认知功能开始的，例如感知、决策和计划。相反，它首先为生物体必须解决的问题提供完整的解决方案，然后分析该解决方案以得出有关认知功能的含义。例如，哪些机制允许生物体或人造生物（例如机器人）感知世界、记住世界或计划（Verschure等人，2003年、2014年；Verschure2012年；Pezzulo、Barsalou等人，2013年；Krakauer等人）等2017）？这是一个重要的随着心理学和神经科学教科书中使用的认知功能分类法在很大程度上继承自早期哲学和心理学理论（有时称为詹姆斯主义范畴），这一趋势正在发生变化。尽管它们具有巨大的启发价值，但它们可能相当任意，或者它们可能不对应于单独的认知和神经过程（Pezzulo和Cisek2016，Buzsaki2019，Cisek2019）。事实上，这些詹姆斯式的范畴可能是我们的生成模型如何解释我们与感觉中枢的接触的候选者而不是解释这种接触。candidatesforhowourgenerativemodelsexplainourengagementwiththesensorium—asopposedtoexplainingthatengagement例如，“我正在感知”的唯我论假设只是我对当前事态的解释，包括我的信念更新。<br>采用规范视角也可能有助于识别不同领域研究的认知现象之间的形式类比。<br>一个例子是勘探和开发explorationandexploitation之间的权衡，它以各种形式出现（Hillsetal.2015）。这种权衡经常在觅食过程中进行研究，此时生物必须在利用以前的成功计划和探索新的（可能更好）的计划之间做出选择。然而，当生物可以在利用当前最佳计划与投入更多时间和认知努力来探索其他可能性之间做出选择时，在利用有限资源（例如，时间限制或搜索努力）进行记忆搜索和深思熟虑期间，也会发生同样的权衡。用自由能来表征这些明显不相关的现象可能会揭示深层的相似性（Friston,Rigolietal.2015；Pezzulo,Cartonietal.2016；GottwaldandBraun2020）。最后，除了对心理现象的统一视角之外，主动推理还提供了一种理解相应神经计算的原则方法。换句话说，它提供了一种将认知处理与（预期的）神经元动力学联系起来的过程理论。主动推理假设与大脑、思想和行为有关的一切行为可以用最小化自由变分来描述活力。反过来，这种最小化具有可以凭经验验证的特定神经特征（例如，在消息传递或大脑解剖学方面）。在本章的其余部分中，我们将探讨主动推理对心理功能的一些影响就像我们在绘制一本心理学教科书一样。对于每个函数，我们还强调了主动推理与文献中其他流行理论之间的一些联系（或分歧）。<br>10.4预测大脑、预测心智和预测处理（次优）<br>Ihavethispictureofpurejoy<br>it’sofachildwithagun<br>he’saimingstraightinfrontofhimself,<br>shootingatsomethingthatisn’tthere.<br>—Afterhours,“Quellochenonc’è”(Somethingthatisn’tthere)<br>传统的大脑和认知理论强调从外部刺激到内部表征，然后是运动动作的前馈转换。这被称为“三明治模型”，因为刺激和反应之间的一切都被贴上“认知”标签（Hurley2008）。从这个角度来看，大脑的主要功能是将传入的刺激转化为适合情境的反应。主动推理与这种观点有很大不同，它强调大脑和认知的预测和目标导向方面。用心理学术语来说，主动推理生物（或其大脑）是概率推理机器，它根据其生成模型不断生成预测。不证自明的生物以两种基本方式使用它们的预测。首先，他们将预测与传入数据进行比较，以验证他们的假设（预测编码），并在较慢的时间尺度上修改他们的模型（学习）。其次，他们制定预测来指导他们收集数据的方式（主动推理）。通过这样做，主动推理生物满足了两个必要条件：认知（例如，视觉探索存在显着信息的地方，可以解决假设或模型的不确定性）和实用（例如，移动到可以进行首选观察（例如奖励）的位置。安全）。认知命令使感知和学习过程变得活跃，而实用命令使行为目标导向。<br>10.4.1预测处理<br>这种以预测和目标为中心的大脑和认知观点与预测处理（PP）密切相关（并为其提供了灵感）：这是心灵哲学和认识论中的一个新兴框架，它将预测视为预测的核心。大脑和认知，并诉诸“预测性大脑”或“预测性思维”的概念（Clark2013，2015；Hohwy2013）。有时，PP理论会吸引主动推理的特定功能及其一些结构，例如生成模型、预测编码、自由能、精确控制和马尔可夫毯子，但有时它们会吸引其他结构，例如耦合逆和耦合逆向推理。前向模型，不属于主动推理的一部分。因此，与主动推理相比，术语“预测处理”的含义更广泛（且限制更少）。<br>预测处理理论在哲学引起了人们的广泛关注，因为它们在许多意义上具有统一的潜力：跨越多个认知领域，包括感知、行动、学习和心理病理学；从较低水平（例如，感觉运动）到较高水平的认知处理（例如，心理结构）；从简单的生物有机体到大脑、个体以及社会和文化结构。PP理论的另一个吸引力是它们使用概念术语，例如信念和惊讶，这涉及哲学家熟悉的心理分析水平（需要注意的是，有时这些术语可能具有与常见用法不同的技术含义）。然而，随着对PP兴趣的增长，哲学家们对其理论和认识论含义有不同的看法，这一点变得越来越明显。例如，它被解释为内在主义（Hohwy2013）、体现或基于行动（Clark2015）以及行动主义和非表征术语（Bruinebergetal.2016，Ramsteadetal.2019）。围绕这些概念解释的争论超出了本书的范围。<br>10.5感知<br>Youcan’tdependonyoureyeswhenyourimaginationisoutoffocus.<br>—MarkTwain<br>主动推理将感知视为基于如何生成感官观察的生成模型的推理过程。贝叶斯规则本质上是反转模型，根据观察结果来计算有关环境隐藏状态的信念。这种“感知即推理”的想法可以追溯到亥姆霍兹（Helmholtz，1866），并且经常在心理学、计算神经科学和机器学习（例如综合分析）中被重新提出。面临具有挑战性的感知问题，例如破坏基于文本的CAPT‑CHA(Georgeetal.2017)。<br>10.5.1贝叶斯大脑假设（次优）<br>这一想法最突出的当代表达是贝叶斯大脑假说，该假说已应用于决策、感觉处理和学习等多个领域（Doya2007）。主动推理通过将变分自由能最小化的要求推导出来，为这些推理思想提供了规范基础。正如同样的命令延伸到动作动力学，主动推理自然地模拟了主动感知以及有机体主动采样观察结果来测试其假设的方式（Gregory1980）。相反，在贝叶斯大脑议程下，感知和行动根据不同的命令进行建模（其中行动需要贝叶斯决策理论；参见第10.7.1节）。更广泛地说，贝叶斯大脑假说指的是一系列不一定是整合的方法，并且经常做出不同的经验预测。例如，这些包括大脑执行贝叶斯最佳感觉运动和多感觉整合的计算级建议（KordingandWolpert2006），大脑实现贝叶斯推理的特定近似的算法级建议，例如决策‑通过采样（Stewart等人，2006年），以及关于神经群体执行概率计算或编码概率分布的具体方式的神经级提案例如，作为样本或概率群体代码（Fiser等人，2006年）。2010，Pouget等人。2013）。在每个解释层面上，该领域都有相互竞争的理论。例如，通常诉诸精确贝叶斯推理的近似值来解释与最佳行为的偏差，但不同的工作考虑不同的（且并不总是兼容的）近似值，例如不同的采样方法。更广泛地说，不同级别的提案之间的关系并不总是直接的。这是因为贝叶斯计算可以通过多种算法方式实现（或近似），即使没有明确表示概率分布（Aitchison和Lengyel2017）。<br>主动推理提供了一个更综合的视角，将规范原则和过程理论联系起来。在规范层面，其核心假设所有过程都最小化变分自由能。相应的推理过程理论使用自由能梯度下降，这具有明确的神经生理学含义，在第5章中进行了探讨（Friston、FitzGerald等人，2016年）。更广泛地说，我们可以从自由能最小化原理出发，推导出对大脑的影响架构例如，感知推理的规范过程模型（在连续时间）是预测编码。预测编码最初由Rao和Ballard(1999)提出作为分层感知处理理论，用于解释一系列记录在案的自上而下效应，这些效应很难与前馈架构以及已知的生理事实相一致（例如，感觉层次中存在前向或自下而上和后向或自上而下的连接）。然而，在某些假设下，例如拉普拉斯近似（Friston2005），预测编码可以从自由能最小化原理导出。此外，连续时间内的主动推理可以被构建为预测编码到动作领域的定向延伸通过赋予预测编码代理运动反射（Shippetal.2013）。这将我们引向下一点。<br>10.6动作控制</p>
<p>—MartinLutherKing<br>在主动推理中，动作处理类似于感知处理，因为两者都受到前向预测（分别是外感受和本体感受）的指导。正是“我的手抓住杯子”的（本体感受）预测引发了抓握动作。动作和知觉之间的等价性也存在于神经生物学层面：运动皮层的结构与感觉皮层的组织方式相同作为预测编码结构，不同之处在于它可以影响脑干和大脑中的运动反射。脊柱（Shippetal.2013）并且它接收到的上升输入相对较少。电机Motor反射允许通过沿着所需的方向设置“平衡点”来控制运动轨迹对应于平衡点假设的想法（费尔德曼，2009）。重要的是，启动一个动作（例如抓起一个杯子）需要适当调节先前信念和感觉流的精度（逆方差）。这是因为这些精度的相对值决定了生物处理其先前信念（它拿着杯子）和它的感官输入（表明它没有拿着杯子）之间的冲突的方式。根据相互矛盾的感官证据，先前关于抓杯子的不精确信念可以很容易地被修正导致改变想法而不采取任何行动。相反，当先验信念占主导地位（即具有更高的精确度）时，即使面对相互冲突的感官证据，它也会被维持，并且会引发解决冲突的抓住行动。为了确保这种情况，动作启动会引起短暂的感觉衰减（或降低感觉预测错误的权重）。这种感觉衰减的失败可能会产生适应不良的后果，例如无法启动或控制运动（Brownetal.2013）。<br>10.6.1意念运动理论<br>在主动推理中，行动源于（本体感受）预测，而不是运动命令（Adams、Shipp和Friston2013）。这个想法将主动推理与行动的意念ideomotor运动理论联系起来：一个理解行动控制的框架，可以追溯到威廉·詹姆斯（1890）和后来的“事件编码”和“预期行为控制”理论（Hommeletal.2001，霍夫曼2003）。意念运动理论表明，动作‑效果联系（类似于前向模型）是认知架构中的关键机制。重要的是，这些链接可以双向使用。当它们用于作用‑效果方向时，它们允许生成感官预测；当它们用于效果‑动作方向时，它们允许选择实现所需感知结果的动作这意味着动作是根据其预测的结果来选择和控制的（因此称为“ideo+motor”）。这种行动控制的预期观点得到了大量文献的支持，这些文献记录了（预期的）行动后果对行动选择和执行的影响（Kundeetal.2004）。主动推理提供了这一想法的数学特征，其中还包括其他机制，例如精确控制和感觉衰减的重要性，这些机制在意念运动理论中尚未得到充分研究（但与意念运动理论兼容）。<br>10.6.2控制论<br>主动推理与控制论思想密切相关，这些思想涉及行为的有目的的、目标导向的性质以及（基于反馈的）主体与环境交互的重要性，如TOTE（测试、操作、测试、退出）和相关的例子所示。模型（Miller等人，1960年；Pezzulo、Baldassarre等人，2006年）。在TOTE和主动推理中，动作的选择是由首选（目标）状态和当前状态之间的差异决定的。这些方法不同于简单的刺激‑反应关系，正如行为主义理论和强化学习等计算框架中更常见的假设（Sutton和Barto1998）。<br>主动推理中的动作控制概念特别类似于感知控制理论（Powers1973）。感知控制理论的核心概念是受控制的是感知状态，而不是运动输出或动作。在驾驶时,我们所控制的——并且在面对干扰时保持稳定——是我们的参考或期望速度(例如,90英里&#x2F;小时),如速度计所指示的,而我们为此选择的动作(例如,加速或减速)更易变并且依赖于上下文。例如,根据干扰(例如,风、陡峭的道路或其他汽车),我们需要加速或减速来保持参考速度。这一观点实现了威廉·詹姆斯(1890)的建议,即“人类通过灵活的手段实现稳定的目标<br>虽然在主动推理和感知控制理论中，控制动作的是感知（特别是本体感受）预测，但这两种理论在控制的操作方式上有所不同。在主动推理（而不是感知控制理论）中，动作控制具有基于生成模型的预期或前馈方面。相反，感知控制理论假设反馈机制在很大程度上足以控制行为，而尝试预测干扰或施加前馈（或开环）控制是毫无价值的。不过，这种反对意见主要是指在解决使用逆控制理论的局限性正向模型（参见下一节）。在主动推理下，生成或前向模型不用于预测干扰，而是用于预测未来（期望的）状态和通过行动实现的轨迹，并推断感知事件的潜在原因。<br>最后，主动推理和感知控制理论之间的另一个重要联系点是它们概念化控制层次结构的方式。感知控制理论提出，更高层次的控制低层次是通过设置参考点或设定点（即他们必须实现的目标），让他们自由选择实现目标的手段，而不是通过设置或偏向较低级别必须执行的行动（即，如何操作）。这与大多数分层和自上而下控制理论形成鲜明对比，在这些理论中，较高级别要么直接选择计划（Botvinick2008），要么偏向较低级别的行动或运动命令的选择（Miller和Cohen2001）。与感知控制理论类似，在主动推理中，人们可以根据目标和子目标的（自上而下）级联分解层次控制，这些目标和子目标可以在适当的（较低）级别自主实现。此外，在主动推理中，控制层次的不同级别所表示的目标的贡献可以通过激励过程进行调节（精确加权），从而优先考虑更显着或更紧急的目标（Pezzulo，Rigoli），和弗里斯顿2015，2018）。<br>10.6.3最优控制理论<br>主动推理解释动作控制的方式与神经科学中的其他控制模型显著不同，例如最优控制理论（Todorov2004，Shadmehretal.2010）。该框架假设大脑的运动皮层使用将刺激映射到反应的（反应性）控制策略来选择动作。相反，主动推理假设运动皮层传达预测，而不是命令。此外，虽然最优控制理论和主动推理都吸引内部模型，但它们以不同的方式描述内部模型（Friston2011）。在最优控制中，两种内部模型之间存在区别：逆模型对刺激响应偶然事件进行编码并选择运动命令（根据某些成本函数），而正向模型对行动结果偶然事件进行编码并为逆模型提供模拟结果。输入来代替噪声或延迟反馈，从而超越了纯粹的反馈控制方案。逆向和正向模型还可以在与外部动作感知分离的循环中运行（即，当输入和输出被抑制时），以支持动作序列的内部“假设”模拟。这种对动作的内部模拟与各种认知功能有关，例如社会领域的计划、动作感知和模仿（Jeannerod2001，Wolpert等人2003）以及各种运动障碍和精神病理学（Frith等人）.2000）。<br>与正向‑逆向建模方案相反，在主动推理中，正向（生成）模型负责动作控制的繁重工作，而逆向模型则非常简单，并且通常简化为在外周水平（即在脑干或大脑中）解决的简单反射。当预期状态和观察到的状态（例如，期望的、当前的手臂位置）之间存在差异时，即感官预测误差，就会开始采取行动。这意味着电机命令相当于正向模型做出的预测，而不是最优控制中逆向模型计算的结果。感觉（更准确地说，本体感受）预测误差通过动作（即手臂运动）来解决。通过行动填补的空白被认为非常小，以至于不需要复杂的逆模型，但需要简单得多的运动反射（Adams、Shipp和Friston20131).运动反射比逆模型更简单的原因在于，它不编码从推断的世界状态到动作的映射，而是编码动作和感觉结果之间更简单的映射。参见Friston、Daunizeau等人。（2010）进一步讨论。最佳电机控制和主动控制之间的另一个关键区别推论是，前者使用成本或价值函数的概念来激励行动，而后者则用贝叶斯先验概念（或先验偏好，隐含在预期自由能中）取代它正如我们在下一节。<br>10.7效用和决策<br>Actionexpressespriorities.<br>—MahatmaGandhi<br>状态成本或价值函数的概念是许多领域的核心，例如最优运动控制、效用最大化的经济理论和强化学习。例如，在最优控制理论中，到达任务的最优控制策略通常被定义为最小化特定成本函数的策略（例如，更平滑或具有最小的加加速度）。在强化学习问题中，例如在包含一种或多种奖励的迷宫中导航，最优策略是允许最大化（折扣）奖励同时最小化移动成本的策略。这些问题通常使用贝尔曼方程（或连续时间的哈密尔顿‑雅可比‑贝尔曼方程）来求解，其一般思想是决策的问题可以分解为两部分：立即奖励和决策问题剩余部分的价值。这种分解提供了动态规划的迭代过程，这是控制理论和强化学习（RL）的核心（Bellman1954）。<br>主动推理与上述方法有两个主要不同之处。首先，主动推理不仅仅考虑效用最大化，而是考虑（预期）自由能最小化的更广泛目标，其中还包括其他（认知）命令，例如消除当前状态的歧义和寻求新颖性（见图2.5）。这些额外的目标有时会添加到经典奖励中，例如作为“新奇奖励”（Kakade和Dayan2002）或“内在奖励”（Schmidhuber1991，Oudeyer等人2007，Baldassarre和Mirolli2013，Gottlieb等人2013）但它们在主动推理中自动出现，使其能够解决探索‑利用平衡。原因是自由能是信念的函数，这意味着我们处于信念优化领域，而不是外部奖励函数。这对于探索性问题至关重要，其中的成功取决于解决尽可能多的不确定性。<br>其次，在主动推理中，成本的概念被吸收到先验中。先验（或先验偏好）指定了控制目标，例如要遵循的轨迹或要到达的终点。使用先验来编码首选观察结果（或序列）可能比使用实用程序更具表现力（Friston、Daunizeau和Kiebel2009）。使用这种方法，寻找最优策略被重新定义为一个推理问题（实现首选轨迹的一系列控制状态），并且不需要价值函数或贝尔曼方程尽管可以诉诸类似的方法如递归逻辑（Friston、DaCosta等人，2020）。主动推理和强化学习中通常使用先验函数和值函数的方式之间至少存在两个根本区别。首先，强化学习方法使用状态或状态‑动作对的值函数，而主动推理则使用观测值的先验。其次，价值函数是根据遵循特定策略的状态（或在状态中执行操作）的预期回报来定义的，即从该状态开始然后获得的未来（贴现）奖励的总和执行政策。相比之下，在主动推理中，先验通常不会对未来的奖励进行求和，也不会对其进行折扣。相反，当预期自由能达到时，类似于预期回报的东西才会出现在主动推理中。这意味着预期自由能是最接近价值函数的模拟。然而，即使如此，预期自由能是关于state的信念的函数，而不是state的函数afunctionalofbeliefsaboutstates,notafunctionofstates，这一点也有所不同。话虽如此，构建类似于RL中状态的价值函数的先验是可能的，例如，通过缓存这些状态中的预期自由能计算（Friston、FitzGerald等人，2017）。2016年；迈斯托、弗里斯顿和佩祖洛(2019)。<br>此外，将效用utility的概念吸收到先验中有一个重要的理论结果:先验扮演目标的角色，并使生成模型有偏见——或乐观,在某种意义上,生物相信它会遇到更好的结果。正是这种乐观使推断的计划在积极的推理中达到预期的结果;这种乐观的失败可能对应于冷漠(Hezemansetal.2020)。这与其他正式的决策方法形成了鲜明的对比,例如贝叶斯决策理论,它将事件的概率与其效用分开。话虽如此,这种区分有些肤浅,因为效用函数总是可以被重写为编码先验信念,这与最大化效用函数的行为是先验的(通过设计)更有可能的事实是一致的。从通货紧缩的角度来看(稍微有点偏离逻辑)，这就是效用的定义。<br>10.7.1贝叶斯决策理论（次优）<br>贝叶斯决策理论是一个数学框架，它将贝叶斯大脑的思想（如上所述）扩展到决策、感觉运动控制和学习领域（KordingandWolpert2006，Shadmehretal.2010，WolpertandLandy2012）。贝叶斯决策理论根据两个不同的过程来描述决策。第一个过程使用贝叶斯计算来预测未来（行动或政策相关）结果的概率，第二个过程使用（固定或学习的）效用或成本函数定义对计划的偏好。最终决策（或行动选择）过程整合了两个流，从而选择（以更高的概率）具有更高概率产生更高奖励的行动计划。这与主动推理形成鲜明对比，在主动推理中，先验分布直接表明什么对有机体有价值（或者在进化历史中什么是有价值的）。然而，贝叶斯决策理论的两个流派与变分自由能和预期自由能的优化之间可以分别进行相似之处。在下面主动推理，变分自由能的最小化提供了关于世界状态及其可能演化的准确（且简单）的信念。先前的信念是，通过政策选择，预期的自由能将被最小化，这包含了偏好的概念。<br>在一些圈子里，人们对贝叶斯决策理论的地位感到担忧。这是从完整的类定理（Wald1947，Brown1981）得出的，该定理说，对于任何给定的决策和成本函数对，存在一些使贝叶斯决策最优的先验信念。这意味着在单独处理先验信念和成本函数时存在隐含的二元性或简并性。从某种意义上说，主动推理通过将效用或成本函数吸收到偏好形式的先验信念中来解决这种退化问题。<br>10.7.2强化学习（次优）<br>强化学习（RL）是一种解决马尔可夫决策问题的方法，在人工智能和认知科学中都很流行（Sutton和Barto1998）。它侧重于智能体如何通过反复试验来学习策略（例如，杆平衡策略）：通过尝试行动（例如，向左移动）并根据行动成功（例如，杆平衡）或接收积极或消极的强化失败（例如，杆子掉落）。<br>主动推理和强化学习解决了一系列重叠的问题，但在数学和概念上在许多方面有所不同。如上所述，主动推理省去了奖励、价值函数和贝尔曼最优性的概念，而这些概念是强化学习方法的关键。此外，政策概念在两个框架中的使用方式也不同。在强化学习中，策略表示一组需要学习的刺激‑响应映射。在主动推理中，策略是生成模型的一部分：它表示需要推断的一系列控制状态。<br>强化学习方法有很多，但它们可以分为三个主要类别。前两种方法尝试学习良好的（状态或状态动作）价值函数，尽管以两种不同的方式。<br>RL的无模型方法直接从经验中学习价值函数：它们执行操作、收集奖励、更新其价值函数，并使用它们来更新其策略。它们被称为无模型的原因是因为它们不使用允许预测未来状态的（转换）模型类似于主动推理中使用的那种。相反，它们隐含地诉诸于更简单的模型（例如，状态‑动作映射）。无模型强化学习中的学习价值函数通常涉及计算奖励预测错误，如流行的时间差异规则。虽然主动推理经常引起预测错误，但这些都是状态预测错误（因为主动推理中没有奖励的概念）。<br>基于模型的强化学习方法不会直接从经验中学习价值函数或策略。相反，他们从经验中学习任务模型，使用该模型进行计划（模拟可能的经验），并根据这些模拟经验更新价值函数和策略。虽然主动推理和强化学习都适合基于模型的规划，但它们的使用方式有所不同。在主动推理中，规划是计算每个策略的预期自由能，而不是更新价值函数的手段。可以说，如果预期自由能被视为价值函数，则可以说使用生成模型得出的推论用于更新该函数，从而在这些方法之间提供了一个类比点。<br>强化学习方法的第三个系列是策略梯度方法，它试图直接优化策略，而不需要中间值函数，而中间值函数是基于模型和无模型强化学习的核心。这些方法从参数化策略开始，能够生成（例如）运动轨迹，然后通过更改参数来优化它们，以在轨迹导致高（低）正奖励时增加（减少）策略的可能性。这种方法将策略梯度方法与主动推理联系起来，这也省去了价值函数（Millidge2019）。然而，政策梯度的总体目标（最大化长期累积奖励）不同来自主动推理。<br>除了主动推理和强化学习之间的形式差异之外，还存在一些重要的概念差异。一个区别在于这两种方法如何解释目标导向行为和习惯行为。在动物学习文献中，目标导向的选择是通过对行动与其结果之间的偶然性的（前瞻性）知识来调节的（DickinsonandBalleine1990），而习惯性选择不是前瞻性的，而是依赖于更简单的选择（例如，刺激‑反应）机制。强化学习中的一个流行观点是，目标导向和习惯性选择分别对应于基于模型和无模型的强化学习，并且这些选择是并行获得的，并不断竞争以控制行为（Dawetal.2005）。<br>相反，主动推理将目标导向和习惯性选择映射到不同的机制。在主动推理（离散时间）中，策略选择本质上是基于模型的，因此符合目标导向的深思熟虑选择的定义。这与基于模型的强化学习中发生的情况类似，但有所不同。在基于模型的强化学习中，行动是在预期中选择的方式（使用模型）但以反应方式进行控制（使用刺激‑反应政策）；在主动推理中，可以通过实现本体感受预测以主动的方式控制动作（关于动作控制，请参阅第10.6节）。<br>在主动推理中，可以通过执行目标导向的策略，然后缓存有关哪些策略在哪些上下文中成功的信息来获得习惯。缓存的信息可以合并为策略的先验值（Friston、FitzGerald等人，2016年；Maisto、Friston和Pezzulo，2019年）。该机制允许无需深思熟虑地执行具有较高先验价值（在给定上下文中）的策略。这可以简单地被认为是通过多次参与一项任务来观察“我做了什么”并了解到“我是那种倾向于这样做的生物”。与无模型强化学习不同，在无模型强化学习中，习惯是独立于目标导向的策略选择而获得的，而在主动推理中，习惯是通过反复追求目标导向的策略（例如，通过缓存其结果）来获得的。<br>在主动推理中，目标导向和习惯机制可以合作而不仅仅是竞争。这是因为对政策的先验信念取决于习惯项（政策的先验值）和深思熟虑的项（预期自由能）。主动推理的分层阐述表明，反应性和目标导向的机制可以按层次结构排列，而不是并行路径（Pezzulo、Rigoli和Friston2015）。<br>最后，值得注意的是主动推理和强化学习在以下方面有细微的区别：2012）。在这些方法中，规划是通过推断后验进行的他们如何看待行为及其原因。强化学习源自行为主义理论，认为行为是由强化介导的试错学习的结果。相反，主动推理假设行为是推理的结果。这将我们引向下一点。<br>10.7.3PlanningasInference<br>就像可以将感知问题转化为推理问题一样，也可以将控制问题转化为（近似）贝叶斯推理（Todorov2008）。与此相一致，在主动推理中，规划被视为推理过程：对生成模型的一系列控制状态进行推理。这个想法与其他方法密切相关，包括控制即推理（Rawliketal.2013，Levine2018）、规划即推理（Attias2003，Botvinick和Toussaint2012）以及风险敏感和KL控制（卡彭等人。2012）。规划通过使用动态生成模型推断动作或动作序列的后验分布来进行，该动态生成模型编码状态、动作和未来(预期)状态之间的概率偶然性。最佳行动或计划可以通过观察未来回报(佩祖洛和里戈利2011年，索尔维和伯特温尼克2012年)或最佳未来轨迹(莱文2018年)的条件生成模型来推断。例如，可以将模型中的未来期望状态固定(即，固定其值),然后推断出更有可能填补从当前状态到未来期望状态的差距的动作序列<br>主动推理、推理规划和其他相关方案使用前瞻性控制形式，该控制形式从未来待观察状态的明确表示开始，而不是从一组刺激响应规则或政策开始。更常见的是最优控制理论和强化学习。然而，控制和规划作为推理的具体实现至少在三个维度上有所不同即，它们使用什么形式的推理（例如，采样或变分推理），它们推理什么（例如，后验分布）动作或动作序列），以及推理的目标（例如，最大化最优条件的边际可能性或获得奖励的概率）。<br>主动推理对每个维度都采取独特的视角。<br>首先，它使用可扩展的近似方案（变分推理）来解决规划即推理过程中出现的具有挑战性的计算问题2。其次，它提供基于模型的规划，或对控制状态的后验推断对应于行动序列或策略，而不是单个行动。第三，为了推断行动序列，主动推理考虑了预期的自由能泛函，它在数学上包含了其他广泛使用的规划即推理方案（例如KL控制），并且可以处理不明确的情况（Friston、Rigoli等人，2015年）。<br>10.8行为和有限理性<br>Thewiseareinstructedbyreason,averagemindsbyexperience,thestupidbynecessityandthebrutebyinstinct.<br>—MarcusTulliusCicero<br>主动推理中的行为自动结合了多个组成部分：深思熟虑的、坚持不懈的和习惯性的（Parr2020）。想象一下一个人正走向她家附近的一家商店。如果她预见到后果根据她的行为（例如，左转或右转），她可以制定一个到达商店的好计划。这种深思熟虑的行为是由预期的自由能提供的，当一个人以某种方式采取行动以实现首选观察时（例如，在商店里），预期的自由能会最小化。请注意，预期的自由能还包括减少不确定性的动力，这可以在深思熟虑中体现出来。例如，如果该人不确定最佳方向，她可以移动到适当的有利位置，从那里她可以轻松找到通往商店的路，即使这意味着更长的路线。简而言之，她的计划获得了认知affordance可供性。<br>如果该人不太能够进行思考（例如，因为她分心），她可能会在到达商店后继续行走。行为的这种持久性是由变分自由能提供的，当人们收集与当前信念（包括关于当前行为过程的信念）相一致的观察结果时，变分自由能就会最小化。人收集的感官和前本体感受观察为“行走”提供了证据，因此可以在没有深思熟虑的情况下决定坚持不懈。<br>最后，当这个人不太能够深思熟虑时，他可以做的另一件事是选择通常的回家计划，而不需要考虑它。这种习惯成分是由策略的先验值提供的。这可能会为回家的计划分配很高的概率她观察到自己过去多次制定了这个计划如果不经过深思熟虑的话，它可能会成为主导。<br>请注意，行为的深思熟虑、坚持不懈和习惯性方面是共存的，并且可以在主动推理中结合起来。换句话说，我们可以推断，在这种情况下，一种习惯是最有可能的行动方案。这与“双重理论”不同，“双重理论”假设我们是由两个独立的系统驱动的，一个是理性的，一个是直觉的（Kahneman2017）。行为的深思熟虑、坚持不懈和习惯性方面的混合似乎取决于情境条件，例如人们可以在可能具有高复杂性成本的深思熟虑过程中投入的经验量和认知资源量3。<br>认知资源对决策的影响已在有限理性的框架下得到了广泛的研究（Simon1990）。其核心思想是，虽然理想的理性主体应该始终充分考虑其行为的结果，但有限理性主体必须平衡计算的成本、努力和及时性，例如，审议最佳计划的信息处理成本（Todorov2009，Gershman等人2015）。<br>10.8.1有限理性自由能理论<br>有限理性是根据亥姆霍兹自由能最小化来表达的：一种与主动推理中使用的变分自由能概念严格相关的热力学结构；有关详细信息，请参阅Gottwald和Braun(2020)。“有限理性的自由能理论”根据自由能的两个组成部分：能量和熵，阐述了行动选择与有限信息处理能力的权衡（见第二章）。前者代表选择的预期价值（准确度术语），后者代表深思熟虑的成本（复杂性术语）。在深思熟虑过程中，代价高昂的是在选择使信念更加精确之前降低信念的熵（或复杂性）（OrtegaandBraun2013，Zénonetal.2019）。直观上，具有更精确的后验信念的选择会更准确（并且可能需要更高的效用），但由于提高信念的精确度是有成本的，因此有界决策者必须找到折衷方案通过最小化自由能。同样的权衡也出现在主动推理中，从而产生了有限理性的形式。有限理性的概念也与证据变分界限（或边际可能性）的使用产生共鸣，这是主动推理的一个确定方面。总之，主动推理提供了（有限）理性和最优性的模型，其中给定问题的最佳解决方案来自互补目标之间的折衷：准确性和复杂性。这些目标源于规范（自由能最小化）的要求，它比经济理论中通常考虑的经典目标（例如效用最大化）更丰富。<br>10.9Valence,Emotion,andMotivation<br>Consideryourorigins:youwerenotmadetoliveasbrutes,buttofollowvirtueandknowledge.<br>—DanteAlighieri<br>主动推理侧重于（负）自由能作为适应性和有机体实现其目标的能力的衡量标准。虽然主动推理提出生物会采取行动来最小化它们的自由能，但这并不意味着它们必须计算它。一般来说，处理自由能的梯度就足够了。以此类推，我们不需要知道我们的海拔高度即可找到山顶，但只需沿着斜坡向上即可。然而，一些人建议生物可以模拟它们的自由能如何随时间变化。这一假设的支持者认为，它可能允许对valence,emotion,andmotivation.等现象进行表征。</p>
<p>具体来说，当一个生物的自由能随着时间的推移而增加时，它可能会为这种情况分配一个负价；而当它的自由能随着时间的推移而减少时，它可能会赋予它正价。将这一思路延伸到自由能（和二阶导数）的长期动态，也许可以描述复杂的情绪状态；例如，从低价态过渡到高价态的欣慰，或者从高价态过渡到低价态的失望。监测自由能动态（以及它们引发的情绪状态）可能允许根据长期环境统计数据调整行为策略或学习率。<br>假设第二个生成模型的作用是监控第一个生成模型的自由能，这似乎有点跳跃。然而，这些想法还可以通过另一种方式来解释。这些观点的一个有趣的形式化在于思考是什么导致了自由能的快速变化。由于它是信念的函数，自由能的快速变化必定是由于信念的快速更新。该速度的关键决定因素是精度precision，它在预测编码的动态中充当时间常数。有趣的是，这与自由能高阶导数的概念相关，因为精度是二阶导数的负数（即自由能的曲率curvatureofafreeenergylandscape）。然而，这引出了一个问题：为什么我们应该将精度与效价联系起来。答案来自于注意到精确性与模糊性成反比。事物越精确，其解释就越不模糊。选择最小化预期自由能的行动方案也意味着最小化模糊性，从而最大化精度。在这里，我们看到自由能的高阶导数、其变化率和动机行为之间的直接关联。<br>对自由能（增加或减少）的期望也可能发挥激励作用并激励行为。在主动推理中，代理对自由能变化（增加或减少）的预期是对政策信念的精确性。这再次凸显了二阶统计量的重要性。例如，高度精确的信念表明人们已经找到了一项好的政策，即一项可以自信地预期能够最大限度地减少自由能的政策。有趣的是，政策（信念）的精确性与多巴胺信号传导有关（FitzGerald、Dolan和Friston2015）。从这个角度来看，提高政策信念精确度的刺激会引发多巴胺爆发这可能表明它们的激励显着性（Berridge2007）。这种观点可能有助于阐明将目标或奖励实现的期望与注意力的增加（Andersonetal.2011）和动机（BerridgeandKringelbach2011）联系起来的神经生理学机制。<br>10.10稳态、动态平衡和内感受处理Homeostasis,Allostasis,andInteroceptiveProcessing<br>Thereismorewisdominyourbodythaninyourdeepestphilosophy.<br>—FriedrichNietzsche<br>生物的生成模型不仅与外部世界有关，而且还也许更重要的是关于内部环境。身体内部（或内感受图式interoceptiveschema）的生成模型具有双重作用：解释内感受（身体）感觉是如何产生的，并确保生理参数的正确调节（Iodiceetal.2019），例如体温或血液中的糖含量。控制论理论（在第10.6.2节中提到）假设生物体的中心目标是维持体内平衡（Cannon1929）确保生理参数保持在可行的范围内（例如，体温永远不会变得太高）并且体内平衡只能通过对环境的成功控制来实现（Ashby1952）。这种形式的稳态调节可以在主动推理中通过指定生理参数的可行范围作为内感受观察的先验来实现。有趣的是，体内平衡调节可以通过多种嵌套方式实现。最简单的调节回路是当某些参数（预计）超出范围时（例如，当体温过高时），自主反射（例如，血管舒张）的参与。这种自主控制可以构建为内感受推理：在内感受interoceptive流上运行的主动推理过程而不是本体感受proprioceptive流，如外部定向动作的情况（Sethetal.2012、SethandFriston2016、Allenetal.2019）。为此，大脑可以使用生成模型来预测内感受和生理流并触发自主反射来纠正内感受预测错误（例如，令人惊讶的高体温）。这类似于激活运动反射以纠正本体感觉预测错误和引导外部指导行动的方式。<br>主动推理超越了简单的自主循环:它可以纠正以越来越复杂的方式产生相同的内感受预测错误（高体温）（Pezzulo、Rigoli和Friston2015）。它可以使用预测性的变稳态策略（Sterling2012，BarrettandSimmons2015，Corcoranetal.2020），超越稳态，在触发内感受预测错误之前以变稳态的方式先发制人地控制生理学，例如，在过热之前寻找阴凉处。另一种预测策略需要在预期偏离生理设定点之前调动资源，例如，在长跑之前增加心输出量，以预期氧气需求增加。这需要动态地修改内感受观察的先验，超越稳态（Tschantzetal.2021）。最终，预测大脑可以制定复杂的目标导向策略，例如确保将冷水带到海滩，以更丰富、更有效的方式满足同样的要求（控制体温）。<br>生物和内感受调节可能对于情感和情绪affectandemotional处理至关重要（Barrett2017）。在情境交互过程中，大脑的生成模型不仅不断预测接下来会发生什么，而且还预测内感受和动态平衡的后果。内感受流在感知外部物体和事件期间引发给它们注入情感维度，这表明它们对于生物的动态平衡和生存有多好或多坏，从而使它们“有意义”。如果这种观点是正确的，那么这种内感受和变稳态处理的障碍可能会导致情失调和各种精神病理状况（Pezzulo2013；Barrettetal.2016；Barcaetal.2019；Pezzulo,Maistoetal.2019）</p>
<p>10.11注意力、显着性和认知动态Attention,Salience,andEpistemicDynamics<br>Trueignoranceisnottheabsenceofknowledge,buttherefusaltoacquireit.<br>—KarlPopper<br>鉴于我们仅在本章中就多次提到精度和预期自由能，如果不花一点空间来关注和突出，那就太疏忽了。这些概念在整个心理学中反复出现，并经过多次重新定义和分类。有时，这些术语用于指代突触增益控制机制synapticgaincontrolmechanisms（Hillyardetal.1998），该机制优先选择某种感觉模态或模态内的通道子集。有时它们指的是我们如何通过公开或秘密的行动来定位自己，以获得更多关于世界的信息（Rizzolattietal.1987;Sheligaetal.1994,1995）。<br>尽管注意力的多种含义带来了不确定性证明了该研究领域的一些认知吸引力，但解决随之而来的歧义也具有价值。心理学的正式观点提供的一件事是我们不需要担心这种歧义。我们可以在操作上将注意力定义为与某些感官输入相关的精确度。这巧妙地映射到增益控制的概念，因为我们推断为更精确的感觉将比那些推断为不精确的感觉对信念更新产生更大的影响。这种关联的结构有效性已经通过心理学范式得到了证明，包括著名的波斯纳范式（费尔德曼和弗里斯顿2010）。具体来说，对视觉空间中具有更高精度affordedahigherprecision的位置处的刺激做出响应比对其他位置的刺激做出响应要快。<br>这使得术语“显着性”需要类似的正式定义。通常，在主动推理中，我们将显着性与预期信息增益（或认知值）相关联：预期自由能的组成部分。直觉上，当我们期望某件事能产生更多信息时，它就更显着。然而，这定义了行动或政策的显着性，而注意力是关于感官输入的信念的一个属性。这符合显着性作为显性或隐性定向的概念。我们在第七章中看到，我们可以将预期信息增益进一步细分为显着性和新颖性。前者是推理的潜力，后者是学习的潜力。表达注意力和显着性（或新颖性）之间差异的类比是科学实验的设计和分析。注意力是从我们已经测量的数据中选择最高质量的数据并使用这些数据为我们的假设检验提供信息的过程。显着性是下一个实验的设计，以确保最高质量的数据。<br>我们并不是为了简单地在文献中添加对注意力现象的另一种重新分类而详细讨论这个问题，而是为了强调致力于形式心理学的重要优势。在主动推理下，其他人是否以不同的方式定义注意力（或任何其他构造）并不重要，因为我们可以简单地引用所讨论的数学构造并排除任何混淆。最后要考虑的一点是，这些定义为为什么注意力和显着性经常被混为一谈提供了简单的解释。高度精确的数据很少有歧义。这意味着他们应该受到关注，并且获取这些数据的行动非常重要（Parr和Friston2019a）。<br>10.12规则学习、因果推理和快速泛化RuleLearning,CausalInference,andFastGeneralization<br>YesterdayIwasclever,soIwantedtochangetheworld.TodayIamwise,soIamchangingmyself.<br>—Rumi<br>与当前的机器相比，人类和其他动物擅长做出复杂的因果推论，学习抽象概念和物体之间的因果关系，并从有限的经验中进行概括学习范式，需要大量的例子才能获得相似的性能。这种差异表明，当前的机器学习方法主要基于复杂的模式识别，可能无法完全捕捉人类学习和思考的方式（Lakeetal.2017）。<br>主动推理的学习范式基于生成模型的开发，该模型捕获动作、事件和观察之间的因果关系。在本书中，我们考虑了相对简单的任务（例如，第7章的T迷宫示例），这些任务需要不复杂的生成模型。相比之下，对复杂情况的理解和推理需要深度生成模型来捕获环境的潜在结构，例如允许在许多明显不同的情况下进行泛化的隐藏规律（Tervo等，2016年；弗里斯顿，林等人。2017）。<br>管理复杂社交互动的隐藏规则的一个简单例子是交通路口。想象一下，一个天真的人观察了一个繁忙的十字路口，并且必须预测（或解释）行人或汽车何时过马路。人们可以积累有关同时发生的事件的统计数据（例如，一辆红色汽车停下来，一个高个子男人过马路；一个老妇人停下来，一辆大车经过），但大多数最终都是无用的。人们最终可以发现一些重复出现的统计模式，例如在所有汽车停在道路上的某个点后不久，行人就会过马路。如果任务只是预测行人何时即将行走，那么在机器学习环境中，这种确定就足够了，但不需要对情况有任何了解。事实上，这甚至可能导致错误的结论：汽车的停止解释了行人的移动。这种错误在机器学习应用程序中很常见，这些应用程序不吸引（因果）模型，并且无法区分是下雨解释了湿草还是湿草解释了下雨（Pearl和Mackenzie2018）。<br>另一方面，推断正确的隐藏（例如，交通灯）规则可以更深入地理解情况的因果结构（例如，交通灯导致汽车停车和行人行走）。隐藏规则不仅提供了更好的预测能力，而且还使推理更加简洁，因为它可以抽象出大多数感官细节（例如，汽车的颜色）。反过来，这允许推广到其他情况，例如不同的十字路口或城市，其中大多数感官细节都存在显着差异‑但需要注意的是，在某些情况下面临十字路口像罗马这样的城市可能需要的不仅仅是看交通信号灯。最后，了解交通灯规则还可以在新情况下实现更有效的学习，或者发展心理学中所谓的“学习集”或机器学习中的学习能力（Harlow1949）。当面对红绿灯关闭的十字路口时，人们无法使用学到的规则，但可能会期望有另一个类似的隐藏规则在起作用，这可以帮助理解交警在做什么。<br>正如这个简单的例子所示，学习丰富的环境潜在结构的生成模型（又名结构学习）可以提供复杂形式的因果推理和概括。扩大生成模型以解决这些复杂的情况是计算建模和认知科学的一个持续目标（Tenenbaumetal.2006，KempandTenenbaum2008）。有趣的是，当前的机器学习趋势（一般思想是“越大越好”）与主动推理的统计方法之间存在着紧张关系，这表明平衡模型的准确性与其复杂性和准确性的重要性。倾向于更简单的模型。模型缩减（以及修剪不必要的参数）不仅仅是避免资源浪费的一种方法，它也是学习隐藏规则的有效方法，包括在睡眠等离线时段（Friston，Lin等人，2017年），也许表现在静息状态活动中（Pezzulo、Zorzi和Corbetta2020）。<br>10.13主动推理和其他领域：开放方向<br>Ithastostartsomewhere,ithastostartsometime,whatbetterplacethanhere?Whatbettertimethannow?<br>—RageAgainsttheMachine,“GuerrillaRadio”<br>在本书中，我们主要关注解决生存和适应生物学问题的主动推理模型。然而主动推理可以应用于许多其他领域。在最后一节中，我们简要讨论两个这样的领域：社会和文化动态以及机器学习和机器人技术。<br>解决前者需要考虑多个主动推理代理交互的方式以及这种交互的新兴影响。解决更复杂的问题但以与理论的基本假设兼容的方式。两者都是有趣的开放研究方向。<br>10.13.1社会和文化动态<br>我们(人类)认知的许多有趣的方面都与社会和文化有关文化动态，而不是个人主义的看法，决定，和行动(Veissière等人，2020年)。根据定义，社会动力学需要multiple主动推理生物参与物理互动(例如，联合行动，例如玩团队运动)或更抽象的交互(例如，选举或社交网络)。互动的简单演示相同生物之间的推论已经产生了有趣的emergent现象，例如简单生命形式的自我组织抵制分散，参与形态发生过程的可能性获取和恢复身体形态，以及相互协调的预测和话轮转换(弗里斯顿2013；弗里斯顿和弗里斯2015a弗里斯顿，莱文等人。2015).其他模拟研究了生物可以将他们的认知扩展到物质人工制品，并塑造他们的认知生态位(Bruineberg等人2018年)。<br>这些模拟只捕捉到了我们社会复杂性的一小部分和文化动态，但它们说明了主动推理的潜力从个人科学扩展到社会科学——以及如何扩展认知超越了我们的头脑(Naveetal.2020)。<br>10.13.2机器学习和机器人技术<br>本书讨论的生成建模和变分推理方法广泛应用于机器学习和机器人技术。在这些领域，重点通常是如何学习（联结主义）生成模型而不是如何将它们用于主动推理，这是本书的重点。这很有趣，因为机器学习方法可能有助于扩大生成模型和本书中考虑的问题的复杂性，但需要注意的是，它们可能需要非常不同的主动推理过程理论。<br>虽然在这里不可能回顾有关机器学习生成模型的大量文献，但我们简要提及一些最流行的模型，并从中开发了许多变体。两种早期的联结主义生成模型，亥姆霍兹机和玻尔兹曼机（Ackleyetal.1985，Dayanetal.1995）提供了范例如何以无监督方式学习神经网络内部表示的示例。亥姆霍兹机与主动推理的变分方法尤其相关，因为它使用单独的识别和生成网络来推断隐藏变量的分布，并从中采样以获得虚构数据。这些方法早期的实际成功是有限的。但之后，堆叠多个的可能性（受限）玻尔兹曼机能够学习多层内部表示，是无监督深度神经网络的早期成功之一（Hinton2007）。<br>连接主义生成模型的两个最新例子，变分自动编码器或VAE（Kingma和Welling，2014年）和生成对抗网络或GAN（Goodfellow等人，2014年），广泛用于机器学习应用，例如识别或生成图片和视频。VAE体现了变分方法在生成网络学习中的优雅应用。他们的学习目标，即证据下界(ELBO)，在数学上等同于变分自由能。该目标使得能够学习数据的准确描述（即，最大化准确性），但也有利于与先验没有太大差异的内部表示（即，最小化复杂性）。后一个目标充当所谓的正则化器，有助于泛化并避免过度拟合。<br>GAN遵循不同的方法：它们结合了两个网络，一个生成网络和一个判别网络，这两个网络在学习过程中不断竞争。判别网络学习区分生成网络生成的示例数据是真实的还是虚构的。生成网络试图生成欺骗判别网络（即被错误分类）的虚构数据。这两个网络之间的竞争迫使生成网络提高其生成能力并生成高保真度的虚构数据这种能力已被广泛用于生成逼真的图像等。<br>上述生成模型（和其他模型）可用于控制任务。例如，Ha和Eck（2017）使用（序列到序列）VAE来学习预测铅笔笔画。通过从VAE的内部表示中采样，该模型可以构建新颖的基于笔划的绘图。玻尔兹曼机能够学习多层内部表示，是无监督深度神经网络的早期成功之一（Hinton2007）。生成建模方法也已用于控制机器人运动。其中一些方法使用主动推理（Pio‑Lopez等人，2016，桑卡塔尔等人2020，西里亚等人2021）或密切相关的想法，但在联结主义背景下（Ahmadi和Tani2019，Tani和White2020）。<br>该领域的主要挑战之一是机器人运动是高维的并且需要（学习）复杂的生成模型。主动推理和相关方法的一个有趣的方面是，要学习的最重要的事情是下一时间步骤的动作和感觉（例如，视觉和本体感觉）反馈之间的前向映射。这种前向映射可以通过多种方式学习：通过自主探索、通过演示，甚至通过与人类的直接交互例如，老师（实验者）引导机器人的手沿着轨迹到达目标，从而构建有效的目标导向行动的获取（Yamashita和Tani2008）。以各种方式学习生成模型的可能性极大地扩展了机器人最终可以实现的技能范围。反过来，使用主动推理开发更先进（神经）机器人的可能性不仅在技术上而且在理论上都很重要。事实上，主动推理的一些关键方面，例如自适应代理与环境交互、认知功能的集成以及体现的重要性，在机器人设置中自然得到解决。<br>10.14总结<br>Homeisbehind,theworldahead,<br>andtherearemanypathstotread<br>throughshadowstotheedgeofnight,<br>untilthestarsareallalight.<br>—J.R.R.Tolkien,TheLordoftheRings<br>我们在本书的开头就提出了一个问题：是否有可能从第一原理来理解大脑和行为。然后，我们引入主动推理作为应对这一挑战的候选理论。我们希望读者相信我们最初问题的答案是肯定的。在本章中，我们考虑了主动推理为感知行为提供的统一视角，以及该理论对熟悉的心理结构（例如感知、行动选择和情感）的影响。这使我们有机会重新审视整本书中介绍的概念，并提醒自己仍有待未来研究的有趣问题。我们希望本书为主动推理的相关著作提供有用的补充，一方面包括哲学（Hohwy2013，Clark2015），另一方面包括物理学（Friston2019a）。<br>我们现在已经到了旅程的终点。我们的目标是提供向那些对使用这些方法感兴趣的人进行介绍无论是概念层面还是形式层面。然而，需要强调的是，主动推理并不是纯粹在理论上可以学习的东西。我们鼓励任何喜欢这本书的人考虑在实践中追求它。理论神经生物学的重要阶段是尝试写下生成模型，体验模拟行为不当时的挫败感，并在意外发生时从违反先前信念的行为中学习。无论您是否选择在计算层面进行这种实践，我们希望您在日常生活中进行主动推理时能够进行反思。这可能表现为强迫你的眼睛去解决你周边视觉中某些事物的不确定性。它可能是选择在最喜欢的餐厅吃饭以满足先前的（味觉）偏好。它可能是在淋浴太热时减少热量，以确保温度符合您的世界应该如何的模型。最终，我们相信您将继续以某种形式追求主动推理。<br>阅读最新前沿科技趋势报告，请访问欧米伽研究所的“未来知识库”<br>https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828<br>未来知识库是“欧米伽未来研究所”建立的在线知识库平台，收藏的资料范围包括人工智能、脑科学、互联网、超级智能，数智大脑、能源、军事、经济、人类风险等等领域的前沿进展与未来趋势。目前拥有超过8000篇重要资料。每周更新不少于100篇世界范围最新研究资料。欢迎扫描二维码或访问https :&#x2F;&#x2F;wx.zsxq.com&#x2F;group&#x2F;454854145828进入。<br>截止到12月25日”未来知识库”精选的100部前沿科技趋势报告<br>2024美国众议院人工智能报告：指导原则、前瞻性建议和政策提案<br>未来今日研究所：2024技术趋势报告-移动性，机器人与无人机篇<br>Deepmind：AI加速科学创新发现的黄金时代报告<br>Continental大陆集团：2024未来出行趋势调研报告<br>埃森哲：未来生活趋势2025<br>国际原子能机构2024聚变关键要素报告-聚变能发展的共同愿景<br>哈尔滨工业大学：2024具身大模型关键技术与应用报告<br>爱思唯尔（Elsevier）：洞察2024：科研人员对人工智能的态度报告<br>李飞飞、谢赛宁新作「空间智能」等探索多模态大模型性能<br>欧洲议会：2024欧盟人工智能伦理指南：背景和实施<br>通往人工超智能的道路：超级对齐的全面综述<br>清华大学：理解世界还是预测未来？世界模型综合综述<br>Transformer发明人最新论文：利用基础模型自动搜索人工生命<br>兰德公司：新兴技术监督框架发展的现状和未来趋势的技术监督报告<br>麦肯锡全球研究院：2024年全球前沿动态（数据）图表呈现<br>兰德公司：新兴技术领域的全球态势综述<br>前瞻：2025年人形机器人产业发展蓝皮书-人形机器人量产及商业化关键挑战<br>美国国家标准技术研究院（NIST）：2024年度美国制造业统计数据报告（英文版）<br>罗戈研究：2024决策智能：值得关注的决策革命研究报告<br>美国航空航天专家委员会：2024十字路口的NASA研究报告<br>中国电子技术标准化研究院2024扩展现实XR产业和标准化研究报告<br>GenAI引领全球科技变革关注AI应用的持续探索<br>国家低空经济融创中心中国上市及新三板挂牌公司低空经济发展报告<br>2025年计算机行业年度策略从Infra到AgentAI创新的无尽前沿<br>多模态可解释人工智能综述：过去、现在与未来<br>【斯坦福博士论文】探索自监督学习中对比学习的理论基础<br>《机器智能体的混合认知模型》最新128页<br>OpenAI管理AI智能体的实践<br>未来生命研究院FLI2024年AI安全指数报告英文版<br>兰德公司2024人工智能项目失败的五大根本原因及其成功之道-避免AI的反模式英文版<br>Linux基金会2024去中心化与人工智能报告英文版<br>脑机接口报告脑机接口机器人中的人机交换<br>联合国贸发会议2024年全球科技创新合作促发展研究报告英文版<br>Linux基金会2024年世界开源大会报告塑造人工智能安全和数字公共产品合作的未来英文版<br>Gartner2025年重要战略技术趋势报告英文版<br>Fastdata极数2024全球人工智能简史<br>中电科：低空航行系统白皮书，拥抱低空经济<br>迈向科学发现的生成式人工智能研究报告：进展、机遇与挑战<br>哈佛博士论文：构建深度学习的理论基础：实证研究方法<br>Science论文：面对“镜像生物”的风险<br>镜面细菌技术报告：可行性和风险<br>Neurocomputing不受限制地超越人类智能的人工智能可能性<br>166页-麦肯锡：中国与世界-理解变化中的经济联系（完整版）<br>未来生命研究所：《2024人工智能安全指数报告》<br>德勤：2025技术趋势报告空间计算、人工智能、IT升级。<br>2024世界智能产业大脑演化趋势报告（12月上）公开版<br>联邦学习中的成员推断攻击与防御：综述<br>兰德公司2024人工智能和机器学习在太空领域感知中的应用-基于两项人工智能案例英文版<br>Wavestone2024年法国工业4.0晴雨表市场趋势与经验反馈英文版<br>Salesforce2024年制造业趋势报告-来自全球800多位行业决策者对运营和数字化转型的洞察英文版<br>MicrosoftAzure2024推动应用创新的九大AI趋势报告<br>DeepMind：Gemini，一个高性能多模态模型家族分析报告<br>模仿、探索和自我提升：慢思维推理系统的复现报告<br>自我发现：大型语言模型自我组成推理结构<br>2025年101项将(或不会)塑造未来的技术趋势白皮书<br>《自然杂志》2024年10大科学人物推荐报告<br>量子位智库：2024年度AI十大趋势报告<br>华为：鸿蒙2030愿景白皮书（更新版）<br>电子行业专题报告：2025年万物AI面临的十大待解难题-241209<br>中国信通院《人工智能发展报告（2024年）》<br>美国安全与新兴技术中心：《追踪美国人工智能并购案》报告<br>Nature研究报告：AI革命的数据正在枯竭，研究人员该怎么办？<br>NeurIPS2024论文：智能体不够聪明怎么办？让它像学徒一样持续学习<br>LangChain人工智能代理（AIagent）现状报告<br>普华永道：2024半导体行业状况报告发展趋势与驱动因素<br>觅途咨询：2024全球人形机器人企业画像与能力评估报告<br>美国化学会(ACS)：2024年纳米材料领域新兴趋势与研发进展报告<br>GWEC：2024年全球风能报告英文版<br>Chainalysis：2024年加密货币地理报告加密货币采用的区域趋势分析<br>2024光刻机产业竞争格局国产替代空间及产业链相关公司分析报告<br>世界经济论坛：智能时代，各国对未来制造业和供应链的准备程度<br>兰德：《保护人工智能模型权重：防止盗窃和滥用前沿模型》-128页报告<br>经合组织成年人是否具备在不断变化的世界中生存所需的技能199页报告<br>医学应用中的可解释人工智能：综述<br>复旦最新《智能体模拟社会》综述<br>《全球导航卫星系统（GNSS）软件定义无线电：历史、当前发展和标准化工作》最新综述<br>《基础研究，致命影响：军事人工智能研究资助》报告<br>欧洲科学的未来-100亿地平线研究计划<br>Nature：欧盟正在形成一项科学大型计划<br>Nature欧洲科学的未来<br>欧盟科学——下一个1000亿欧元<br>欧盟向世界呼吁加入我们价值1000亿欧元的研究计划<br>DARPA主动社会工程防御计划（ASED）《防止删除信息和捕捉有害行为者（PIRANHA）》技术报告<br>兰德《人工智能和机器学习用于太空域感知》72页报告<br>构建通用机器人生成范式：基础设施、扩展性与策略学习（CMU博士论文）<br>世界贸易组织2024智能贸易报告AI和贸易活动如何双向塑造英文版<br>人工智能行业应用建设发展参考架构<br>波士顿咨询2024年欧洲天使投资状况报告英文版<br>2024美国制造业计划战略规划<br>【新书】大规模语言模型的隐私与安全<br>人工智能行业海外市场寻找2025爆款AI应用-241204<br>美国环保署EPA2024年版汽车趋势报告英文版<br>经济学人智库EIU2025年行业展望报告6大行业的挑战机遇与发展趋势英文版<br>华为2024迈向智能世界系列工业网络全连接研究报告<br>华为迈向智能世界白皮书2024-计算<br>华为迈向智能世界白皮书2024-全光网络<br>华为迈向智能世界白皮书2024-数据通信<br>华为迈向智能世界白皮书2024-无线网络<br>安全牛AI时代深度伪造和合成媒体的安全威胁与对策2024版<br>2024人形机器人在工业领域发展机遇行业壁垒及国产替代空间分析报告<br>《2024年AI现状分析报告》2-1-3页.zip<br>万物智能演化理论，智能科学基础理论的新探索-newv2<br>世界经济论坛智能时代的食物和水系统研究报告<br>生成式AI时代的深伪媒体生成与检测：综述与展望<br>科尔尼2024年全球人工智能评估AIA报告追求更高层次的成熟度规模化和影响力英文版<br>计算机行业专题报告AI操作系统时代已至-241201<br>Nature人工智能距离人类水平智能有多近？<br>Nature开放的人工智能系统实际上是封闭的<br>斯坦福《统计学与信息论》讲义，668页pdf<br>国家信息中心华为城市一张网2.0研究报告2024年<br>国际清算银行2024生成式AI的崛起对美国劳动力市场的影响分析报告渗透度替代效应及对不平等状况英文版<br>大模型如何判决？从生成到判决：大型语言模型作为裁判的机遇与挑战<br>毕马威2024年全球半导体行业展望报告<br>MR行业专题报告AIMR空间计算定义新一代超级个人终端-241119<br>DeepMind36页AI4Science报告：全球实验室被「AI科学家」指数级接管<br>《人工智能和机器学习对网络安全的影响》最新273页<br>2024量子计算与人工智能无声的革命报告<br>未来今日研究所：2024技术趋势报告-广义计算篇<br>科睿唯安中国科学院2024研究前沿热度指数报告<br>文本到图像合成：十年回顾<br>《以人为中心的大型语言模型（LLM）研究综述》<br>经合组织2024年数字经济展望报告加强连通性创新与信任第二版<br>波士顿咨询2024全球经济体AI成熟度矩阵报告英文版<br>理解世界还是预测未来？世界模型的综合综述<br>GoogleCloudCSA2024AI与安全状况调研报告英文版<br>英国制造商组织MakeUK2024英国工业战略愿景报告从概念到实施<br>花旗银行CitiGPS2024自然环境可持续发展新前沿研究报告<br>国际可再生能源署IRENA2024年全球气候行动报告<br>Cell:物理学和化学、人工智能知识领域的融合<br>智次方2025中国5G产业全景图谱报告<br>上下滑动查看更多</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/02/24/1000003022-2650028587-2/">https://zejuncao.github.io/2025/02/24/1000003022-2650028587-2/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                                    <span class="chip bg-color">开源项目</span>
                                </a>
                            
                                <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                                    <span class="chip bg-color">微信公众号聚合平台</span>
                                </a>
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                    <span class="chip bg-color">人工智能学家</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/02/24/1000000491-2247494468-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000000491_2247494468_1.jpg" class="responsive-img" alt="实测文心智能体平台满血版 DeepSeek R1 效果">
                        
                        <span class="card-title">实测文心智能体平台满血版 DeepSeek R1 效果</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                        <span class="chip bg-color">开源项目</span>
                    </a>
                    
                    <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                        <span class="chip bg-color">微信公众号聚合平台</span>
                    </a>
                    
                    <a href="/tags/%E5%8C%85%E5%8C%85%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/">
                        <span class="chip bg-color">包包算法笔记</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/02/24/1000003022-2650028587-4/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003022_2650028587_4.jpg" class="responsive-img" alt="对话硅谷大佬马克·安德森：两家中国AI新秀如何改变游戏规则？">
                        
                        <span class="card-title">对话硅谷大佬马克·安德森：两家中国AI新秀如何改变游戏规则？</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                        <span class="chip bg-color">开源项目</span>
                    </a>
                    
                    <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                        <span class="chip bg-color">微信公众号聚合平台</span>
                    </a>
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                        <span class="chip bg-color">人工智能学家</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
