<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="模型之战，DeepSeek R1 改写下一代模型研究的方向？| 万有引力, ZejunCao&#39;Blogs">
    <meta name="description" content="模型之战，DeepSeek R1 改写下一代模型研究的方向？| 万有引力

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

作者|《万有引力》出品|CSDN（ID：CSDNnews）如果说DeepSeekV3的发布只是吸">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>模型之战，DeepSeek R1 改写下一代模型研究的方向？| 万有引力 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000002555_2247585835_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">模型之战，DeepSeek R1 改写下一代模型研究的方向？| 万有引力</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                                <span class="chip bg-color">开源项目</span>
                            </a>
                        
                            <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                                <span class="chip bg-color">微信公众号聚合平台</span>
                            </a>
                        
                            <a href="/tags/AI%E7%A7%91%E6%8A%80%E5%A4%A7%E6%9C%AC%E8%90%A5/">
                                <span class="chip bg-color">AI科技大本营</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-02-24
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/qRrLkQv10QiEEHl-GL0axw">模型之战，DeepSeek R1 改写下一代模型研究的方向？| 万有引力</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>作者|《万有引力》<br>出品|CSDN（ID：CSDNnews）<br>如果说DeepSeekV3的发布只是吸引了大家初步关注，那么DeepSeekR1的发布无疑引发了AI技术圈的「Aha时刻」。<br>随着热度的逐渐上升，不少人认为，DeepSeekR1技术创新以及开源策略，已经让OpenAI、Meta等竞争对手感到了前所未有的压力。从早期“蒸馏OpenAI”等传言甚嚣，到OpenAI紧急推出了本应具有更大影响力的DeepResearch、o3-mini，以及其近日还罕见调整模型发布计划，取消单独推出o3模型，转而将其与未来的GPT-5整合发布。在外界看来，OpenAI等走在AI前沿的公司产品发布节奏已经因DeepSeek的崛起而发生了改变。<br>正因此，更多的技术人致力于深探DeepSeek的“魔力点”：它是如何从一个默默无闻的模型，发展成为引领行业的先锋，其技术优势到底在哪里？它的创新究竟源于工程突破，还是算法优化？关于“DeepSeek甚至绕过了CUDA”这一说法，是否真实？<br>为了解答这些疑问，在CSDN特别策划的「DeepSeek暨AI进化论十日谈」系列直播的第三期中，《万有引力》邀请了硅谷资深AI技术专家吴双，北京邮电大学人机交互与认知工程实验室主任、《人机环境系统智能：超越人机融合》作者刘伟，《知识增强大模型》作者、前达观数据副总裁王文广，在栏目主理人CSDN&amp;《新程序员》执行总编唐小引的主持下，通过「直击DeepSeek技术真相，对我们究竟意味着什么？」这一主题，从硅谷、学术、产业的不同视角为大家深度剖析DeepSeek背后的技术创新及其对未来AI发展的深远影响。<br>对DeepSeek的初印象<br>唐小引：DeepSeek在今年春节期间形成了刷屏之势，请老师们分享一下对DeepSeek的感受与体验。<br>吴双：DeepSeekR1发布后，几乎所有的技术媒体、财经媒体和技术行业的人都在讨论这一技术，各种信息涌现，导致了不少信息混乱。其实大家最关心的还是这一技术对自己的影响。<br>可以说，DeepSeek确实是当前最重要的话题，且热度持续上升。我也第一时间去读了它的技术报告，确实有许多值得关注的亮点。<br>王文广：我从V1开始就在关注DeepSeek模型，此前也曾撰文分析过DeepSeekV2、V3所使用的模型架构MoE（混合专家）[1]，包括DeepSeek此前开源的数学定理证明模型Prover，因此，我对DeepSeek本身较为熟悉。<br>从春节情况来看，我觉得DeepSeek是诞生于国内，但热度是从美国传回了中国。它的爆火，我认为有三个要素：<br>在内部，DeepSeekR1的能力超越了其他过往版本。于去年12月发布的DeepSeekV3能力虽然不错，但没有与GPT-4、通义千问等模型显著拉开差距，DeepSeekR1则明显超过了其他版本。<br>在外部，DeepSeekR1的性能超过了OpenAIo1，即使OpenAIo3-mini发布后，我个人觉得R1至少是在中文环境下的表现仍然优于o3-mini。<br>中国式全球化开始。我将DeepSeek的风靡与此前自称为“TikTok难民”的美国网友涌入小红书的案例关联起来。二者都发生在2024年底至2025年初，这两个事件引发一个客观事实：无论从技术角度，还是用户使用习惯，全球的网民整逐步接受并愿意使用中国的App，这无疑为中国开发者带来了更多机遇。在我看来，这不仅是一个市场变化，更是“中国式全球化”的新起点。2025年或许只是序章，我也相信，中国式全球化的星星之火或将燎原。<br>刘伟：首先，我对梁文锋老师（DeepSeek创始人）及其团队致以敬意，他们在本土能够取得如此高的成就，令人非常钦佩。<br>其次，从专业角度而言，我认为无论是DeepSeek、ChatGPT、Gemini，还是Claude、Grok等大模型，我们都应以平常心看待。归根究底，这些都是软件和硬件的结合，用行话来说都是“机器”，它们在某些方面可能超过人类，比如下围棋、做科研助手等，但要全面超越人类，尤其是实现超级智能或通用人工智能，道路仍非常遥远。<br>我认为，未来人工智能的发展将是“人机环境系统智能”。如果没有“人-机-环”的结合，独立的ChatGPT、DeepSeek亦或是其他软件的存在都会内藏缺陷，尤其是基于Transformer架构的模型，其本身就有一定基因性的局限性。<br>至于缺陷是什么，我们曾在三年前翻译过马库斯（纽约大学心理学与神经科学教授）的《代数大脑》一书，书中明确指出：“只要是用多层的神经网络系统，肯定会出现机器幻觉。”简单来看，就是机器会出错而且无法判断出错的时间，倘若没有经验的人把这些技术用在关键场合，极有可能会带来致命风险。这使得我们日常也不要过度神化这些模型。在当前数学和物理学没有重大突破的情况下，创造出与人类智能相似的机器智能是不可能的。人类的智能非常复杂，除了理性，还有感性成分，这些都构成了人类智慧的核心，而当前的AI模型过于依赖理性和数学。<br>再者，DeepSeek的突破性和受到众人的热捧，主要在于它的“平权”和“小力出奇迹”的能力。过去，我们普遍认为只有大规模计算能力才能实现的任务，DeepSeek却凭借较少的计算资源也能做到。这符合人类智能的发展规律，也意味着我们从一个“拼硬件”的时代，已进入一个“拼软件、拼算法”的时代。<br>唐小引：谈到模型与人类智慧，近期在DeepSeekR1席卷的同时，关于R1是否存在自主意识的讨论也很多，几位老师有什么观点可以与大家分享？<br>刘伟：我认为DeepSeekR1、ChatGPT等确实有“意识”，但这只是“机器意识”。因为它们里面都有多层神经网络系统，这就是一种非线性函数，函数之间通过权重分配来决定输入与输出的关系。<br>论及这些机器是否能拥有像人类一样的意识，我认为不可能。曾有朋友问我，假设一台机器与一个刚出生的孩子同时观察世界，它们会否进化出相同的智能和智慧。我的回答是：不可能。原因在于人类有自己的基因，而机器也有“基因”，但我们无法将人类几百万年的进化历程完全复制到机器中。<br>以上是我的观点，不知是否完全恰当，也欢迎大家指正。<br>王文广：我认为“意识”的定义本身尚未明确，至于“意识”是否仅限于人类，也没有定论。从长远来看，存在三种可能性：第一种是像刘伟老师所说的，机器不会产生像人类一样的“意识”；第二种可能是机器会产生类似人类的“意识”；第三种是机器可能会拥有一种与人类完全不同的“意识”。<br>我曾看过不少关于脑科学、神经科学以及神经心理学的书籍和论文，至今关于人类大脑如何产生意识、进行推理等问题，仍没有明确的答案，但可以确认的是——神经网络本身是在模仿人类大脑，如果人类大脑能够产生人类思维，那么神经网络在足够大的情况下产生思维的概率也是存在的。<br>如果大家频繁使用DeepSeek，就会发现，它已经有点像人一样存在了。对此，我也有一些看法：<br>神经网络本身具备知识记忆，就像人类一样。然而，DeepSeekR1在推理过程中，当它的记忆与推理结果发生冲突时，它会在思维链里表现出“纠结”，而不是简单地选择一个结果，这与人类的思维方式非常相似。R1的推理能力也不同于其他模型。它在经过多次推理后，如果推理结果超越了记忆中的信息，R1会提供推理结果，而不是依赖记忆。这一点是其他模型包括OpenAIo3-mini都没有的特征。<br>从情感角度看，R1展现了与人类情感相似的反应。在一些社交平台，许多非技术用户使用DeepSeekR1处理情感问题、算卦等，它在情感分析和回应方面常常超越许多心理学家和心理医生的能力，有时展现出同情心和人性化的建议。<br>总的来说，R1可能会产生意识，也有可能不会，但其在解决推理、情感问题上的表现已然不错。<br>吴双：意识乃至AI的整体发展，实际是一个不断促进我们反思对智能、推理以及意识本质理解的过程。这些思考让我们产生质疑：智能和意识是否一定要依赖生物基础？还是它们可以独立于碳基生物体存在，或许能以硅基等其他形式出现？<br>随着深度学习的发展，我们正在不断挑战以往的直觉。例如，我们曾认为大规模神经网络几乎无法运行，但事实证明并非如此。AlphaZero的成功表明，机器可以不依赖人类经验，仅凭自我学习便能掌握围棋。类似地，R1模型证明，即便不进行传统的监督学习（SFT），通过强化学习（RL）也能实现推理。<br>过去很多人认为只有人类才具备意识，而某些动物并不具备意识。虽然这种看法有其历史验证基础，但科学的意义就在于挑战这些假设。我认为，未来如果意识能够在非碳基体中产生，也并非不可能。科学本身是永远开放的，始终可以推翻旧有的理论。从这个角度看，我希望能看到更多关于“意识”的突破，这将让这个世界更加精彩。<br>此外，一台机器与一个新生儿在同时学习的过程中，最大的不同在于当前的AI模型在推理时并不会主动学习，而是将学习与推理严格分开。例如，DeepSeekR1在训练完成后，其权重保持不变，始终在进行相同的推理，并不会自主学习。然而，对于一个复杂的系统而言，模型进行学习之后，其行为可以表现出极大的复杂性。现代大模型虽然参数庞大，但其行为的多样性远超其参数规模，对同一个问题可能给出不同的答案，展现出高度复杂的推理能力。<br>从这个角度来看，学习与推理的边界迟早会被打破。目前，已有研究在探索“测试时学习”（test-timelearning），即模型在推理过程中持续学习。如果这一技术实现，模型将不再是静态的，而是能够随着环境的互动不断进化。这意味着，未来的AI将具备动态学习与自我调整的能力，使其在行为上展现出更复杂、更智能的特性。因此，计算机模型通过不断更新来表现出更高程度的复杂性和智能，完全是可以预见的。<br>王文广：在推理过程中进行学习，就目前而言，强化学习本身无法做到。然而，强化学习理论上是可以在推理过程中动态更新模型参数的。至于为什么现在没做，主要还是受限于算力。一旦计算芯片，或诸如神经网络、光学芯片等硅基架构取得突破，使得算力足够强大，就完全可以在推理过程中实现实时学习，并在学习过程中进行推理。这个在技术上是没有问题的。<br>还原DeepSeek技术真相一：DeepSeek很强，强在哪？<br>唐小引：DeepSeek是否具备底层创新，是否真的具有国运级的技术突破？<br>吴双：关于DeepSeek的讨论，主要集中在两篇论文上：一篇是去年12月底发布的DeepSeekV3模型[2]，另一篇是今年1月底发布的DeepSeekR1模型[3]。这两篇论文虽然有所联系，但各自有不同的侧重点。V3在R1的数据上做了优化，而R1则是基于V3的底层架构。可以说，它们是两个并行推进的工作，但如果要总结，V3和R1代表了两种不同的研究方向。<br>V3的工作更多侧重于工程优化，它并不涉及算法上的突破，而是通过细致的优化将大模型的训练提升到了一个新的层次，包括在软件和硬件架构等多个方面的极致优化。因此，V3更像是工程上的胜利。而R1则是更偏向于科研突破，它证明了强化学习（RL）在大语言模型中可以绕过传统的监督学习阶段。这一阶段的最大难点在于，当前大模型训练中的监督微调需要大量人工标注数据，尤其是专业领域的数据，成本非常高。强化学习可以在无需大量人工数据的情况下，通过自我提升进行能力的优化。这个过程类似于AlphaGo向AlphaGoZero的转变，后者在不依赖人类棋谱的情况下，依靠随机探索和规则判断，自我学习并变得更强。<br>R1的核心在于其底层模型的强大性。就像GPT-4o能实现的突破，GPT-3.5可能难以做到。因此，R1的研究出现是必然的，其他公司或许也在进行类似的工作，只是出于某些考虑尚未公开。DeepSeek选择公开，是基于科研目的，向全世界展示这一技术是可行的。就像当年AlexNet的出现，证明了ImageNet训练的可行性。<br>至于具体的技术细节或是哪家公司率先推出模型，其实并不重要。R1的意义在于向世界证明：这种技术可以实现，而一旦被验证，整个行业都会跟进。这正是科学发展的意义。<br>王文广：很难将DeepSeek的技术创新简单归类为科学算法创新或工程创新。从我的角度来看，它并不算理论上的创新，因为相关的理论基础在多年前大多已经建立了，比如图灵奖和诺贝尔奖获得者的工作，早已成为公认的成果。这些理论或算法的创新，实际上是几十年前的事了。</p>
<p>同时，DeepSeek的MLA（Multi-levelAttention）也对attention进行了创新，尤其是在降低计算量和优化KV缓存方面，通过矩阵分解等方式将大矩阵转换为小矩阵进行存储和计算。尽管这些技术本身并不是新的理论突破，但DeepSeek将它们有效结合，形成了一些技术上的突破，这种跨学科的结合既可以视为工程优化，也可视为算法创新。很难做出明确的界定，但它不应被视为原创新的理论突破。<br>不仅如此，R1所采用的强化学习技术，也是几十年前就已存在的技术。从20世纪50年代AI发展起步，到马尔可夫决策过程（MDP）的提出，强化学习的理论基础早已奠定，只不过当时业界不太认可这一理论。直到AlphaGo的成功，强化学习才被广泛认可。回顾当时，围棋界几乎没有人相信人工智能能够战胜顶尖棋手，但事实证明，AI打败人类围棋手李世石。在今天，许多人仍然认为智能在某些领域无法超越人类，但实际上，随着技术的发展，AI在越来越多领域超越人类的可能性日益增加。<br>过去，强化学习在AI领域的应用并不广泛，反而更多地用于机器人、游戏和量化交易等领域。尤其在量化交易中，摩根大通、高盛、幻方等公司早已应用强化学习进行量化分析。然而，我没有预料到，量化公司竟然能成功将强化学习应用到大模型上，并且真正走通了这条路。<br>我猜测在R1发布之前，OpenAI也在探索类似的方向，但并未公开相关研究。DeepSeekR1是首个以论文形式公开研究成果、开放模型，并提供验证的案例。它不仅证明了强化学习在大模型中的可行性，还分享了具体的方法，使得现在不少公司可复现DeepSeekR1。尽管这种方法未必是未来所有模型的标准方案，甚至未来可能会有更优的路径，但它至少证明了强化学习这条路在大模型中是可行的，为后续研究提供了一个可以复现的路径。<br>唐小引：DeepSeekR1的发布确实掀起了一股复现热潮。比如我们看到李飞飞团队的研究人员以不到50美元的费用训练了一个能力比肩DeepSeek-R1的S1模型，GitHub上已经有许多基于R1的衍生项目，大家如何看待这种情况？<br>吴双：相比于我们只知道o1的效果但不清楚如何实现的情况，当大家看到公开的研究成果，以及能接触到更多的细节时，激发了技术人员强烈的研发热情。因此，我认为复现的过程更多体现的是技术人员的好奇心，大家都希望深入理解这些技术的工作原理、局限性和边界。<br>R1的出现更多地让我们反思之前的一些判断和理解的偏差，让我们思考为什么没有像DeepSeek一样相信这件事情能够做出来的。另外，正如王老师刚才提到的，事实上，在AlphaGo之后，强化学习的热度一度有所下降。当时很多人认为强化学习存在局限性，原因在于缺乏良好的仿真环境和清晰的奖励函数，这些问题使得强化学习的落地应用变得困难。然而，我认为，强化学习的低迷其实更多是因为当时基于监督学习的方法在提升性能上显得更加直接和简单，大家更倾向于选择这条路径。<br>图灵奖得主杨立昆曾经提到，监督学习是一个很小的部分，而强化学习才是更重要的。然而，他同时也指出，自监督学习才是最关键的部分。事实上，也不能说他的说法是错误的，现在的R1正是在自监督学习的基础上，结合强化学习进行创新，二者的关系非常微妙。强化学习的应用实际上非常广泛，尤其是在我所从事的自动驾驶领域。<br>同时，强化学习在一些如运维、货运、交易等商业场景中也展现了惊人的潜力。如果这些场景有明确的逻辑和环境因素，强化学习方法也能快速适应，并在模型规模不大的情况下，达到超越人类的表现，这些现象均已在实践中得到验证。<br>作为开发者，我们要保持敏锐的洞察力，理解强化学习的应用场景，尤其是在我们熟悉的行业和领域中。如果能够准确发现强化学习的潜力，并恰当地应用，可能会带来点石成金的效果。<br>刘伟：大家在讨论人工智能的时候，不知不觉将“智能”与“人工智能”混为一谈。其实人类的智能包括了文学、艺术、宗教等领域的元素，甚至包括想象力和虚构能力。智能的复杂性远超出了数学的范畴。这二者都是超越科学技术的。<br>以量化交易中的“计算”为例，人们通常认为它只是纯粹的数学计算，但本质上，它更接近于“算计”。量化交易不仅涉及数字运算，还要综合考虑结构化与非结构化数据、线性与非线性关系、相关与非相关因素等复杂变量。这种“算计”行为，实际上体现了智能的多层次特性，而不仅仅是数学运算的结果。<br>关于机器是否能产生意识，目前仍是一个开放性问题。但人类的意识来源于社会交互。正如马克思所说：“人是社会的动物。”个体的意识是由其所处的社会环境塑造的。例如，一个在狼群中长大的人，其意识会更接近狼，而非人类社会中的意识形态。相比之下，机器缺乏社会基因，也无法真正经历人类社会的交互过程，因此，它不可能拥有“人类的智能”。机器智能只是基于训练数据和算法生成的，而非由社会环境塑造而成。<br>另一个关键问题是情感。MIT教授RosalindPicard的情感计算研究虽然在情感的结构化和形式化方面取得了突破，但人与机器的情感仍然存在本质差异。人类情感源自进化，与社会关系和文化背景密不可分，而机器的情感只能停留在模拟层面。<br>智能的研究还反映了东西方思维方式的差异。东方思维更注重整体性和系统化，而西方思维倾向于形式化和还原论。这种不同的思维方式在现代智能技术中也有所体现。例如，DeepSeek虽然基于西方的深度学习技术，但它在多头注意力机制和专家模型方面，融合了东方整体论的思维方式。未来的智能体系，或许将是东西方智慧的结合——既关注科技，也关注非科技领域，既结合数学，也融合人文社会因素，最终构建出更具完整性的智能框架。<br>王文广：关于DeepSeek的复现，目前最接近原始版本的模型应该是HuggingFace推出的OpenR1项目（https :&#x2F;&#x2F;open-r1.com）。这个项目致力于从数据到模型的完整复现，虽然现在仍处于早期阶段，但它已经完成了对R1671B模型的评估，并且评估结果与论文中的描述非常相符，甚至在某些指标上有所超越论文中写的指标。这证明了R1本身的能力是无可置疑的。<br>除了OpenR1外，一些较小的项目尝试复现7B、1B规模的R1模型。由于671B级别的复现成本极高，许多实验室和科研团队选择以7B入手，以降低成本。然而，即便是7B规模的训练，也需要大量计算资源。例如，哪怕在V3训练的基础上进行后续微调，仍至少需要数千张GPU，而如果不采用低成本优化方案，完整训练可能需要数万张GPU。<br>时下R1开源的优势就在于，大家可以直接看到模型的实现，任何人都可以检验其是否达到宣称的效果，这样没有任何隐瞒或造假的空间。<br>还原DeepSeek技术真相二：“蒸馏”的争议<br>唐小引：DeepSeek还面临着被指蒸馏ChatGPT的争议，大家如何看待这一问题，到底有没有蒸馏？<br>吴双：DeepSeekR1刚出现时，有人尤其在技术圈外对这个问题非常纠结，但经过这两周，技术圈的人已经不再关注这个问题了。大家非常清楚，并不是获得GPT-4API生成的数据就能蒸馏成一款大模型。坦白说，现在网上已经有很多包含GPT对话数据的流传，模型不可避免地接触到这些数据，所以它有可能产生类似的效果。而且我们也知道，即便是GPT-4、Gemini这样的模型，也会偶尔出现身份认知错误，比如Gemini会错误地说自己是ChatGPT。<br>因此，我觉得这件事已经不再是一个值得讨论的焦点，因为它只是一个没有任何证据的猜测，且对技术评判没有实际意义。<br>王文广：我完全认同吴双老师的观点。首先，OpenAI至今未能提供任何令人信服的证据，甚至没有任何证据表明DeepSeek是从OpenAI的模型蒸馏而来的。毕竟，DeepSeek是开源的，如果有证据，应该很容易就能拿出来。此外，身份认知错误是非常正常的，例如GPT-4在中文领域曾误认为自己是文心一言模型，任何大模型都有可能误认为自己是另一个大模型，这是常见的情况。<br>关于蒸馏的问题，正如一些段子所说，如果DeepSeek能轻松通过蒸馏创造出超越o1模型的新模型，那OpenAI的技术壁垒在哪呢？如果别人能随便蒸馏出更强的模型，那就说明OpenAI的技术水平不高，甚至可以说它不具备独特的价值。其实这个问题从技术圈的角度来看并没有什么值得讨论的，但从政治圈来看，显然是一个话题。<br>再者，从技术角度来看，蒸馏本身也是正常的。实际上，DeepSeeK也蒸馏出了几个小模型供大家使用，比如1B、3B、7B、14B、30B、70B等模型。然而，这些小模型的能力显然比满血版的R1模型要差得多。实际上，在OpenAI、Claude内部也有同样的情况，满血大模型是非常昂贵的，免费提供给用户的模型往往是从这些大模型蒸馏出来的小模型。例如，微软的论文曾暴露了ChatGPT的gpt-3.5-turbo接口参数仅有20B（后论文撤回）。尽管不能说确定这一信息是100%正确的，但有99.999%的可能性，这个模型也是从GPT-4或其他大模型中蒸馏出来的小模型。蒸馏技术本身已经存在了几十年，是一种非常常见的技术。<br>刘伟：实际上GPT本身也在变相地蒸馏人类的知识。目前，GPT正面临许多法律诉讼，其中一些新闻媒体也在起诉GPT，认为它通过蒸馏他们的内容来生成答案。<br>还原DeepSeek技术真相三：高效率的模型，训练成本真有那么低？<br>唐小引：据DeepSeekV3技术报告披露，其训练成本不足600万美元。如今，虽然R1的训练成本没有公开，但很多人认为它的训练成本相较V3有所降低。同时，尽管训练成本降低，R1的训练时间却非常短，从V3到R1仅仅用了两个月时间，却在推理任务上能够与OpenAIo1模型相媲美。DeepSeek是如何实现低成本高效率的训练，亦或者说模型训练的关键因素是什么？<br>王文广：我的看法是——低成本本身并没有那么重要，也不是这次DeepSeekR1爆红的源头。对于中国不少企业而言，低成本较为重要，因为很多公司购买不到太多高性能的显卡。而在美国科技圈，R1的能力才是关键。如果R1或V3的性能不足，即便低成本也难以引起硅谷的关注。对于那些拥有数十万甚至上百万张GPU的科技巨头来说，成本并非核心考量。然而，低成本方案的出现，确实在一定程度上削弱了高成本模型的竞争优势。<br>从技术角度来看，DeepSeek实现低成本高效率的训练，我认为有三个关键点：</p>
<p>DeepSeek应该是第一个使用FP8进行训练的大型模型。虽然一些小型实验室可能有类似做法，但在大模型方面，DeepSeek是首个走通了FP8训练模式，这大大提升了显卡利用率。<br>DeepSeek在公开技术中应用了PTX等底层优化方法，优化了训练过程中的技术。此前没有其他公司公开过使用类似的技术。<br>此外，DeepSeek可能还积累了大量高质量的数据，既包括人工标注数据，也包括合成数据。之前他们推出了一个小型模型DeepSeekMath7B，并发布了一篇论文《DeepSeekPolver：通过大规模合成数据推进LLM中的定理证明》（https :&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2405.14333v1），介绍了如何通过合成数据解决数学问题。高质量的数据使得他们可以用更少的数据训练出同等或更强的模型能力。<br>以上几个因素结合起来，帮助DeepSeek实现低成本训练。<br>吴双：有一些流传较广的观点认为DeepSeek的高效率架构绕开了算力控制，但我认为这显然不成立。实际上，DeepSeek创始人梁文锋曾在采访中也明确提到，算力依然是他们面临的最大瓶颈，他们希望能够获得更多算力。<br>DeepSeek做了很多的工程优化，实际上是出于算力受限的情况下的不得已之举。由于他们的显卡仍然是H800，而H800存在带宽问题，因此他们不得不进行大量优化，包括压缩带宽、降低节点间数据交流数量等，目的就是为了克服没有满血H100的限制。<br>这种优化的成功在于，它在有限的资源下做到了极致，因此在国外技术圈中，大家普遍认可DeepSeek在这方面的表现，包括使用了PTX等底层技术。然而，需要补充的是，使用PTX并不等同于绕过CUDA。实际PTX和CUDA都是Nvidia的技术，本质并没有绕过任何东西，只是不同的方式来为芯片编写代码，依然是针对Nvidia的架构。<br>抛开技术细节，DeepSeek此次成功“出圈”，更关键的因素在于其开源策略带来了巨大的关注度和流量。这一举措可能推动业界围绕DeepSeek构建庞大的模型生态，同时也引发了美国的极大担忧。<br>美国的开发者和公司对“最好的开源模型为何不在自己掌控之中”感到焦虑。其中，Meta尤为紧张，甚至专门组织多个小组讨论如何在技术上让Llama超越DeepSeek。未来，随着DeepSeek模型在非美国地区的开发者和用户中广泛应用，全球开源模型生态的格局或将发生深远的变化。<br>还原DeepSeek技术真相四：开源vs闭源，性能比肩vs超越？<br>唐小引：关于大模型的开源问题，国内讨论一直十分热烈，尤其是围绕模型究竟是真开源还是“假开源”的争议。其中，一个核心问题是：是否能够实现模型的完全开源和透明化。<br>另外，DeepSeek已经证明，开源模型的性能足以对标OpenAI的闭源o1模型。这也引发了一个关键讨论——开源模型与闭源模型的性能差距是否会逐步缩小？未来，开源模型的发展将呈现哪些新趋势？开源模型能否真正经受住实际应用的考验？<br>王文广：我认为开源模型、闭源模型的“出圈”存在一定偶然性。回看ChatGPT的出圈也有偶然性，其实GPT-3模型早已发布了但没有引起轰动，直到2022年11月30日，经过包装的ChatGPT出现才让其真正爆发。在DeepSeekR1发布之前，主流观点普遍认为闭源模型超越了开源模型。然而，DeepSeekR1的推出改变了这种看法，尽管不能说它超越了闭源模型，但至少已追赶上了。<br>未来，无论是开源超越闭源，还是闭源拉开与开源的差距，都是可能的。我认为，无论是开源还是闭源，保持较大的领先优势都非常困难。开源模型一旦发布，闭源模型可以快速模仿；而闭源模型则通常隐藏其思维链，试图保有领先优势，但DeepSeekR1的出现证明了这种方法似乎并未见效。因此，开源和闭源模型未来可能会在某些方面平分秋色，类似于iOS和Android的竞争局面。<br>有人担心开源“污染”问题，我觉得开源模型中的“污染”问题其实是虚构的。开源代码一旦发布，使用者可以自由选择并决定是否使用。然而，大多数人没有能力检查每一行代码是否存在问题，就像Android的开源代码一样，虽然其中可能存在不为人知的风险，但没有人会逐行检查。我举个例子，671B的大模型虽然可以下载，但需要昂贵的硬件支持，普通人根本无法自行运行，最多只能通过API调用。而API提供者能否提供真实的R1模型，则完全依赖于商家的信誉。因此，污染问题并不需要过于担忧，毕竟用户可以自由选择如何使用开源、闭源的模型。<br>吴双：我补充两点。首先，开源尤其是像DeepSeekR1模型的出现，让一些国外公司和开发者特别兴奋。之前，大家对使用ChatGPTAPI、GeminiAPI往往有些谨慎，原因就是美国的商业公司特别关注数据安全，他们希望数据能够留在本地，尽可能地避免将数据外传。所以，如果能拥有一个与闭源模型相媲美的开源模型，在自己的服务器上部署、在公司内部使用，大家就会更加放心。事实上，很多硅谷的大公司已经在公司内部部署了开源的大模型供员工使用。DeepSeek一出来，很多公司已经开始在内部部署，甚至像Oracle这些公司也在云上进行了部署。这意味着所有公司都可以部署这样的模型，这也打破了高质量大模型的垄断地位。虽然DeepSeek可能不是最强的，但它满足了需求，而且没有任何后顾之忧，这非常重要。<br>从中国和美国之外的其他国家来看，他们显然也非常欢迎这一点，这也可以从HuggingFace上不断涌现的基于DeepSeek衍生的模型就可以看出来。这样的趋势反过来刺激了更多技术探索和试错，可能还会发现新的亮点，进一步推动大模型的发展。开源或公开科学研究的意义就在于，原本大家认为非常有价值的技术被某些公司以商业利益为目的进行了垄断，而这一次的打破垄断是革命性的。<br>王文广：我认同这一观点。首先，DeepSeek的R1能力已经达到了可以使用的水平，虽然可能不算是最强，但也可以排在第二。其次，所有国家、机构、企业甚至个人，只要愿意付钱，都可以本地化部署自己的模型，完全没有任何限制，也没有审查。<br>第三，之前除了中美，其他国家几乎没有在做大模型。比如，欧洲只有法国的Mistral较为知名，中东的一些项目也没有太大进展，其他国家几乎没有大模型的研发，但DeepSeek发布后，日本、韩国、欧洲各国和印度都开始投入大模型的研发，因为他们看到了这个基础，并且知道可以直接为政府或企业部署，解决自己的需求。这些国家不再依赖他国，拥有了自主控制的大模型。<br>刘伟：目前大模型领域的快速发展主要集中在中美，而其他国家相对滞后。DeepSeek这次的出现，起到了很重要的作用，正如两位老师提到的，它给大家带来了希望，很多人已经从中看到了曙光，或者已经感受到了它的威力。这也是DeepSeek引起轰动效应的一个重要原因，蝴蝶效应已经开始显现。<br>不过，我还是想提醒一下大家，不要过分神化它。它肯定存在一些问题，任何使用DeepSeek的人都知道，它在某些回答上存在逻辑上的问题。因此，我们首先要端正态度，明确什么时候它可以使用，什么时候不能使用，不要误以为它是万能的，这样的看法是不对的。<br>唐小引：在R1发布之后，OpenAI显然感受到了压力，因此紧接着发布了DeepResearch，而Google也发布了Gemini2.0全家桶，大家怎么看待这个现象以及产品？<br>吴双：我觉得OpenAIDeepResearch显然是一个反应性的发布。过往OpenAI的商业运作一直都很精明，每一次发布通常都是经过精心准备的，但DeepResearch的发布给人一种有点被迫的感觉。坦白说，Google早在去年12月甚至更早的时候就发布了一个同名的DeepResearch产品，但Google一如既往地不擅长产品营销和宣传，导致很多人不知道它的存在，尽管它其实是挺好用的。<br>目前OpenAIDeepResearch特别是在质量和研究深度上看起来确实做得更好一些。技术圈的很多人都在试用这个产品，并且不少人对这款产品的印象很好，宛如当初用ChatGPT的感觉。它能做到非常有条理的深度分析，尤其是在信息的聚合上，能够收集大量的信息源进行整合。这方面，DeepResearch可以被认为是产品方向上的一个新标杆，其他公司可能会迅速向它看齐，展示出类似的深度研究能力。<br>我认为，本来OpenAI可能计划稍后发布这款产品的，但因为DeepSeek的强势发布，他们被迫提前推出了DeepResearch。这样一来，其他公司就会更快地对齐能力，缩短差距。所以，从竞争的角度来看，这其实是一个非常正常的过程。<br>至于DeepSeek，如果他们想做出类似的产品，我相信他们完全有能力做到。关键在于他们是否认为这项工作是他们的最高优先级，因为DeepResearch虽然展现的是模型能力的一部分，但更多的其实是一个产品发布的策略。<br>王文广：与DeepResearch类似的应用一直存在，如秘塔AI搜索、PerplexityAI等，但DeepResearch做得更专业一些，它将这一业务作为核心产品来打造。<br>o3-Mini和DeepResearch的发布，实际上是被DeepSeekR1推动出来的，否则它们可能会选择慢慢发布。实际上，在硅谷这个信息透明的圈子里，大家对竞品的实力都有一定了解。每当竞品发布新模型或产品时，OpenAI通常会提前一两天推出类似的东西，而且水平更好，这使得OpenAI总能在宣传上占据最前沿。可以看出来o3-mini的发布非常匆忙，甚至有迹象表明，它在某些方面没有完全调试好。<br>同样，DeepResearch的发布也有些仓促。原本DeepResearch的发布计划应该是在下一个关键节点，比如年底或年中的发布会，但由于o3-mini对R1没有明显优势，没有对R1造成太大威胁，导致很多用户觉得每月200美元的费用可能有些不值。毕竟，R1是免费的，且大量企业内部和云服务都在使用它，这迫使OpenAI必须推出一些新的功能来吸引用户。<br>还原DeepSeek技术真相五：模型之战，DeepSeekR1改写下一代模型研究的方向？<br>唐小引：DeepSeekR1引起了很多云算力厂商和AI基础设施企业的兴奋，但大多数模型厂商似乎保持缄默。除了几天前，作为面壁的首席科学家刘知远老师分享了一些关于从DeepSeek看AI未来的思考。我们当前能够看到大家格外关心的一点是，全球的各大巨头和创业公司在模型训练和迭代上的投入非常高昂。而现在，这个投入是否白费了？模型未来的发展方向又会去往何处？<br>王文广：模型厂商一般不会评价竞争对手，因为如果你的模型能力更强，根本无需评价。像DeepSeekR1的出现，很多厂商包括云计算公司，似乎都没有办法赶上这个水平。越是评价，反而会被认为是在为竞品做宣传，不过幸运的是，DeepSeek是开源的，厂商想评价也可以随便评价。<br>云计算厂商之所以如此兴奋，是因为过去在大模型领域，他们几乎分不到什么份额，大家都在看OpenAI等少数公司赚大钱，而DeepSeek的出现改变了这一格局。各大云厂商纷纷抢占R1及其完整版的上架机会，即使70B版本可能跑不动，7B版本也能提供服务，让他们得以展示自身价值，吸引开发者。事实上，在国内，许多云厂商提供的满血版R1API服务被大量使用，需求几乎满负荷。<br>以袁进辉老师的硅基流动为例，他是较早上线DeepSeekR1的，但频繁遇到负载过高的问题，导致无法继续提供服务。在DeepSeek之前，云厂商的服务并未如此紧张，因为没有一个强大的开源模型吸引如此多的用户。然而，DeepSeek的出现让云计算厂商迎来了前所未有的机遇，因此NVIDIA、微软等企业第一时间上线了R1，甚至一向对中国市场态度冷淡的Oracle也迅速支持DeepSeek，足见其影响力之大。<br>未来，DeepSeek预计仍将保持R1版本的开源，但具体开放到何时尚难预测。根据创始人梁文锋的采访，DeepSeek的目标是迈向AGI，而非单纯的商业化。因此，他们甚至关闭了充值功能，这无疑会影响商业化进程。然而，在算力资源紧张、国内芯片供应受限的情况下，DeepSeek可能更专注于提升算力与训练更强的模型，而非急于盈利。<br>这一局势让其他模型厂商颇为尴尬——DeepSeek的下一个版本究竟能否超越OpenAI？如果能，其他厂商该如何应对？尤其是国内企业，将面临巨大压力。而对于芯片厂商而言，DeepSeek的崛起无疑是重大利好。无论是英伟达、AMD，还是华为、百度昆仑芯等，即便是本地运行大模型，依然需要强大的算力支撑，推动了AI硬件市场的进一步发展。<br>吴双：大模型的能力正迅速向商品化方向发展，这意味着大模型将大规模供应，且价格会迅速下降，针对这一点，硅谷已达成共识。在硅谷科技圈，真正从事底层大模型训练的公司数量极少，可能一只手就能数过来。大部分公司是在这些基础智能能力的基础上，构建各种应用。因此，当前的行业结构正在逐渐成型：少数公司类似于当年CPU提供商，专注于大模型算力和智能的底层提供；而上层的开发者则通过使用这些底层能力，解决具体的场景问题。我认为，这种两层结构已经初步形成。<br>对于云厂商来说，他们已经有了各自的大模型团队，或者与其他公司合作。例如，亚马逊与Anthropic紧密合作、Google拥有自己的团队，而微软与OpenAI之间的关系逐渐有所松动，但它也在积极寻求确保拥有行业领先的大模型。我认为，这些大公司的博弈对普通开发者影响不大。普通开发者更应该关注的是，如果我们的模型能力达到R1水平，甚至更高，我们能解决什么实际问题。这个问题才是更开放、更复杂、更有机会的，也是大家需要关注的重点。<br>至于技术发展的未来，我个人关注以下几个方向：<br>首先，大模型在科学研究中的应用正在迅速发展，已经有许多人开始将大模型作为科研助手，甚至用它来激发新的科研想法。在制药、分子、材料等领域，大模型已经在帮助改变研究范式。我相信，在未来一两年内，基于大模型的工作将可能取得诺贝尔奖级的成果。<br>其次，多模态模型是我特别关注的方向。语言毫无疑问是人类高级智能的载体，但人类的智能还包括一些较为基础的能力，如感知、运动、物理空间的规划和控制等，而这些正是当前AI的短板，但已经在迅速推进。我们可以预见，今年会有很多新的成果涌现。<br>最后，对于开发者而言，大模型驱动的开发工具正迎来拐点，开发者应尽快学习并使用这些新工具。硅谷从最初的观望态度，已转变为高度认可其价值，并广泛应用来提升效率。现在，国内API的使用成本较低，即使有数据安全顾虑，本地部署也是可行方案。例如，VSCode的相关插件已十分成熟，强烈推荐开发者尝试。<br>开发者启示录<br>唐小引：DeepSeek对开发者有怎样的启示？对开发者及相关技术栈有何影响？未来开发者的方向在哪里？<br>王文广：我们应该尽快使用这些AI工具，提升工作效率、改善生活质量，进而增加幸福感。在前面提到的“中国式全球化”中，过去几十年，全球化一直是美国主导的，但DeepSeek和小红书给我们带来的启示是：全球的用户愿意使用中国的产品，尤其是那些为中国用户量身定制的产品，只要产品好用，其他国家的用户同样会选择它。<br>根据1月份的数据，DeepSeek在全球的分布情况显示，中国市场只占30%，而70%的用户来自海外。除了美国，其他国家的用户分布和各国网民的占比非常相似。这表明，DeepSeek已经被全球用户接受，尽管它是中国的产品。这也意味着中国的产品正逐渐被全球市场认可。<br>对于中国开发者来说，这带来的一大好处是，今后开发的App或其他互联网及AI相关产品，可能不需要进行特别的优化，只要在国内市场能满足需求，再加上多语言支持（现在大模型能够很好地处理多语言），海外市场尤其是欧美、东南亚、中东甚至日本等地区也可能会愿意使用。这是以前只有美国公司才能享有的机会，而现在中国公司也有了这个机会，这是一个非常大的利好。<br>吴双：坦白说，这更多是心态问题。过去，国内互联网发展迅猛，大家的关注点主要在国内市场，因为它足够大且商业价值巨大。但现在，面对如此多的机遇，应该放眼全球，而非局限于本土。从一开始，就应以全球市场为目标，这样机会会更多。如今，我们的技术和人才积累已具备条件，正是大展宏图的好时机。是大家大展宏图的好时机。国内竞争激烈，走出去看看（出海），说不定会有更好的发展。<br>刘伟：大模型将在各行各业带来深远的冲击，这是不可忽视的趋势。然而，目前仍有几个问题需要关注，并且正成为中美及全球市场讨论的焦点：<br>数据问题，数据是大模型发展的驱动力，它的封闭化、过滤和传播等限制正成为发展瓶颈。<br>AI的地理围栏。AI的应用范围需要明确界定，哪些地方可以使用，哪些地方不可以使用。像核武器的控制这种敏感领域，大模型的应用就可能带来巨大风险，因为其脆弱性、不确定性和不可解释性。<br>人机关系。目前业界达成的共识是，所有AI产品应当有人的参与或监督，这样才能确保其可靠性和负责任的使用。这也涉及到人机协同的议题。机器智能水平越高，对人的要求也越高。如果机器的智能水平很高而人的水平相对较低，就可能出现失配，进而导致控制问题。人机协同可以分为四种情况：1.人优机优，这是最理想的情况；2.人优机劣；3.人劣机优；4.人劣机劣。后三种情况都可能带来潜在的风险和问题，大家不应误以为引入了先进工具就能带来理想的结果。<br>智能体自主性。AI的下一步方向可能是智能体（Agent）。这种智能体不仅仅是单一机器的智能，而是多智能体之间的相互作用，甚至是多个机器智能体与环境之间的复杂体系。这种生态系统的演进表明，未来可能会出现更加复杂的多智能体协作，而这种智能体最大的特点是自主性，包括感知、处理、预测和协同能力。<br>伦理道德和法律法规。目前，欧盟已经在去年年底出台了人工智能法案，并且正在推动美国和中国也出台类似的法规。没有适当的约束，人工智能可能对人类和社会产生危害，甚至会像核武器一样，需要严格的管控。<br>对大模型的智能指标设计和评价方法的优化。如何衡量一个模型的优劣？例如，DeepSeek在一些指标上表现优秀，但并非在所有领域都表现完美。因此，我们应当以更加客观的眼光来看待每个大模型，了解它们的优点和缺点，而不是全盘否定或肯定。<br>总体而言，这六个问题是目前中美都在关注的核心议题。在讨论大模型和人工智能时，我们需要从多个角度综合来看待其发展，而不是简单地认为它完全好或完全不好。通过这种全面的视角，我们才能更好地理解人工智能的潜力和挑战。<br>OneMoreThing——解答开发者的一些疑问<br>唐小引：前面我们讨论了不少强化学习相关的内容，针对基于人类反馈的强化学习（RLHF）向纯强化学习（RL）的迁移，在这个过程中，安全性和合规性是否会有所倒退？<br>王文广：强化学习是机器智能进化到自主探索和产生自我意识的关键环节。只有在强化学习过程中，机器能够根据环境反馈更新参数，才能迈向自主意识的产生。这是机器智能获得自我意识的必要条件。<br>正如刘老师提到的，如果把人类置于原始森林中，像狼孩一样，他们可能会缺乏很多智能。类似地，如果机器智能仅在人工监督下进行训练，更新的只是参数，而没有自主探索的能力，那么它就无法产生真正的自主意识。自主意识的产生，必须通过机器与环境（无论是与人还是机器）之间的交流，逐渐将这种交流的成果体现在模型上，才能形成。因此，实现人工超级智能（ASI）的目标，仍然是一个相当遥远的目标。<br>唐小引：哪些应用场景适合用强化学习？<br>吴双：这个话题其实很复杂，想要理解强化学习的应用，首先需要掌握它的基本概念，弄清它当前的发展水平——它能解决哪些问题，不能解决哪些问题。只有了解这些，才能判断强化学习适合哪些场景。<br>强化学习最适用于能够自动生成反馈的环境，最好是不需要人为干预。例如，过去的RLHF（人类反馈强化学习）严格来说与强化学习的关系不大，因为它的环境反馈缺乏典型的序列决策特性。而真正适合强化学习的场景，通常具备以下特点：<br>1.工作流程复杂，且步骤较长——这些步骤之间有复杂的依赖关系，但在应用场景中是清晰定义的，不需要开发者手动架构。<br>2.反馈机制清晰——例如业务流程中的成功率、具体的运营数据等，这些可以作为强化学习的直接反馈指标。<br>3.系统能够持续运转——即便目前是由人执行这些流程，强化学习仍然可以从工作日志中学习，并逐步优化流程，甚至可能找到人类未曾发现的更优方案。<br>强化学习的一个挑战在于，如果开发者过多介入手工建模，就可能引入主观偏见，导致环境被扭曲，使得智能体的学习方向偏离最优路径。因此，最理想的情况是让智能体在真实业务流程中持续迭代，基于真实数据优化决策逻辑。<br>当然，强化学习的应用并不是简单的“拿来就能用”——它无法直接复制到所有场景，而需要结合具体业务特点进行调整。但值得关注的是，它在许多不同领域的应用往往具有共性。如果理解了强化学习的基本原理，就能在其他行业的成功案例中找到可借鉴的方法。例如，某个领域成功应用强化学习优化流程后，类似的思路或许也可以迁移到你所在的行业。<br>目前，强化学习仍是一片“蓝海”，很多潜在应用场景还未被探索。对于技术从业者来说，这正是一个值得深入研究的方向，也许某些领域的尝试会带来意想不到的突破。<br>唐小引：DeepSeek对自动驾驶有什么影响？<br>吴双：从技术人员的角度来看，DeepSeek以及整个大模型的发展对我们有很大的借鉴意义，但能否直接将其应用到自动驾驶领域，仍然值得商榷。<br>大模型的成功已经在多个领域得到验证，例如近年来在自动驾驶领域开始讨论的VRM（VehicleRepresentationModel）和VLA（VehicleLanguageAgent），它们与大模型的技术路线一脉相承。因此，底层技术具有可复用性，许多大模型的最新成果也可以被借鉴。但这并不意味着可以直接将ChatGPT搬到汽车上，让它来开车——这完全是两个不同的问题。<br>另一个值得关注的点是DeepSeekR1背后的强化学习机制，这对于自动驾驶研究带来了一定的启发。近期，苹果公司发布了一篇论文，探讨如何在模拟环境中利用强化学习训练自动驾驶算法，而不依赖真实世界数据采集。这证明了强化学习在自动驾驶中的可行性，同时也拓宽了研究边界。<br>技术的发展并不是简单地从论文到应用的直接搬运，而是理解其工作原理，并将核心思想应用到具体场景。例如，AlphaGo和AlphaZero之所以成功，是因为它们依赖高质量的模拟器。那么，自动驾驶是否也需要更好的模拟器？如果现有的模拟器不足，该如何构建？世界模型的研究是否能提供帮助？这些问题相互关联，也推动着行业的不断创新。<br>近两年自动驾驶的进展相比前几年更为迅速，核心原因在于技术架构的变化。这种变化并非技术的简单拷贝，而是基于对大模型原理的深入理解和借鉴，从而推动行业迈向新的高度。<br>唐小引：DeepSeek怎么适配国产芯片，效率怎么样？<br>刘伟：业界正在积极推进大模型在国产芯片上的适配，但当前成果尚不明朗，仍缺乏清晰的效果展示。不过，随着持续投入，这一生态体系有望逐步完善。<br>近期，芯片产业的讨论愈发热烈，特别是最新相关新闻显示，国内芯片产业正加速推进。面对外部挑战，自主研发已成为必然选择，正如那句经典的话：“没有枪没有炮，只能自己造。”<br>吴双：从适配情况来看，国产芯片已基本支持大部分主流模型，虽然高规格的“满血版”适配较少，但70B、32B，甚至7B规模的模型已能运行，云厂商也在提供相应计算服务。然而，国产芯片在存储能力、多卡通信带宽等方面仍存在瓶颈，影响实际效果。因此，虽然目前已达到“能用”水平，但要真正做到“好用”，仍有较大优化空间。<br>唐小引：DeepSeek在垂直领域的微调方面是否有相关建议或指导？在微调方面，你们有哪些经验可以分享给大家？<br>王文广：我建议大家不要急于进行微调，因为大模型的能力发展迅速。目前尚不清楚DeepSeek的下一版本，以及通义千问和Llama是否会发布基于R1训练的模型，但这些版本都有可能发布。因此，此时进行微调并不必要。我们可以直接采用RAG或知识图谱（KG）等方法，通过知识增强结合DeepSeek的R1或V3模型，基本可以满足垂直应用的需求。<br>在我看来，现阶段微调小模型的意义不大，反而直接使用大模型更为有效。而微调大模型的成本非常高，例如微调一个670B版本的模型可能需要几百张GPU卡。<br>吴双：我非常同意，我认为一开始不必急于进行微调。坦白说，在大多数情况下，微调并不是必需的。而且底层模型的进展非常迅速，微调带来的收益可能会被底层模型的更新所替代。更多时候，我认为大模型的应用层仍有许多值得探索的地方。<br>我认为，积累这些应用层的经验，对于理解价值链条和商业场景的应用，才是更加重要和稳定的经验。底层模型提供基础，在此基础上反复微调并无法积累有价值的经验，因此不太值得去做，除非是在一个足够大且垂直的应用场景中，微调才可能有意义。但我认为，绝大多数情况下，这种条件并不成立，所以不建议进行微调。<br>刘伟：微调是一个过程。实际上，刚才大家讨论的核心方向是：你所使用的应用场景是否足够广泛且有价值。这个方向确定之后，再去考虑微调的问题。千万不要先考虑微调，再去考虑场景，这样做是没有意义的。<br>相关资料：<br>[1]https :&#x2F;&#x2F;mp.weixin.qq.com&#x2F;s&#x2F;QpLifmBbXgY9LoghhvViVw<br>[2]https :&#x2F;&#x2F;github.com&#x2F;deepseek-ai&#x2F;DeepSeek-V3&#x2F;blob&#x2F;main&#x2F;DeepSeek_V3.pdf<br>[3]https :&#x2F;&#x2F;github.com&#x2F;deepseek-ai&#x2F;DeepSeek-R1&#x2F;blob&#x2F;main&#x2F;DeepSeek_R1.pdf<br>关于《万有引力》：<br>这是由CSDN&amp;《新程序员》执行总编唐小引主理的对话栏目。技术趋势多变，一不留神总担心错过。正在发生的技术事件，对于我们开发者意味着什么？我们面临的诸多困惑从何寻找答案？《万有引力》即志在于此，直面事件与困惑，抽丝剥茧，解读技术真相。<br>栏目定位：一档面向开发者群体，聚焦解读技术事件的对话直播栏目。<br>直播观看平台：CSDN视频号、CSDN网站&amp;App<br>多形式：文章、视频、音频都会有，持续关注CSDN公众号都可获取。目前《万有引力》栏目已上线小宇宙平台，欢迎大家关注！</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/02/24/1000002555-2247585835-1/">https://zejuncao.github.io/2025/02/24/1000002555-2247585835-1/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                                    <span class="chip bg-color">开源项目</span>
                                </a>
                            
                                <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                                    <span class="chip bg-color">微信公众号聚合平台</span>
                                </a>
                            
                                <a href="/tags/AI%E7%A7%91%E6%8A%80%E5%A4%A7%E6%9C%AC%E8%90%A5/">
                                    <span class="chip bg-color">AI科技大本营</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/02/24/2650956408-2650956408-2/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/2650956408_2650956408_2.jpg" class="responsive-img" alt="模型安全武装，复旦新研究实现SOTA扩散模型风险概念擦除效果，入选AAAI 2025">
                        
                        <span class="card-title">模型安全武装，复旦新研究实现SOTA扩散模型风险概念擦除效果，入选AAAI 2025</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-02-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                        <span class="chip bg-color">开源项目</span>
                    </a>
                    
                    <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                        <span class="chip bg-color">微信公众号聚合平台</span>
                    </a>
                    
                    <a href="/tags/%E6%9C%BA%E5%99%A8%E4%B9%8B%E5%BF%83/">
                        <span class="chip bg-color">机器之心</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/02/24/1000001349-2247508775-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000001349_2247508775_1.jpg" class="responsive-img" alt="竞赛总结：Kaggle Santa 2024挑战赛">
                        
                        <span class="card-title">竞赛总结：Kaggle Santa 2024挑战赛</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-02-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/">
                        <span class="chip bg-color">开源项目</span>
                    </a>
                    
                    <a href="/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7%E8%81%9A%E5%90%88%E5%B9%B3%E5%8F%B0/">
                        <span class="chip bg-color">微信公众号聚合平台</span>
                    </a>
                    
                    <a href="/tags/Coggle%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/">
                        <span class="chip bg-color">Coggle数据科学</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>





</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
