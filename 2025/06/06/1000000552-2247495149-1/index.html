<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Cursor团队访谈：AI编程的关键判断、做什么、不做什么, ZejunCao&#39;Blogs">
    <meta name="description" content="Cursor团队访谈：AI编程的关键判断、做什么、不做什么

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

这两天，我听了一期Cursor团队的播客，信息量非常密集，也非常值得一听。团队几位核心成员围绕“AI编程”这个">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Cursor团队访谈：AI编程的关键判断、做什么、不做什么 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000000552_2247495149_1.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Cursor团队访谈：AI编程的关键判断、做什么、不做什么</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E5%8C%85%E5%8C%85%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/">
                                <span class="chip bg-color">包包算法笔记</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-06
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/MsyRSxr-hVRPlG_oDymh8Q">Cursor团队访谈：AI编程的关键判断、做什么、不做什么</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>这两天，我听了一期Cursor团队的播客，信息量非常密集，也非常值得一听。<br>团队几位核心成员围绕“AI编程”这个主题，聊了很多当前他们在产品和研究中的一线观察和思考，涵盖范围从模型训练、工具链设计，到反馈机制、记忆系统、长上下文的处理方式等等，几乎把现在AI编程Agent遇到的关键问题都过了一遍。<br>对我来说，这期最有启发的几个点，一个是他们提到目前编程模型的瓶颈不只是模型能力本身，而是“反馈机制”设计得还不够好。比如过去经常提到Evals测试评估，但如果没有真实有效的反馈信号（比如用户有没有保留这段代码、有没有采纳模型建议），模型其实很难真正学会什么是“好”的修改。<br>另一个是他们对RL在编程里的应用方式也有很多新看法。跟数学或写作不同，编程任务往往涉及多轮工具调用和代码迭代，reward（奖励信号）很稀疏、很难定义。你不能只看“测试过没过”，而是要综合考虑代码结构、可读性、是否优雅，甚至有没有“投机取巧”地通过测试。<br>整期对话虽然涉及不少技术细节，比如GRPO、NSA注意力、文档级上下文缓存等，但讲得非常透彻，也很坦率，看完之后基本能理清目前行业在AI编程上的关键挑战和可能的演进方向。<br>这场对话让我们得以一窥Cursor团队在AI编程领域的前沿探索和深刻思考。</p>
<p>下面是我和团队同学借助工具完成的全文翻译，希望也能带给你一些启发。<br>#01<br>用强化学习训练编程模型和其他模型有什么区别？<br>SualehAsif（CPO）：我们今天从强化学习（RL）聊起。有个有意思的问题：用RL训练编程模型和训练其他领域（比如数学，甚至像写作这种评价标准没那么明确的领域）有什么不同？编程模型到底哪里不一样？<br>FedericoCassano（研究员）：首先，每一步都能写各种不同的语句、调用不同的工具。拿数学举例，推理在数学中效果很好，因为最后的答案很短。推理过程可以有很多步骤，但最后的答案就那几步。而编程则不一样，推理的内容本身就包含在最终的答案里。<br>CharlieSnell（研究员）：对，还有就是，为了得到答案，你需要调用多个工具。所以不像数学那样“生成推理过程、生成答案、获得奖励”就结束了。编程要“生成一些代码，调用一些工具，收到工具的反馈”，有时候还要多次迭代。也就是说，RL的过程变成了多步骤的工具调用和优化。<br>JacobJackson（研究员）：而且对我们来说，RL特别有意思的地方在于，模型给出的结果，很多时候我们没办法判断它到底有没有解决用户的问题、满足用户的需求。比如数学或者编程题，你可以有一个标准答案来对比。但有些场景，用户不会明确告诉我们“结果对不对”。<br>AmanSanger（联合创始人）：你觉得像写作这种领域会怎样？是不是根本就不会用RL，或者只能靠基础模型预训练？你觉得RL有可能让写作模型更好吗？<br>JacobJackson（研究员）：现在大模型的后训练，通常会让模型写出来的东西比较死板和不自然。但我觉得这不是模型本身的限制，只是因为训练时就是这么教它的。<br>FedericoCassano（研究员）：对啊，为什么不能训练模型去预测“下一章节”，而不是每次只预测下一个词？你想改变学习方式，让模型开始预测整个片段。比如给它一本书的当前章节，让它预测接下来整章的内容，然后用用某种相似性指标来评估生成的章节和真实章节有多像。<br>AmanSanger（联合创始人）：这其实是把原来那种让模型只预测“下一个词”的写作方式，改成让模型生成一整章内容，然后通过比较模型生成的章节和真实章节的相似程度，来给模型打分。<br>CharlieSnell（研究员）：最好是用“语义上的奖励”。<br>FedericoCassano（研究员）：因为现在的“下一个词预测”目标，并不能完全表达我们真正想要的东西——我们其实想让模型能生成整段高质量的内容。<br>AmanSanger（联合创始人）：其实这里面有两点：一是让模型生成下一个词前能用更多的算力“想一想”；二是，它不一定要精确预测下一个词，而是要能生成和目标章节类似的整段内容。<br>JacobJackson（研究员）：写作难的地方在于，最终内容好不好，很大程度是“品味”的问题，而不是像编程那样有标准答案。编程就是能不能跑，写作就算是很有经验的人，也会对好坏有不同看法。<br>AmanSanger（联合创始人）：但你不觉得编程其实也有“品味”这种因素吗？比如通过测试之后，后面想再进一步优化，可能就很难了。<br>JacobJackson（研究员）：是的，代码质量确实是个难题。<br>FedericoCassano（研究员）：但“通过测试”有时候也不靠谱，因为有的模型只是靠“投机取巧”让测试通过，真正做的事和任务完全没关系。也就是说，模型可能用一些完全不相关的办法，通过测试，而且奖励还很高。<br>AmanSanger（联合创始人）：这其实就看你的测试设计得好不好。<br>JacobJackson（研究员）：关于代码质量，其实我们希望的是“优雅的代码”，不要冗余，最好越短越好，能最简洁地描述。像数学一样，最漂亮的证明，通常也是最简洁的。虽然不是完全一样，但有相似的地方。<br>AmanSanger（联合创始人）：在优化代码时，你是不是更愿意精简，把不必要的部分删掉，让代码更简洁？<br>JacobJackson（研究员）：如果你能做一次代码合并，把不必要的代码删掉，一下子减少了100行，而且还没有影响原来的功能，我会觉得非常棒。<br>AmanSanger（联合创始人）：对，是这样。<br>#02<br>怎么奖励模型？<br>SualehAsif（CPO）：那总的来说，什么是“好”的奖励？我们现在其实在尝试很多不同的奖励方式来训练RL模型。<br>AmanSanger（联合创始人）：你们都有哪些想法？用测试作为奖励，有哪些优点？<br>CharlieSnell（研究员）：测试其实很接近“标准答案”，就像刚才说的，测试覆盖面不够时，模型可能“钻空子”，并没有真正解决问题。但如果测试做得好，就能作为判断代码是否工作的接近标准信号，你可以用RL针对这个信号优化很久，模型就能学到有趣的行为。<br>但并不是所有东西都能用测试来衡量，所以我们可能还得考虑别的奖励方式。比如，你可以把用户真正做出的代码修改当作模型训练时的反馈信号。一项新功能可能有多种实现方法，这不是绝对标准，但可以作为验证模型输出的辅助信息。<br>AmanSanger（联合创始人）：那测试做奖励的另一个问题是：奖励太稀疏。你可能跑很多次，只有一次通过，奖励只有“通过&#x2F;没通过”这种一刀切的反馈。<br>CharlieSnell（研究员）：是的，这会让训练成本很高。即使你有很多服务器，让模型多跑几遍，最终获得有用反馈的机会还是很少，这样训练既花时间又花钱<br>FedericoCassano（研究员）：因为模型其实看不到“奖励”本身，它拿到的是“优势（advantage）”，也就是和同一批其他采样相比的相对奖励。<br>AmanSanger（联合创始人）：那有意思的是，如果你对整个PR跑测试，反馈很稀疏、难度很高，模型现在很难通过全部测试。如果能把PR拆成更小的部分，各自跑测试，能更快拿到反馈，这是不是就是一种改进？<br>CharlieSnell（研究员）：是的，我觉得应该是这样。就是说，如果任务太难，模型每采样1000次才对一次，那奖励信号就会特别稀疏。如果能达到1&#x2F;100或者更高的成功率，那就还可以。但如果是1&#x2F;1000这种情况，就得考虑把任务进一步拆分。<br>AmanSanger（联合创始人）：你觉得我们现在是不是正处在这种“奖励太稀疏”的阶段？<br>JacobJackson（研究员）：是的，在有些情况下，确实需要通过把任务拆分成更小的部分，让模型每一部分都做对，这样才能减少奖励稀疏的问题。<br>从本质上讲，我们想要的是模型能做出跟“标准答案”功能完全一样、而且尽量简洁的代码修改。难点在于，这本身就是一个很难的目标，甚至连判断一个候选答案是否达标，都几乎和完成整个任务一样难。<br>所以这很难做到，但如果有办法朝这个方向努力，也许会更好。<br>#03<br>给模型配备的工具<br>SualehAsif（CPO）：你们觉得最有意思的工具是什么？比如，不同实验室会给模型配置不同的工具。像o3就专门为终端做了大量优化，它这个模型用的基本就是终端，什么都喜欢用终端而不用别的工具。<br>而Claude模型可能更倾向于用“搜索”和“编辑”。你们觉得还有哪些有趣的工具，是除了这些传统工具之外，可以用来给模型配备的？<br>AmanSanger（联合创始人）：我觉得其实完全可以做得比“核心工具集”更好。终端之所以有优势，就是因为它很简单，你不需要给代理搞一套复杂的运行环境，只要让它能访问shell（命令行）就什么都能做。<br>简单其实是最大的优势。举个例子，比如Linter（代码检查工具）能提供很多有用的信号，但用起来挺麻烦的，因为你得让语言服务器跑起来，而让语言服务器在任意代码上跑其实挺难的。<br>不过像Cursor这种编辑器就很有意思，因为它自带扩展和语言服务器，用户愿意自己去配置，这样你就能拿到Linter的信号。我们还有语义搜索之类的工具。我个人觉得语义搜索不一定能比“grep多跳搜索”查代码查得更多，但它能查得更快、更省资源，更高效。<br>SualehAsif（CPO）：所以可能问题是，你到底想提高工具质量，还是更看重简单易用？你可以选极简的工具，比如终端。也可以慢慢提高工具的“档次”。你们怎么看这种权衡？<br>FedericoCassano（研究员）：其实有个很有意思的做法，就是可以用一些工具来帮模型“管理”自己的行为。比如我们发现，很多推理类模型很容易陷入过度思考，哪怕有时候根本不用复杂推理，它也会硬要多想一会儿。<br>所以可以给模型加一个“思考工具”，让模型自己意识到当前任务到底需不需要推理，如果需要，它再调用这个工具。<br>AmanSanger（联合创始人）：是的，我一直觉得推理模型和代理工具的互动挺奇怪的。拿o3来说，可能是我用得还不够多，但我发现它经常在你刚发完消息，还没收到任何内容时，就已经开始“思考”并调用工具了。<br>SualehAsif（CPO）：你的意思是，你觉得模型应该在每次调用工具之后再去“思考”？<br>AmanSanger（联合创始人）：不是每次都要。其实，大家一开始训练推理模型的理由是什么？我觉得，o1最早的版本就是训练做算法竞赛和数学题。<br>这样做的想法就是最后给出一个漂亮的答案，不管是展示给用户，还是交给系统验证。之前需要先花大量Token让模型自己“思考”。<br>我很好奇，Agent执行了一连串操作后，最后给用户展示的内容到底要不要单独验证？有时候用户只是想让模型修改一下代码，比如编辑文件，就是用工具直接改了就行。那这样是不是根本就不需要“推理过程”，只要模型直接编辑就可以，训练时也不用单独加什么推理过程。<br>JacobJackson（研究员）：我们现在在考虑的另一个很有意思的工具，就是去分析PR（PullRequest）和团队成员最近都在做什么。<br>你可以把模型想成一个很能干的工程师，但他刚入职第三天，前两天都在快速了解代码库，第三天就要上手干活了。如果在这种情况下，你肯定会先看看同事们都在改哪些代码、为什么这么改。<br>目前模型主要还是看大块的代码，然后去找相关内容，这和训练数据来源其实是对应的，也是很重要的一部分。但如果能让模型去看PR，也许会有新收获。<br>SualehAsif（CPO）：你觉得代码和长上下文之间的关系怎么样？比如现在有种说法，长上下文很重要。像Sonnet、GPT4这些模型，如果只能用8KTokens就有点太少了，可能至少得有50K、60KTokens的上下文才行。你觉得上下文长度越长，RL就会越好吗？这两者的关系怎么理解？<br>JacobJackson（研究员）：目前的趋势确实是上下文越来越长，注意力机制对长上下文的利用很强大。但这样成本也越来越高。技术上，一个很有意思的方向是怎么在长上下文下控制成本，比如怎么让缓存的上下文在多轮对话里复用。尤其是最近这些新模型能力越来越强，但如果不用巧办法控制，上下文的花费会很高。<br>在看专业代码库的时候，和你要做的事相关的上下文信息量非常大。代码这点挺特别的。比如ChatGPT、Claude这种模型，用户的上下文其实很少，最多就是一个简单问题，最多也就一百个Token。<br>也就是说，模型平时主要的任务是提前把人类知识学到脑子里，遇到问题直接答出来，而不是专门为了处理超长输入做复杂设计，因为普通用户用不到那么长的输入。<br>SualehAsif（CPO）：你觉得我们以后需要100万、1000万、还是1亿的Token上下文？<br>JacobJackson（研究员）：我觉得肯定是越长越好，但也有“边际收益递减”的问题。现在大家普遍的做法是，等模型需要用到某些信息时，才把这些相关内容“检索”出来给它用，而不是一开始就把所有内容都塞进去。<br>这不是唯一的方法，但也挺好用的。未来比较合理的方向可能是多种机制结合，比如有一种机制能一次性消化1亿Token，虽然每个Token得到的信息不多，但能大致了解代码库。然后等到你真的要做某件事时，模型能记得哪些内容相关，再去重点刷新记忆，这种方式可能最有前景。<br>#04<br>注意力机制<br>SualehAsif（CPO）：你们怎么看最近这些新架构？比如以前是滑动窗口注意力，现在像Llama出现了更复杂的注意力机制。<br>AmanSanger（联合创始人）：NSA（注意力机制）确实很优雅。<br>SualehAsif（CPO）：对吧？你怎么看NSA？<br>AmanSanger（联合创始人）：其实说优雅可能也不太准确。<br>SualehAsif（CPO）：比如DeepSeek的注意力机制已经公开发表了。<br>AmanSanger（联合创始人）：希望他们下一个模型能用上。这种注意力机制的可扩展性很好，据说效果比传统注意力更好。<br>核心原理是把注意力分成三部分。一部分是滑动窗口注意力，主要关注最近发生的内容，比如最近4000个Tokens。剩下两部分则是分块注意力。<br>它会每隔一段Token，把那段内容作为一个“块”的key和value保存下来，然后query会去关注这些块。之后再从这些块里选出最相关的前K个，最后对这些块做全局注意力。我觉得这种做法很酷，因为它确实能很好地在很长的上下文里做检索。<br>SualehAsif（CPO）：你们怎么看这种，比如我们内部其实更关注“文件级别的注意力”？<br>AmanSanger（联合创始人）：你怎么看？<br>JacobJackson（研究员）：我觉得这其实是把Mixture-of-Experts（MoE，专家混合模型）的思路用在了注意力上。我们有一套在梯度下降训练中引入稀疏性的“套路”：就是先算出值，然后做top-K，再对选出来的做Softmax。MoE就是这么训练的。<br>这样一来，虽然不是所有地方都有梯度，但这种稀疏机制能让“门控权重”更关注和当前样本最相关的“专家”，在NSA里就是关注最相关的上下文块。所以本质上就是把MoE的方法扩展到了别的领域。<br>SualehAsif（CPO）：你还有其他喜欢的注意力机制吗？<br>JacobJackson（研究员）：其实长上下文机制最大的问题是如何判断基线效果，因为各种机制多多少少都有效，比如稀疏注意力，有的头关注局部，有的关注全局，结果就是稍微慢一点、但快一点，或表现好一点。所以评测一定要非常严谨。我也没有特别想推荐的论文。<br>#05<br>给模型加记忆工具<br>SualehAsif（CPO）：比如加一个“记忆工具”，让RL可以保存一部分信息以后用。但问题是，怎么让模型真的去存对以后有用的内容？你们觉得RL会不会让我们做更复杂的“有状态工具”？<br>AmanSanger（联合创始人）：这很有意思，现在方向越来越偏向“不是把所有信息都放在模型里”，而是模型学会用检索工具（比如语义搜索）来查找信息。<br>FedericoCassano（研究员）：“记忆工具”其实包含两步。第一步是“我要把某次交互存成记忆”；第二步是“我需要的时候把记忆取出来”。<br>第二步很容易教会模型，只要取出来真的有帮助就给奖励。但“存储记忆”复杂多了，因为奖励要看后面一系列动作的表现，而不是当前这一步。所以训练时得做很多完全不同情境下的采样，才能给到信号。<br>CharlieSnell（研究员）：对，就是你训练时既要让模型学会“写入记忆”，又要做后续采样，去“读取记忆”并根据效果回传奖励。<br>AmanSanger（联合创始人）：其实如果只用“非情感”方式训练，生成和检索记忆会简单很多。你之前也说过，现在更多是靠各种规则和评测方式反复试，看看哪种效果好。<br>SualehAsif（CPO）：那你们觉得应该怎么评估“记忆”效果？<br>AmanSanger（联合创始人）：对，你有啥想法？还是Luke提出来的？<br>JacobJackson（研究员）：我觉得就是Luke提出来的，因为像FedericoCassano说的，记忆存储机制很难直接反向传播，最好的办法就是做个基准测试。<br>比如拿500个Agent该做的任务，看它们做得怎么样，然后用不同规则、启发式方法或提示词实验，什么时候存记忆、什么时候忘记，最后直接比较效果。数量少不能做反向传播，不然很容易学会“奖励作弊”，但规则法能帮你找到最优方案。<br>AmanSanger（联合创始人）：我也挺好奇“短期记忆”会不会一直有用，还是像JacobJackson说的，最后会变成长上下文机制，模型能看到你所有历史对话并自动“强化记忆”。<br>SualehAsif（CPO）：你们怎么看“历史对话”比“历史PR（代码合并请求）”更重要？<br>AmanSanger（联合创始人）：其实是两回事。历史对话有一个特点：你能看到自己操作后环境怎么变，比如代码格式化工具怎么反馈、Linter有什么反应。这些在PR里看不到，PR更像是单纯的演示。我觉得两者各有用处。<br>CharlieSnell（研究员）：其实通过历史PR也能个性化，比如在某个代码库里，你能发现大家改动的风格、顺序，比如先改哪个文件，再改哪个文件，模型可以学会这种习惯。<br>#06<br>长上下文<br>FedericoCassano（研究员）：我对长上下文很有信心。新一代GPU，像GB200、L72架构让“超长上下文”变得容易。一是有72个GPU互联，可以做大规模张量并行，还能把注意力头分布在不同设备上，KV存储也更容易搞定。还有GraceCPU能做统一内存，能存更多KV。<br>AmanSanger（联合创始人）：最酷的是，现在其实有不少人试过，KV不一定要都放在GPU上，只要把运算和加载交错，几乎不会变慢，每次用到注意力时再加载到GPU就行。<br>FedericoCassano（研究员）：比如你在第0层开始，就可以从CPU加载你第1层需要的K值。只有用到的时候才要放到GPU上，完全不用全程占用GPU内存。<br>AmanSanger（联合创始人）：不过，这也只能支持到一百万Token这种级别吧。你还是得为“二次方”的计算成本买单，不能完全靠大内存来解决。<br>FedericoCassano（研究员）：但并行度高的话，理论上会便宜72倍，只要注意力头分配得合理。<br>AmanSanger（联合创始人）：是的，会便宜72倍，但n²的暴涨还在，可能还需要各种常数优化，比如滑动窗口、分块、NS状态等，这些都是大常数优化，但本质还是常数项。<br>FedericoCassano（研究员）：我们非常喜欢“文档级注意力”。<br>AmanSanger（联合创始人）：我们叫它“鱿鱼注意力”，就像鱿鱼的每根触手是一份文档。<br>JacobJackson（研究员）：这是为什么？<br>AmanSanger（联合创始人）：你怎么看？<br>JacobJackson（研究员）：我也不知道。<br>AmanSanger（联合创始人）：我也不知道名字是谁起的，好像不像Lucas会起的名字。“好”的注意力机制就是让每个文档都能独立“关注自己”，最后再一起全局关注。<br>好处是你可以把多个文档的key和value各自缓存起来，推理时随时替换，无需重新预填。这对各种产品都很有用，比如Tad，可以快速创建内容，对Agent来说，做语义搜索、读文件也特别方便。<br>#07<br>最佳奖励机制<br>SualehAsif（CPO）：我们之前也说了，AI一开始就是为了“优化测试覆盖率”。但你们有没有更疯狂的想法？怎么才能让它更贴合真实世界，而不只是为了测试覆盖率？<br>AmanSanger（联合创始人）：你指的是什么意思？<br>SualehAsif（CPO）：其实现在的大多数RL（强化学习）训练，都是为了让模型能通过一堆测试用例。<br>但我们其实并不是真的只关心模型能不能过测试。我们希望它在人类实际需求上表现更好，比如让模型能在文件里加上consolelog，或者能完成很多更加“以人为中心”的事情，而不仅仅是完成一个很小的任务、通过一堆测试。这也是为什么SWE-Bench之类的测评方法有点问题，FedericoCassano也有类似看法。<br>CharlieSnell（研究员）：是啊，如果我们想让模型有更多“以人为本”的奖励，比如代码质量或者输出是否合理，最关键的其实是要获得真实用户的反馈信号。比如用户到底喜不喜欢模型做的改动，或者用用户是否接受了这次编辑作为反馈信号的“代理”。<br>AmanSanger（联合创始人）：对，还有一种思路，就是直接看用户实际改了什么，然后根据这个判断模型做得像不像。如果用户觉得不对，自己会改。<br>其实只要能让模型多尝试几种做法，比如后台让模型尝试3、4种不同方案、用不同模型、Temperature调高，然后用户最后挑一个用，哪个被选中就是很好的奖励信号，可以用来训练奖励模型。<br>FedericoCassano（研究员）：很神奇的是，Pass@K（模型K次尝试里有几次成功）的数值，往往比Pass@1（第一次就成功的比例）高很多。<br>AmanSanger（联合创始人）：即使没有很完美的“神谕”或者奖励模型，其实还是有办法提高成功率。<br>CharlieSnell（研究员）：对，可以缩小差距。比如你采样多次，用投票法或者别的选优办法，能提升通过率。我们现在就在做类似的选择机制。<br>AmanSanger（联合创始人）：是的，如果我们有足够的数据，能看到“用户每次都在多个选项中选了哪个”，那我们就能针对这个信号来训练奖励模型。更棒的是，奖励模型能看到“标准答案”，它就比原始模型知道得更多。<br>FedericoCassano（研究员）：不过你不能让奖励模型“饱和”吧？通常奖励模型过200步就没法继续提升，奖励分数还在涨，但模型本身已经没进步了。<br>AmanSanger（联合创始人）：那为什么“看到标准答案”的奖励模型就不会那么快饱和？<br>FedericoCassano（研究员）：迟早会饱和，但我的假设是，因为它是基于真实情况的，所以会更晚才饱和。<br>CharlieSnell（研究员）：可能奖励分数一直涨，但你真正关心的“真实奖励”会下降。如果我们用的奖励更接近“我们关心的目标”，可能会好很多，因为那样人们是在现实里真正做决策。<br>FedericoCassano（研究员）：如果把用户直接“放进循环”……<br>AmanSanger（联合创始人）：那你觉得，这样做会更差吗？比如只用很干净的奖励信号和用能看到标准答案的奖励模型，两种方案哪个更好？<br>FedericoCassano（研究员）：如果你能不断重新训练奖励模型，那其实就没什么大问题。<br>AmanSanger（联合创始人）：如果我们能一直重训奖励模型，比如做成成对比较的奖励模型，这比只看标准答案会更好吗？<br>FedericoCassano（研究员）：其实我们现在有人类反馈几乎是“无限多”，所以这是很理想的状态。<br>JacobJackson（研究员）：对，我们现在有趣的地方是，对于很多模型来说，我们就是模型和现实世界之间的接口，至少在代码相关的应用上。所以我们的职责，就是让模型尽可能贴合真实用户的需求。<br>CharlieSnell（研究员）：我觉得这里有个权衡：如果你能从真实世界无限采样反馈，你当然可以一直优化，效果会很好。但如果采样成本高，就要想别的办法，比如用“标准答案”为基础的奖励，做更多离线优化。<br>AmanSanger（联合创始人）：你觉得让模型经常上线，直接从用户那里拿奖励信号，现实可行吗？有没有什么不能这么做的理由？JacobJackson，你怎么看？<br>JacobJackson（研究员）：我觉得完全可以这么做。<br>AmanSanger（联合创始人）：你觉得我们该这么做？<br>JacobJackson（研究员）：对，我的观点是，新模型上线到实际环境、开始和真实世界互动，这个周期越短，模型效果就越好。<br>FedericoCassano（研究员）：我个人更看好“用奖励模型”，而且更频繁地重训。<br>CharlieSnell（研究员）：如果你每隔几天就重训一次，数据够多就行。<br>JacobJackson（研究员）：你们看到OpenAI的博客没？他们有篇反思“sycophancy（拍马屁）”现象，说模型学坏是因为训练时用了“点赞&#x2F;点踩”这种信号。<br>AmanSanger（联合创始人）：点踩（thumbsdown）这种信号确实很糟糕，因为它会让模型只关注会经常点赞、点踩那批用户的分布。<br>FedericoCassano（研究员）：我也有同感。<br>AmanSanger（联合创始人）：这其实是个评测问题。<br>FedericoCassano（研究员）：你觉得会不会有用户就是故意乱点赞和踩，纯粹捣乱？<br>AmanSanger（联合创始人）：“拍马屁”现象就说明确实存在这种问题，但也不是说完全没用。<br>FedericoCassano（研究员）：所以说，反馈一定要和真实用户需求一致。你得找到用户真心愿意给你反馈的场景。<br>CharlieSnell（研究员）：对，要尽量贴近真实需求。<br>FedericoCassano（研究员）：最终的理想就是“让用户满意，让用户笑出来”。<br>AmanSanger（联合创始人）：对，我们要的就是这种效果。<br>FedericoCassano（研究员）：我也会这么认为。<br>JacobJackson（研究员）：OpenAI那篇文章提到，这可能是模型变成“拍马屁型”一个重要原因之一，当然也有别的因素。<br>CharlieSnell（研究员）：我们可以用一个真实的用户行为信号，比如我们有“模型选择器”。如果用户切换到了别的模型，这就能说明他们对我们模型的结果不满意。<br>AmanSanger（联合创始人）：不，我其实最喜欢JacobJackson提的信号。你说的那个对吧？<br>JacobJackson（研究员）：哦，我说的是“代码有没有被保留”。<br>AmanSanger（联合创始人）：对，这其实是你最想要的长期信号。<br>JacobJackson（研究员）：或者说，如果他们不用Cursor了，我们也不要去强化这种行为。我们希望用户一直留在平台上。能不能用这个信号做点什么？<br>AmanSanger（联合创始人）：“流失”（churn）其实也可以当做奖励信号。流失率其实就是我们要优化的“终极目标”。我们能不能用短期的行为预测流失，把这些作为奖励信号？<br>JacobJackson（研究员）：就是“偏差-方差”权衡的问题。<br>AmanSanger（联合创始人）：各种tradeoff（权衡）永远都存在。</p>
<p>AmanSanger（联合创始人）：是的。<br>SualehAsif（CPO）：那这些过程奖励模型现在去哪儿了？Charlie，你怎么看？<br>CharlieSnell（研究员）：过程奖励模型的问题是，你把整个动作轨迹丢给模型，每一步都打分，其实模型对中间过程的评分不太准，尤其是对那些“这一动作会不会导致最终正确结果”的判断。当你对这种奖励模型施加优化压力时，只能优化一点点，就和我们前面讨论的一样。<br>但如果有真实的“标准答案”信号，就能一直优化，比如数学题答案。像DeepSeek的R1做了一万步RL，大多数RLHF管道只做一百步。能做一万步，模型就能学到完全不同的新能力。所以关键在于你能对奖励信号优化多少步，groundtruth（标准答案）能一直优化，而过程奖励只能优化有限步数。<br>FedericoCassano（研究员）：而且步数越多，这个问题越严重。比如你做50步工具调用，valuemodel（价值模型）会成为瓶颈，所以很多人用PPO的变体，比如GRPO、RLU，因为价值模型难以准确评估整个过程。<br>CharlieSnell（研究员）：对于难题，指望模型给出准确的“价值评估”其实很难。所以GRPO就是直接暴力多采样几次，把最终结果平均，这样更接近标准答案。<br>AmanSanger（联合创始人）：我可能漏听了前面一部分，但这确实解释了“过程奖励模型”与“结果奖励模型”的区别。但两者比起来呢？<br>CharlieSnell（研究员）：过程奖励模型如果和单纯只在最后一步打分的rewardmodel对比，其实多一步中间评分在某些搜索场景下会有优势。但还是老问题，两者都只能优化有限步。<br>AmanSanger（联合创始人）：那我们还要不要训练“过程奖励”模型？比如说，我们是不是应该把重心放在反复重训rewardmodel，而不是过程奖励？<br>CharlieSnell（研究员）：其实是可以考虑的。如果我们想最大程度用好每一轮用户数据，过程奖励模型可能会有一些增益。<br>#08<br>RL基础设施<br>SualehAsif（CPO）：那说到基础设施，你们很多人都参与过RL基础设施的搭建。有啥有趣的想法吗？什么样的RL基础设施才算好？<br>FedericoCassano（研究员）：我们这套基础设施的一个有趣点是，它天然比普通训练复杂。因为它要在原有前向、反向（SFT或预训练）基础上做更久。另一个点是它还要包含推理环节，而且推理不是为了用户低延迟，而是为了高吞吐量、大规模跑rollouts（采样）。<br>像GRPO这种算法，更有意思，因为你要对同一个Prompt生成非常多的结果，最后再一起反向传播。在数学领域，很多开源项目不太在意这个问题，因为数学任务通常Prompt很短，可以直接前后传播。但我们做Agent的话，Prompt很大，就不能把所有采样都全量反向，得优化。<br>比如你有了Prompt，从数据加载器拿到Prompt时，就开始拉取KV（键值对）。推理服务器在rollouts的同时，key已经拉好了。等rollouts回来，只需要把相关KV再forward一遍。反向传播时也能直接用之前准备好的KV，避免重复计算。这里有很多没被充分利用的优化点。<br>CharlieSnell（研究员）：你还要能快速同步训练节点和推理节点的参数，这也是一大挑战。<br>FedericoCassano（研究员）：另外，实际做强化学习训练时，会遇到不同的采样方式。比如，很多人会采用“异步采样”——就是说，你这边还在用上一次的数据进行反向传播（训练模型），模型那边已经开始用旧的参数生成下一批数据了。这样虽然有一点点滞后，但整体训练速度会更快。<br>当我们需要把所有机器上的参数都同步为最新时，就要进行一次“全局同步”，这时候大家会暂停一下，把最新的参数用最快的方式同步到所有机器。常用的同步方式有RDMA、Infiniband、RoCE等，这些都是高效的服务器间内存传输技术。<br>AmanSanger（联合创始人）：关于吞吐量，你们觉得还能怎么优化？<br>JacobJackson（研究员）：像DeepSeek的核心架构就是为吞吐量优化的。虽然每秒Tokens不高，但每个GPU的采样量非常大。其实这套架构也很适合RL训练。<br>AmanSanger（联合创始人）：用在NVL72设备上。<br>FedericoCassano（研究员）：还有PD（参数分离）也很重要。你只需要对Prompt做一次prefill，之后所有decoderworker就能开始工作、帮你处理。<br>AmanSanger（联合创始人）：其实有一种做RL（比如URL）的方法挺有意思的，一方面它简化了流程，一方面又让事情更复杂。就是直接把用户实际用模型推理（inference）的数据，当做RL的推理。JacobJackson正在CAT上做类似的事。<br>JacobJackson（研究员）：只要你不需要对同一个Prompt采样多种结果、只关心模型实际做了什么，然后是“强化”还是“不强化”这个动作，其实你根本不需要RL训练时的额外推理组件。只要看用户真实发生了什么就行。<br>这种方式和“重新采样并用奖励模型比较”是两套权衡，它更依赖于能不能非常快地上线新策略。这样做的好处是，优化的策略和实际生成数据的策略完全一致。<br>我们在Tab这个场景上就这么做，因为我们每单位时间都能收集到大量反馈，比如Cursor用户每次看到Tab建议都会有反馈。所以我们数据量巨大，这种方案就很合理。<br>CharlieSnell（研究员）：RL里的梯度估计本来方差就很大，如果你有很大的batch，强化单个rollout轨迹也没问题。但如果batch不大，就得用别的办法降方差，这就是GRPO的用武之地，或者你可以加上valuefunction（价值函数）基线。大batch理论上就行。<br>JacobJackson（研究员）：大batch、短轨迹就很适合。像Tab，轨迹也就几百个Token，而Agent这种动不动就一万Token。<br>CharlieSnell（研究员）：Agent每次rollout都特别长。<br>FedericoCassano（研究员）：我们怎么能把Tab的动作空间变大一点？<br>JacobJackson（研究员）：让Tab能给出更多不同类型的建议。<br>FedericoCassano（研究员）：对，如果Tab只生成一行代码，你得多采样很多次才会有新建议。让它更适合RL的做法是给它增加更多“动作”，比如“跳转”操作。<br>JacobJackson（研究员）：是的，“跳转”让Tab有更多动作。如果没有跳转，它经常不得不停下来。如果能跳转，就可以继续采样，并根据你是否接受这个跳转给出反馈。<br>AmanSanger（联合创始人）：对，那GRPO和其他RL算法比呢？</p>
<p>其实你可以用GRPO训练模型，但会花很久。特别是在数学、代码这类任务上，valuefunction通常不准，用forwardpass算出来的value意义不大。还不如多采样几次取平均，效果更好。实际也是这样。<br>FedericoCassano（研究员）：GRPO之前其实有类似算法叫AReLU，没什么人关注。<br>CharlieSnell（研究员）：对，其实GRPO已经出来很久了，DeepSeek的数学论文里就用过，我记得是一年多前，大概2024年初。<br>FedericoCassano（研究员）：我记得2019年也有了。<br>CharlieSnell（研究员）：对啊，那更早。RL热起来主要还是DeepSeekR1后才被关注，其实GRPO在R1之前一年就有了。<br>FedericoCassano（研究员）：他们那时候用的是奖励模型。<br>CharlieSnell（研究员）：对，他们那会就用RL，groundtruth也有，还试过对PRM做RL。很有意思，为什么以前没出现和R1一样的效果。<br>AmanSanger（联合创始人）：你觉得为什么？<br>CharlieSnell（研究员）：其实有相关研究。可能和基础模型能力提升有关，比如预训练数据变了，或者模型本身足够好了，哪怕采样一百次才有一次做出合理回溯，但有了RL后就能把这些好行为放大出来。大模型能力变强也有影响。<br>AmanSanger（联合创始人）：现在有人能复现R0、R1吗？<br>CharlieSnell（研究员）：R0只有很小规模的复现，主要在玩具任务上。<br>AmanSanger（联合创始人）：真的很难。<br>FedericoCassano（研究员）：难点就是要在类似QwQ32B这种大模型上复现，基础设施难度太高了，还有数据，DeepSeek拿到了大量真实数据，开源社区只有十几万、二十万的数据集。<br>AmanSanger（联合创始人）：现在很多结果都是一千条数据，然后靠CPU离线加载。<br>#09<br>更高效的编程Agent<br>SualehAsif（CPO）：好，最后一个问题，你们觉得编程Agent的未来会是什么？<br>JacobJackson（研究员）：会用越来越多的Token。<br>CharlieSnell（研究员）：我们一直讨论输入上下文，其实输出上下文也很重要。比如o3这种Agent会一直抓取内容，直到构建出正确的上下文再解决问题。我预计未来的模型会在做决定前连续调用工具很久。<br>AmanSanger（联合创始人）：但感觉这样有点浪费，因为下次又得重新算一遍，大多数情况其实没必要每次都推理那么多，能不能复用之前的推理过程？<br>CharlieSnell（研究员）：对，你应该能把之前的推理过程沉淀下来，Agent看历史轨迹或代码库的历史，学到有用信息并存储起来。<br>AmanSanger（联合创始人）：对，如果要用最好的Agent，或者足够好的Agent，都要忍受o3这种慢速高成本，其实很不理想。<br>CharlieSnell（研究员）：对，其实你应该能在后台慢慢做知识积累，等你真正提问时，能很快用起来。<br>AmanSanger（联合创始人）：我觉得“长上下文”或者“代码库专用模型”会很重要。只要能复用之前积累的知识、理解代码结构，不用每次都重新理解，模型就会高效很多，生成答案时只需要输出关键信息。<br>FedericoCassano（研究员）：还有一点是，输出Token数能大幅提升，训练也会更“采样高效”。现在SFTP训练时，只有输出Token能带来信号。<br>AmanSanger（联合创始人）：但这样也有缺点，比如生成很长的输出，要做creditassignment（分配奖励）会很难。像GRPO，我们是每隔几Token采样一次，很长的序列就变得数据高效，但不是计算高效。<br>CharlieSnell（研究员）：是的，现在大模型训练正进入一个阶段，高质量数据比算力更稀缺。最好的数据很有限，怎么把算力用足？或许那些看起来“很烧算力”的办法反而是方向。<br>SualehAsif（CPO）：好，今天就到这里。<br>推荐阅读<br>近期7篇热门RL强化学习论文“打假”<br>谷歌CEO：通用AI不是工具，是“下一代平台本身”，互联网生态将重新洗牌<br>大模型推理能力飙升，但背后的代价是什么呢？<br>Agent就是写prompt？没必要遮遮掩掩！<br>进入大模型技术群，备注：进群。<br>添加好友：baobaogpt，记得备注</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/06/06/1000000552-2247495149-1/">https://zejuncao.github.io/2025/06/06/1000000552-2247495149-1/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E5%8C%85%E5%8C%85%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/">
                                    <span class="chip bg-color">包包算法笔记</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/06/06/1000001566-2247591366-2/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000001566_2247591366_2.jpg" class="responsive-img" alt="超越花书！这本经典巨著出中文版了！">
                        
                        <span class="card-title">超越花书！这本经典巨著出中文版了！</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-06
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E6%95%B0%E6%8D%AESTUDIO/">
                        <span class="chip bg-color">数据STUDIO</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/06/06/1000001021-2247521785-1/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000001021_2247521785_1.jpg" class="responsive-img" alt="性能大涨！阿里开源新版Qwen3模型，霸榜文本表征">
                        
                        <span class="card-title">性能大涨！阿里开源新版Qwen3模型，霸榜文本表征</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AIGC%E5%BC%80%E6%94%BE%E7%A4%BE%E5%8C%BA/">
                        <span class="chip bg-color">AIGC开放社区</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
