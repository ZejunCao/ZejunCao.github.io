<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="世界亟须为“智能体优先”（agent-first）构建基础设施｜万字逐页深度解读Andrej Karpathy YC演讲, ZejunCao&#39;Blogs">
    <meta name="description" content="世界亟须为“智能体优先”（agent-first）构建基础设施｜万字逐页深度解读Andrej Karpathy YC演讲

仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接

本文旨在对安德烈·卡帕西（AndrejKarpa">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>世界亟须为“智能体优先”（agent-first）构建基础设施｜万字逐页深度解读Andrej Karpathy YC演讲 | ZejunCao&#39;Blogs</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    


    <!-- bg-cover style     -->



<link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
<link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
<link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
<link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
<link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
<link rel="stylesheet" type="text/css" href="/css/matery.css">
<link rel="stylesheet" type="text/css" href="/css/my.css">
<link rel="stylesheet" type="text/css" href="/css/dark.css" media="none" onload="if(media!='all')media='all'">




    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">




    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    



    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 7.3.0"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">ZejunCao&#39;Blogs</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">ZejunCao&#39;Blogs</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/frontcover/1000003140-2650036049_1-1750757244.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">世界亟须为“智能体优先”（agent-first）构建基础设施｜万字逐页深度解读Andrej Karpathy YC演讲</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                <span class="chip bg-color">人工智能学家</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-06-24
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Ty2IrAt92MjaYmedTadM5w">世界亟须为“智能体优先”（agent-first）构建基础设施｜万字逐页深度解读Andrej Karpathy YC演讲</a></p>
<blockquote>
<p>仅用于站内搜索，没有排版格式，具体信息请跳转上方微信公众号内链接</p>
</blockquote>
<p>本文旨在对安德烈·卡帕西（AndrejKarpathy）于2025年6月在YC人工智能创业学校（YCAIStartupSchool）发表的演讲《人工智能时代的软件》（SoftwareintheeraofAI）进行全面、专业的深度剖析。作为人工智能领域的杰出人物，卡帕西的演讲不仅是一系列观察的集合，更是一套关于软件演进的统一理论，并为该领域的建设者和投资者描绘了一幅战略路线图。<br>AndrejKarpathy是人工智能领域最具影响力的思想家和实践者之一。他的职业生涯贯穿了本轮AI革命的几个关键节点：作为OpenAI的创始成员，他参与了奠定当前技术浪潮基础的早期研究；在斯坦福大学，他师从著名AI学者李飞飞，并创立了极具影响力的深度学习课程CS231n；作为特斯拉前人工智能高级总监，他领导团队将前沿的计算机视觉技术应用于自动驾驶系统Autopilot1。近期，他创办了AI教育组织EurekaLabs，致力于通过“ZerotoHero”等课程普及AI知识，这进一步巩固了他作为该领域关键教育者和思想领袖的地位1。Karpathy的深厚学术背景和丰富的产业经验，使其观点具有极高的权威性和前瞻性。<br>演讲背景：<br>本次演讲于6月16日在YC人工智能创业者学校进行，其核心内容不仅是对技术趋势的解读，更是一份为未来十年软件开发制定的战略宣言7。它系统性地阐述了软件开发范式的演进，并为技术领导者、开发者和投资者指明了方向。本文旨在对这份长达72页的PPT进行详尽的、逐页的深度分析，不仅翻译其内容，更将结合广泛的市场、技术和战略背景，全面解读其深层含义。<br>同时我们将遵循卡帕西的叙事逻辑，分为五个部分：<br>1. 探讨软件范式的演进；2. 分析作为新型计算平台的LLM的本质；3. 剖析这些新模型的“心理学”特征；4. 审视当前的市场机遇；5. 论述为“智能体优先”（agent-first）世界构建基础设施的迫切性。<br>1. 1从代码到权重：软件2. 0时代的黎明<br>卡帕西的理论始于对软件开发历史的重新划分。传统软件，即“软件1. 0”，是由人类程序员通过明确的、确定性的指令编写的，其产物是源代码，使用的语言包括Python、C++等。随后，他引入了其在2017年首次提出的“软件2. 0”概念，这标志着一个根本性的转变：程序不再是编写出来的，而是通过优化过程学习得来的。在这个新范式中，软件的核心产物不再是源代码，而是神经网络的数值“权重”——一个通过数据训练优化而成的庞大参数集。<br>这一转变重新定义了开发者的角色。开发者从一个编写算法的“程序员”转变为一个“教师”或“数据策展人”，其主要工作是收集、清洗和标注海量数据集，以引导优化过程找到最佳的程序（即权重）。开发环境也从集成开发环境（IDE）转变为由PyTorch、TensorFlow等框架构成的数据处理流水线和模型训练基础设施。<br>演讲开篇即宣告了一场变革的到来。“GitHub地图”是Karpathy用来描绘软件1. 0世界的巧妙视觉隐喻7。在这张地图上，技术领域被划分为由不同编程语言和框架定义的“领地”和“王国”（如Pythonium、Javacore、DotnetDominion等）。这代表了数十年来由人类程序员手动编写代码的传统软件开发模式。Karpathy以此为基准，引出了即将颠覆这一格局的新范式。<br>将传统的计算机代码（软件1. 0）与一个神经网络权重矩阵（软件2. 0）并置，并引用了Karpathy在2017年发表的博客文章7。<br>此页引入了“软件2. 0”这一核心概念。该术语由Karpathy在2017年的一篇Medium文章中首次提出，迅速成为行业内的重要词汇8。<br>○软件1. 0：由人类程序员用C++、Python等语言编写的显式指令。其逻辑是确定性的、人类可读的。<br>○软件2. 0：“代码”不再是人类编写的逻辑，而是经过训练的神经网络的权重。程序不是被“编写”出来的，而是通过数据“优化”出来的。其源代码由“数据集”和定义了网络骨架的“模型架构”组成11。<br>○早期反响：这一概念最初曾引发一些争议，部分评论者认为它更像是一种“营销炒作”或修辞手法，而非真正的范式转移12。然而，随着神经网络能力的飞速发展，其影响力日益彰显。<br>将“GitHub地图”（软件1. 0）与“HuggingFace模型图谱”（软件2. 0）进行对比7。<br>Karpathy将HuggingFace定位为软件2. 0时代产物（即模型权重）的中央存储库。HuggingFace平台托管了超过一百万个模型、数据集和应用，被誉为“AI领域的GitHub”13。其战略重要性体现在其高达45亿美元的估值（截至2023年）以及来自谷歌、亚马逊、英伟达和Salesforce等所有主要科技巨头的投资13。这雄辩地证明，软件2. 0的“资产”已经形成了一个价值数十亿美元的庞大市场。<br>追溯了从固定功能的神经网络（如AlexNet，约2012年）到可编程的大语言模型（LLM，约2019年）的演进，并首次将软件3. 0定义为“提示”（Prompts）7。<br>○固定功能（软件2. 0）：像AlexNet这样的早期模型，被训练用于执行单一特定任务（如图像识别）。它们功能强大，但在通用性上有所欠缺。</p>
<h2 id="演讲中关于情感分类的例子极好地说明了这三种范式的差异：●软件1-0：一个脆弱的Python函数，依赖于一个硬编码的关键词列表。它易于理解，但无法处理任何细微的语言差别或反讽。●软件2-0：需要一个包含数万条正负面评论的大型标注数据集，经过特征工程（如词袋模型）处理后，用于训练一个二元分类器。这种方法更强大，但资源消耗巨大，且模型功能单一。●软件3-0：一段结构清晰的提示词，向LLM解释任务、定义输出格式，并提供几个示例（即“少样本提示”或few-shotprompting）。这种方法开发速度极快，灵活性高，并且不需要任何自定义的模型训练或代码编写。对比了实现情感分类任务的三种方法从软件1-0到3-0的演进，体现了技术能力与使用门槛之间关系的倒置。软件1-0要求开发者具备深厚的编程语言知识；软件2-0要求开发者掌握机器学习和数据工程的专业技能；而软件3-0，在其基本形式上，仅要求使用者具备清晰的逻辑思维和自然语言表达能力。这极大地降低了软件创造的门槛，这一主题在后续的“氛围感编程”（vibecoding）中将得到进一步阐述。然而，这也预示着“资深”的定义正在改变。一个资深的软件3-0工程师，其核心竞争力可能不再是传统的编码技巧，而是成为一个更优秀的AI“教师”和“沟通者”。他们擅长通过精妙的提示词工程（promptengineering）来引导、约束和激发模型的潜能，并深刻理解模型的“心理”特质，以规避其固有的缺陷。再次展示“GitHub地图”，并在其上增加了一块新大陆：“LLM提示，用英语编写”（软件3-0）。同时，展示了Karpathy广为流传的推文：“最热门的新编程语言是英语”。软件“编程”的门槛被极大地降低了——从需要掌握形式化语言（如Python、C-）的专业知识，转变为熟练运用自然语言。这在极大程度上实现了软件创造的民主化，但同时也对技能提出了新的要求：从纯粹的编码转向提示工程、上下文管理和系统设计。展示了特斯拉Autopilot的技术栈。其中，“2-0代码”模块（如BEVNet、Temporalmodule）处理来自摄像头和传感器的输入以生成预测，这些预测随后被“1-0代码”用于控制转向和加速。这是一个“软件2-0吞噬软件1-0”的真实世界案例10。作为特斯拉前AI总监，Karpathy提供了内部视角。特斯拉最初在视觉任务上更多地使用传统的算法方法（软件1-0），但后来转向了一个统一的神经网络方法（软件2-0），该方法直接从海量的驾驶数据中学习10。“鸟瞰图预测”（Bird’seyeviewpredictions）是神经网络（权重）的输出，这些输出接着成为经典控制系统（代码）的输入。这种范式转变并非简单的技术升级，而是一种深刻的权衡。软件2-0在处理像自动驾驶这样复杂、数据丰富的领域时展现出超越人类的潜力，但同时也引入了新的挑战。特斯拉自动驾驶系统既能完成令人惊叹的驾驶操作，也因其在某些边缘场景下的可靠性问题而备受争议。这种在“能力”与“可靠性”之间的张力，是软件2-0的核心特征。它以牺牲传统软件的确定性和可解释性为代价，换取了在模糊和复杂问题上的强大性能。“巨量的软件将被（重新）编写”，并用箭头表示从1-0向2-0和3-0的迁移7。向软件2-0和3-0的转变不仅意味着创造新应用，更意味着对现有软件进行根本性的平台重构。这创造了巨大的经济机遇，堪比从大型机到个人电脑，或从桌面端到Web端的历史性转变。特征软件1-0软件2-0软件3-0源产物显式代码（如Python文件）神经网络权重（如-pt文件）自然语言提示（如文本文件）开发过程编写显式逻辑策划数据集、训练模型提示工程、少样本示例运行环境CPUGPU-TPU-专用硬件LLM（作为服务或在设备上）核心技能算法思维、语言语法数据科学、机器学习工程提示设计、领域知识、系统设计示例simple-sentiment函数训练好的二元分类器Youareasentimentclassifier…提示这张表格清晰地总结了Karpathy所介绍的基础概念，为理解后续内容奠定了坚实的基础。它将抽象的1-0、2-0和3-0概念具体化、可比较化，极具参考价值。在本部分中，将深入分析卡帕西用以阐释LLM本质及其市场动态的三个关键类比。这三个类比——“效用设施”、“晶圆厂”和“操作系统”——共同构建了一个理解当前AI技术格局的强大心智模型，将其定位为一个全新的、基础性的计算平台。2-1LLM作为一种公共事业或效用设施（Utility）卡帕西引用了吴恩达（AndrewNg）的名言“AI是新的电力”，将LLM类比为一种基础的效用设施或公共服务。●资本支出（CAPEX）与运营支出（OPEX）：训练一个基础模型的巨大前期投入（例如，xAI公司拥有10万块H100GPU的“巨像”计算集群），相当于建设一座“发电厂”的资本支出。而持续提供模型推理服务的成本，则构成了运营支出。●计量访问与同质化API：用户通过一个日益标准化的API（输入提示词，输出文本）接入这个“智能电网”，并根据使用量付费（例如，按百万令牌计费），这与支付电费的方式如出一辙。●可靠性与“断电”：用户要求服务具有高正常运行时间和低延迟，就像要求电网提供稳定的电压一样。当像OpenAI这样的主要供应商服务中断时，整个数字经济都会经历一次“智能断电”（intelligencebrownout）。2-2LLM作为一座晶圆厂（Fab）这个类比将LLM训练中心比作半导体制造的晶圆厂。●深度技术与商业机密：两者都涉及巨额的资本支出、深度的研发投入和专有的技术秘密（“secretsauce”）。●“无厂”与“整合”模式：像Anthropic或Mistral这样在NVIDIA的GPU上训练模型的公司，类似于“无厂”（fabless）芯片设计公司（如AMD或苹果），它们依赖台积电（TSMC）的晶圆厂进行制造。而像Google这样使用自研芯片（TPU）进行训练的公司，则类似于“整合设备制造商”（IDM）（如英特尔），它们拥有自己的晶圆厂。这种区别对成本、控制能力和供应链安全具有重大的战略影响。潜在的xAI被视为垂直整合的参与者，它们“拥有自己的晶圆厂”。幻灯片中提到的xAI由10万块H100GPU组成的“Colossus”集群，直接指向了埃隆·马斯克正在孟菲斯建造的“计算超级工厂”。这一类比的意义超越了单纯的成本考量，它揭示了人工智能计算的地缘政治维度。全球半导体供应链已是地缘政治博弈的核心战场。同样，能否获得尖端的AI芯片（如NVIDIA的H100）以及运行它们所需的庞大能源，正迅速成为衡量国家实力的关键指标。卡帕西提及xAI的“巨像”集群，正是在强调构建一个顶尖LLM已成为一项需要国家级产业投入的行动，这与全球在半导体领域的竞赛遥相呼应。“LLM即晶圆厂”的概念预示着，未来AI的发展将受到与芯片产业相同的产业政策、出口管制和资本投资力量的塑造。将LLM训练集群比作半导体制造工厂（晶圆厂）。模型家族具体模型预估训练成本OpenAIGPT-47800万美元GoogleGemini1-0Ultra1-91亿美元MetaLlama3-家族-5亿多美元AnthropicClaude3Sonnet数千万美元基础模型预估训练成本论证LLM不仅仅是商品，更是一个复杂的软件生态系统，类似于操作系统（OS）。幻灯片展示了一个带有外围设备的“LLMOS”示意图7。●这是Karpathy最核心的类比。○内核-用户空间：系统提示（开发者的指令）就像内核空间，而用户提示则是用户空间。这直接关联到提示注入这一安全挑战，即不受信任的用户输入可能会“攻击”内核的指令23。○内存-RAM-：上下文窗口是LLM的工作记忆。这是一个关键限制，导致了“顺行性遗忘症”（将在第三部分讨论）。○外围设备：LLM可以与计算器、Python解释器、浏览器甚至其他LLM等外部工具交互，将它们视为输入-输出设备。将在一系列传统操作系统（Windows、Mac、Linux）上运行应用（VSCode），与在一系列LLM“操作系统”（GPT-4、Claude、Gemini）上运行LLM应用（Cursor）进行类比。这个类比有力地强化了操作系统的概念。应用（如Cursor这样的面向用户的产品）正与底层的“内核”（基础LLM）解耦。应用开发者可以、也将会为多个LLM进行开发，而用户最终将能够选择或切换它们，就像我们为电脑选择操作系统一样。这创造了一个新的竞争层面，也催生了对OpenRouter（见第14页）这类抽象层的需求。将当前AI的发展阶段比作20世纪50-70年代大型机的分时共享时代。随后，通过在AppleSilicon上运行大型模型的例子，展示了“个人计算v2”的早期迹象。●历史类比与未来趋势：○分时共享：我们通过“终端”（聊天界面）访问强大、集中的LLM（云端的“大型机”），计算任务被分批处理和流式传输。○个人计算v2：强大的端侧硬件，特别是苹果的统一内存架构（UnifiedMemoryArchitecture），正在开启一个新的范式。苹果的M系列芯片最高可支持512GB的统一内存，能够将拥有数千亿参数的庞大LLM完全加载到本地内存中运行24。幻灯片中展示的在多台Mac上运行稀疏专家混合（Mixture-of-Experts-MoE）模型（如Llama4和DeepSeek）的例子，正突显了这一趋势。MoE模型计算效率高，因为在处理任何给定token时，只有一小部分参数是活跃的，这使其非常适合在设备上进行推理26。将文本聊天界面比作图形用户界面（GUI）出现之前的终端，说明LLM如何颠覆了传统的技术扩散模型○聊天即终端：当前LLM的主要交互界面（如ChatGPT）就像命令行——功能强大但体验原始。这暗示着LLM的“GUI”尚未被发明，这在UI-UX设计领域意味着巨大的机遇。○颠覆性扩散：Karpathy指出，技术通常是从军事领域扩散到企业，再到消费者（例如GPS、互联网）。LLM却颠覆了这一模式。最先进的模型几乎在一夜之间就直接提供给了数十亿消费者（“你好ChatGPT，怎么煮鸡蛋？”），而企业和政府现在才开始追赶。这是一个独特的历史时刻，对创新和监管都具有深远影响。28第一部分核心观点：LLM实验室如同晶圆厂，LLM类似于20世纪60年代通过分时共享访问的操作系统，而现在数十亿人突然获得了对其进行编程的能力。这部分内容为LLM作为一种新的、基础性的计算平台进行了全面的定位，为接下来探讨其具体特性和所创造的机会铺平了道路。如果LLM是一个操作系统，那么一场新的平台竞争将不可避免。正如Windows、macOS和Linux在功能、开发者生态和用户体验上各有千秋，来自OpenAI、Anthropic和Google的模型也展现出不同的“风格”和能力。像Cursor这样的AI原生应用虽然可以在不同的LLM上运行，但其行为可能会有细微差异，从而产生“转换摩擦”。这为模型供应商创造了强大的动力去构建自己的生态系统——包括“驱动程序”（API、工具集成）和“应用程序”，以锁定开发者和用户，这与上世纪90年代的操作系统战争如出一辙。这个框架解释了为何像VercelAISDK这样的开发者工具具有重要的战略意义，因为它们充当了跨平台的兼容层23。同时也说明了为什么像Stripe这样的公司要构建特定的“驱动程序”（如其模型上下文协议MCP），以确保自己的“硬件”（服务）能与这个新操作系统良好兼容26。本部分从技术和经济类比转向探讨LLM的行为特征，即Karpathy所称的“心理学”。将LLM描述为“人类的随机模拟”（stochasticsimulationsofpeople），它们拥有一种涌现出的“心理学”。“随机鹦鹉”（stochasticparrots）一词常被用作批判，但Karpathy将其重塑为“人类精神的模拟器”，这是一个更宽容的说法，承认了它们在模拟类人推理、知识和缺陷方面的能力。Transformer架构图再次出现，旨在将这种涌现行为追溯到其底层架构。电影《雨人》的海报，百科全书式的知识-记忆3-2核心病症及其安全隐患●幻觉（Hallucination）：这是指LLM以极高的置信度生成事实不正确或无意义内容的行为。○技术背景：幻觉并非程序错误，而是自回归模型（autoregressivemodel）的固有属性。这类模型的设计目标是预测下一个最可能的token，而非最真实的token27。幻觉的产生可能源于训练数据中的错误、有缺陷的注意力机制，或是模型试图“填补”其知识空白的结果27。○现实影响：幻觉是LLM在企业级应用中普及的主要障碍，尤其是在法律、金融等高风险领域，错误的输出可能导致严重后果28。这也是驱动像Perplexity这样基于检索增强生成（RAG）技术开发问答引擎的关键原因。电影《恐惧拉斯维加斯》的海报幻觉LLM倾向于生成看似合理但实际上不正确或毫无意义的信息。这是可靠性方面的一个主要问题，也是当前研究的重点领域。参差不齐的智能（Jaggedintelligence）一个模型可能在简单的算术或逻辑谜题上失败。这种“参差不齐的智能边界”使得在没有验证的情况下难以信任其输出。顺行性遗忘症（Anterogradeamnesia）LLM没有超越其上下文窗口的长期记忆。这个窗口的功能类似于一个短暂的工作记忆。它们不会通过与用户的互动来将新知识固化到其权重中。卡帕西用电影《记忆碎片》（Memento）和《初恋50次》（50FirstDates）来比喻这种记忆缺陷。为解决此问题，活跃的研究领域包括检索增强生成（Retrieval-AugmentedGeneration-RAG）以及更复杂的持续学习技术，如自适应SVD，这些技术试图在不覆盖关键知识的情况下更新模型权重29。这两部电影为LLM的记忆局限性提供了强大而直观的类比，使一个复杂的技术问题变得易于理解。《记忆碎片》的主角无法形成新的长期记忆，《初恋50次》主角的记忆每天都会重置——两者都是对LLM状态限制的完美隐喻。轻信（Gullibility），以及关于提示注入风险的警告安全深度解读：这指的是提示词注入（promptinjection）漏洞，OWASP将其列为LLM应用面临的头号威胁23。○威胁模型：攻击者将恶意指令嵌入到不受信任的数据中（例如，用户评论、检索到的网页）。由于LLM无法区分可信指令和不可信数据，它可能会遵循恶意指令23。○防御机制：研究重点在于防御机制，如StruQ（结构化指令调优）和SecAlign（特殊偏好优化）。这些方法通过微调模型来忽略数据部分的指令，通常使用特殊的分隔符标记，并从用户输入中过滤掉这些标记23。04新软件时代的机会（人工智能时代的战略机遇）本部分将卡帕西的理论框架转化为具体的商业机会，重点关注应用程序和智能体的构建，这是演讲中最长、最实用的部分，为清晰起见，分为三个小节进行分析。卡帕西主张，当前的战略重点应该是构建“钢铁侠战衣”（即增强人类能力的工具），而非追求“钢铁侠机器人”（即完全自主的系统）。最直接的机会在于开发“部分自治应用”（partialautonomyapps），或称“CopilotforX”类产品，它们旨在增强而非取代人类。这类应用的核心用户体验模式是一个紧密的循环：AI负责生成方案，人类负责验证。产品的成功取决于两点：一是让这个循环过程尽可能快速、便捷；二是将AI“拴在一条短绳上”，确保其生成的内容质量高且易于验证。产品分析：Cursor——程序员的“钢铁侠战衣”Cursor是一款AI原生的代码编辑器，是VisualStudioCode的一个分支，专为AI辅助编程而设计。Cursor的工作流程体现了“生成-验证”循环：-1-将当前状态（代码、文件、错误信息）打包到上下文窗口中；-2-编排对LLM的调用以生成代码修改建议；-3-提供一个定制化的图形界面（GUI），让用户可以方便地审查差异（diff）并一键接受或拒绝修改。Cursor通过其功能设计体现了“自治滑块”（autonomyslider）的概念。其自动化程度从简单的代码补全（按Tab键），到交互式聊天问答（Cmd-K），再到能够执行多步骤任务的智能体模式（Cmd-L），为开发者提供了不同层次的AI辅助。产品分析：PerplexityAI——研究者的“钢铁侠战-衣”Perplexity是一款“对话式问答引擎”，它将LLM与实时网络搜索相结合，旨在提供有来源可查的、准确的答案。其工作流程是：-1-接收用户查询；-2-编排网络搜索和LLM调用，对信息进行综合处理；-3-在一个定制化的GUI中呈现附有引用来源的答案，并提供建议的后续问题。这套流程是解决LLM幻觉问题的直接方案。Perplexity的自治滑块体现在其搜索模式上，用户可以选择从“快速搜索”到“深度研究”，从而控制AI在信息收集过程中的深度和广度。将“Copilot”或“CursorforX”作为主要应用模式详细分解了CursorAI代码编辑器的界面及其核心组件。分解了PerplexityAI问答引擎的构成。公司主要功能最新估值主要投资者HuggingFaceAI社区-模型中心-“AI界的GitHub-“-45亿美元-2023年8月-Google-Amazon-Nvidia-SalesforcePerplexityAIAI问答引擎90亿美元-2024年12月-IVP-JeffBezos-Nvidia-DatabricksCursorAI原生代码编辑器99亿美元-2025年6月-Thrive-Accel-a16z-DSTxAI基础模型与基础设施私有-马斯克生态系统的一部分"><a href="#演讲中关于情感分类的例子极好地说明了这三种范式的差异：●软件1-0：一个脆弱的Python函数，依赖于一个硬编码的关键词列表。它易于理解，但无法处理任何细微的语言差别或反讽。●软件2-0：需要一个包含数万条正负面评论的大型标注数据集，经过特征工程（如词袋模型）处理后，用于训练一个二元分类器。这种方法更强大，但资源消耗巨大，且模型功能单一。●软件3-0：一段结构清晰的提示词，向LLM解释任务、定义输出格式，并提供几个示例（即“少样本提示”或few-shotprompting）。这种方法开发速度极快，灵活性高，并且不需要任何自定义的模型训练或代码编写。对比了实现情感分类任务的三种方法从软件1-0到3-0的演进，体现了技术能力与使用门槛之间关系的倒置。软件1-0要求开发者具备深厚的编程语言知识；软件2-0要求开发者掌握机器学习和数据工程的专业技能；而软件3-0，在其基本形式上，仅要求使用者具备清晰的逻辑思维和自然语言表达能力。这极大地降低了软件创造的门槛，这一主题在后续的“氛围感编程”（vibecoding）中将得到进一步阐述。然而，这也预示着“资深”的定义正在改变。一个资深的软件3-0工程师，其核心竞争力可能不再是传统的编码技巧，而是成为一个更优秀的AI“教师”和“沟通者”。他们擅长通过精妙的提示词工程（promptengineering）来引导、约束和激发模型的潜能，并深刻理解模型的“心理”特质，以规避其固有的缺陷。再次展示“GitHub地图”，并在其上增加了一块新大陆：“LLM提示，用英语编写”（软件3-0）。同时，展示了Karpathy广为流传的推文：“最热门的新编程语言是英语”。软件“编程”的门槛被极大地降低了——从需要掌握形式化语言（如Python、C-）的专业知识，转变为熟练运用自然语言。这在极大程度上实现了软件创造的民主化，但同时也对技能提出了新的要求：从纯粹的编码转向提示工程、上下文管理和系统设计。展示了特斯拉Autopilot的技术栈。其中，“2-0代码”模块（如BEVNet、Temporalmodule）处理来自摄像头和传感器的输入以生成预测，这些预测随后被“1-0代码”用于控制转向和加速。这是一个“软件2-0吞噬软件1-0”的真实世界案例10。作为特斯拉前AI总监，Karpathy提供了内部视角。特斯拉最初在视觉任务上更多地使用传统的算法方法（软件1-0），但后来转向了一个统一的神经网络方法（软件2-0），该方法直接从海量的驾驶数据中学习10。“鸟瞰图预测”（Bird’seyeviewpredictions）是神经网络（权重）的输出，这些输出接着成为经典控制系统（代码）的输入。这种范式转变并非简单的技术升级，而是一种深刻的权衡。软件2-0在处理像自动驾驶这样复杂、数据丰富的领域时展现出超越人类的潜力，但同时也引入了新的挑战。特斯拉自动驾驶系统既能完成令人惊叹的驾驶操作，也因其在某些边缘场景下的可靠性问题而备受争议。这种在“能力”与“可靠性”之间的张力，是软件2-0的核心特征。它以牺牲传统软件的确定性和可解释性为代价，换取了在模糊和复杂问题上的强大性能。“巨量的软件将被（重新）编写”，并用箭头表示从1-0向2-0和3-0的迁移7。向软件2-0和3-0的转变不仅意味着创造新应用，更意味着对现有软件进行根本性的平台重构。这创造了巨大的经济机遇，堪比从大型机到个人电脑，或从桌面端到Web端的历史性转变。特征软件1-0软件2-0软件3-0源产物显式代码（如Python文件）神经网络权重（如-pt文件）自然语言提示（如文本文件）开发过程编写显式逻辑策划数据集、训练模型提示工程、少样本示例运行环境CPUGPU-TPU-专用硬件LLM（作为服务或在设备上）核心技能算法思维、语言语法数据科学、机器学习工程提示设计、领域知识、系统设计示例simple-sentiment函数训练好的二元分类器Youareasentimentclassifier…提示这张表格清晰地总结了Karpathy所介绍的基础概念，为理解后续内容奠定了坚实的基础。它将抽象的1-0、2-0和3-0概念具体化、可比较化，极具参考价值。在本部分中，将深入分析卡帕西用以阐释LLM本质及其市场动态的三个关键类比。这三个类比——“效用设施”、“晶圆厂”和“操作系统”——共同构建了一个理解当前AI技术格局的强大心智模型，将其定位为一个全新的、基础性的计算平台。2-1LLM作为一种公共事业或效用设施（Utility）卡帕西引用了吴恩达（AndrewNg）的名言“AI是新的电力”，将LLM类比为一种基础的效用设施或公共服务。●资本支出（CAPEX）与运营支出（OPEX）：训练一个基础模型的巨大前期投入（例如，xAI公司拥有10万块H100GPU的“巨像”计算集群），相当于建设一座“发电厂”的资本支出。而持续提供模型推理服务的成本，则构成了运营支出。●计量访问与同质化API：用户通过一个日益标准化的API（输入提示词，输出文本）接入这个“智能电网”，并根据使用量付费（例如，按百万令牌计费），这与支付电费的方式如出一辙。●可靠性与“断电”：用户要求服务具有高正常运行时间和低延迟，就像要求电网提供稳定的电压一样。当像OpenAI这样的主要供应商服务中断时，整个数字经济都会经历一次“智能断电”（intelligencebrownout）。2-2LLM作为一座晶圆厂（Fab）这个类比将LLM训练中心比作半导体制造的晶圆厂。●深度技术与商业机密：两者都涉及巨额的资本支出、深度的研发投入和专有的技术秘密（“secretsauce”）。●“无厂”与“整合”模式：像Anthropic或Mistral这样在NVIDIA的GPU上训练模型的公司，类似于“无厂”（fabless）芯片设计公司（如AMD或苹果），它们依赖台积电（TSMC）的晶圆厂进行制造。而像Google这样使用自研芯片（TPU）进行训练的公司，则类似于“整合设备制造商”（IDM）（如英特尔），它们拥有自己的晶圆厂。这种区别对成本、控制能力和供应链安全具有重大的战略影响。潜在的xAI被视为垂直整合的参与者，它们“拥有自己的晶圆厂”。幻灯片中提到的xAI由10万块H100GPU组成的“Colossus”集群，直接指向了埃隆·马斯克正在孟菲斯建造的“计算超级工厂”。这一类比的意义超越了单纯的成本考量，它揭示了人工智能计算的地缘政治维度。全球半导体供应链已是地缘政治博弈的核心战场。同样，能否获得尖端的AI芯片（如NVIDIA的H100）以及运行它们所需的庞大能源，正迅速成为衡量国家实力的关键指标。卡帕西提及xAI的“巨像”集群，正是在强调构建一个顶尖LLM已成为一项需要国家级产业投入的行动，这与全球在半导体领域的竞赛遥相呼应。“LLM即晶圆厂”的概念预示着，未来AI的发展将受到与芯片产业相同的产业政策、出口管制和资本投资力量的塑造。将LLM训练集群比作半导体制造工厂（晶圆厂）。模型家族具体模型预估训练成本OpenAIGPT-47800万美元GoogleGemini1-0Ultra1-91亿美元MetaLlama3-家族-5亿多美元AnthropicClaude3Sonnet数千万美元基础模型预估训练成本论证LLM不仅仅是商品，更是一个复杂的软件生态系统，类似于操作系统（OS）。幻灯片展示了一个带有外围设备的“LLMOS”示意图7。●这是Karpathy最核心的类比。○内核-用户空间：系统提示（开发者的指令）就像内核空间，而用户提示则是用户空间。这直接关联到提示注入这一安全挑战，即不受信任的用户输入可能会“攻击”内核的指令23。○内存-RAM-：上下文窗口是LLM的工作记忆。这是一个关键限制，导致了“顺行性遗忘症”（将在第三部分讨论）。○外围设备：LLM可以与计算器、Python解释器、浏览器甚至其他LLM等外部工具交互，将它们视为输入-输出设备。将在一系列传统操作系统（Windows、Mac、Linux）上运行应用（VSCode），与在一系列LLM“操作系统”（GPT-4、Claude、Gemini）上运行LLM应用（Cursor）进行类比。这个类比有力地强化了操作系统的概念。应用（如Cursor这样的面向用户的产品）正与底层的“内核”（基础LLM）解耦。应用开发者可以、也将会为多个LLM进行开发，而用户最终将能够选择或切换它们，就像我们为电脑选择操作系统一样。这创造了一个新的竞争层面，也催生了对OpenRouter（见第14页）这类抽象层的需求。将当前AI的发展阶段比作20世纪50-70年代大型机的分时共享时代。随后，通过在AppleSilicon上运行大型模型的例子，展示了“个人计算v2”的早期迹象。●历史类比与未来趋势：○分时共享：我们通过“终端”（聊天界面）访问强大、集中的LLM（云端的“大型机”），计算任务被分批处理和流式传输。○个人计算v2：强大的端侧硬件，特别是苹果的统一内存架构（UnifiedMemoryArchitecture），正在开启一个新的范式。苹果的M系列芯片最高可支持512GB的统一内存，能够将拥有数千亿参数的庞大LLM完全加载到本地内存中运行24。幻灯片中展示的在多台Mac上运行稀疏专家混合（Mixture-of-Experts-MoE）模型（如Llama4和DeepSeek）的例子，正突显了这一趋势。MoE模型计算效率高，因为在处理任何给定token时，只有一小部分参数是活跃的，这使其非常适合在设备上进行推理26。将文本聊天界面比作图形用户界面（GUI）出现之前的终端，说明LLM如何颠覆了传统的技术扩散模型○聊天即终端：当前LLM的主要交互界面（如ChatGPT）就像命令行——功能强大但体验原始。这暗示着LLM的“GUI”尚未被发明，这在UI-UX设计领域意味着巨大的机遇。○颠覆性扩散：Karpathy指出，技术通常是从军事领域扩散到企业，再到消费者（例如GPS、互联网）。LLM却颠覆了这一模式。最先进的模型几乎在一夜之间就直接提供给了数十亿消费者（“你好ChatGPT，怎么煮鸡蛋？”），而企业和政府现在才开始追赶。这是一个独特的历史时刻，对创新和监管都具有深远影响。28第一部分核心观点：LLM实验室如同晶圆厂，LLM类似于20世纪60年代通过分时共享访问的操作系统，而现在数十亿人突然获得了对其进行编程的能力。这部分内容为LLM作为一种新的、基础性的计算平台进行了全面的定位，为接下来探讨其具体特性和所创造的机会铺平了道路。如果LLM是一个操作系统，那么一场新的平台竞争将不可避免。正如Windows、macOS和Linux在功能、开发者生态和用户体验上各有千秋，来自OpenAI、Anthropic和Google的模型也展现出不同的“风格”和能力。像Cursor这样的AI原生应用虽然可以在不同的LLM上运行，但其行为可能会有细微差异，从而产生“转换摩擦”。这为模型供应商创造了强大的动力去构建自己的生态系统——包括“驱动程序”（API、工具集成）和“应用程序”，以锁定开发者和用户，这与上世纪90年代的操作系统战争如出一辙。这个框架解释了为何像VercelAISDK这样的开发者工具具有重要的战略意义，因为它们充当了跨平台的兼容层23。同时也说明了为什么像Stripe这样的公司要构建特定的“驱动程序”（如其模型上下文协议MCP），以确保自己的“硬件”（服务）能与这个新操作系统良好兼容26。本部分从技术和经济类比转向探讨LLM的行为特征，即Karpathy所称的“心理学”。将LLM描述为“人类的随机模拟”（stochasticsimulationsofpeople），它们拥有一种涌现出的“心理学”。“随机鹦鹉”（stochasticparrots）一词常被用作批判，但Karpathy将其重塑为“人类精神的模拟器”，这是一个更宽容的说法，承认了它们在模拟类人推理、知识和缺陷方面的能力。Transformer架构图再次出现，旨在将这种涌现行为追溯到其底层架构。电影《雨人》的海报，百科全书式的知识-记忆3-2核心病症及其安全隐患●幻觉（Hallucination）：这是指LLM以极高的置信度生成事实不正确或无意义内容的行为。○技术背景：幻觉并非程序错误，而是自回归模型（autoregressivemodel）的固有属性。这类模型的设计目标是预测下一个最可能的token，而非最真实的token27。幻觉的产生可能源于训练数据中的错误、有缺陷的注意力机制，或是模型试图“填补”其知识空白的结果27。○现实影响：幻觉是LLM在企业级应用中普及的主要障碍，尤其是在法律、金融等高风险领域，错误的输出可能导致严重后果28。这也是驱动像Perplexity这样基于检索增强生成（RAG）技术开发问答引擎的关键原因。电影《恐惧拉斯维加斯》的海报幻觉LLM倾向于生成看似合理但实际上不正确或毫无意义的信息。这是可靠性方面的一个主要问题，也是当前研究的重点领域。参差不齐的智能（Jaggedintelligence）一个模型可能在简单的算术或逻辑谜题上失败。这种“参差不齐的智能边界”使得在没有验证的情况下难以信任其输出。顺行性遗忘症（Anterogradeamnesia）LLM没有超越其上下文窗口的长期记忆。这个窗口的功能类似于一个短暂的工作记忆。它们不会通过与用户的互动来将新知识固化到其权重中。卡帕西用电影《记忆碎片》（Memento）和《初恋50次》（50FirstDates）来比喻这种记忆缺陷。为解决此问题，活跃的研究领域包括检索增强生成（Retrieval-AugmentedGeneration-RAG）以及更复杂的持续学习技术，如自适应SVD，这些技术试图在不覆盖关键知识的情况下更新模型权重29。这两部电影为LLM的记忆局限性提供了强大而直观的类比，使一个复杂的技术问题变得易于理解。《记忆碎片》的主角无法形成新的长期记忆，《初恋50次》主角的记忆每天都会重置——两者都是对LLM状态限制的完美隐喻。轻信（Gullibility），以及关于提示注入风险的警告安全深度解读：这指的是提示词注入（promptinjection）漏洞，OWASP将其列为LLM应用面临的头号威胁23。○威胁模型：攻击者将恶意指令嵌入到不受信任的数据中（例如，用户评论、检索到的网页）。由于LLM无法区分可信指令和不可信数据，它可能会遵循恶意指令23。○防御机制：研究重点在于防御机制，如StruQ（结构化指令调优）和SecAlign（特殊偏好优化）。这些方法通过微调模型来忽略数据部分的指令，通常使用特殊的分隔符标记，并从用户输入中过滤掉这些标记23。04新软件时代的机会（人工智能时代的战略机遇）本部分将卡帕西的理论框架转化为具体的商业机会，重点关注应用程序和智能体的构建，这是演讲中最长、最实用的部分，为清晰起见，分为三个小节进行分析。卡帕西主张，当前的战略重点应该是构建“钢铁侠战衣”（即增强人类能力的工具），而非追求“钢铁侠机器人”（即完全自主的系统）。最直接的机会在于开发“部分自治应用”（partialautonomyapps），或称“CopilotforX”类产品，它们旨在增强而非取代人类。这类应用的核心用户体验模式是一个紧密的循环：AI负责生成方案，人类负责验证。产品的成功取决于两点：一是让这个循环过程尽可能快速、便捷；二是将AI“拴在一条短绳上”，确保其生成的内容质量高且易于验证。产品分析：Cursor——程序员的“钢铁侠战衣”Cursor是一款AI原生的代码编辑器，是VisualStudioCode的一个分支，专为AI辅助编程而设计。Cursor的工作流程体现了“生成-验证”循环：-1-将当前状态（代码、文件、错误信息）打包到上下文窗口中；-2-编排对LLM的调用以生成代码修改建议；-3-提供一个定制化的图形界面（GUI），让用户可以方便地审查差异（diff）并一键接受或拒绝修改。Cursor通过其功能设计体现了“自治滑块”（autonomyslider）的概念。其自动化程度从简单的代码补全（按Tab键），到交互式聊天问答（Cmd-K），再到能够执行多步骤任务的智能体模式（Cmd-L），为开发者提供了不同层次的AI辅助。产品分析：PerplexityAI——研究者的“钢铁侠战-衣”Perplexity是一款“对话式问答引擎”，它将LLM与实时网络搜索相结合，旨在提供有来源可查的、准确的答案。其工作流程是：-1-接收用户查询；-2-编排网络搜索和LLM调用，对信息进行综合处理；-3-在一个定制化的GUI中呈现附有引用来源的答案，并提供建议的后续问题。这套流程是解决LLM幻觉问题的直接方案。Perplexity的自治滑块体现在其搜索模式上，用户可以选择从“快速搜索”到“深度研究”，从而控制AI在信息收集过程中的深度和广度。将“Copilot”或“CursorforX”作为主要应用模式详细分解了CursorAI代码编辑器的界面及其核心组件。分解了PerplexityAI问答引擎的构成。公司主要功能最新估值主要投资者HuggingFaceAI社区-模型中心-“AI界的GitHub-“-45亿美元-2023年8月-Google-Amazon-Nvidia-SalesforcePerplexityAIAI问答引擎90亿美元-2024年12月-IVP-JeffBezos-Nvidia-DatabricksCursorAI原生代码编辑器99亿美元-2025年6月-Thrive-Accel-a16z-DSTxAI基础模型与基础设施私有-马斯克生态系统的一部分" class="headerlink" title="演讲中关于情感分类的例子极好地说明了这三种范式的差异：●软件1. 0：一个脆弱的Python函数，依赖于一个硬编码的关键词列表。它易于理解，但无法处理任何细微的语言差别或反讽。●软件2. 0：需要一个包含数万条正负面评论的大型标注数据集，经过特征工程（如词袋模型）处理后，用于训练一个二元分类器。这种方法更强大，但资源消耗巨大，且模型功能单一。●软件3. 0：一段结构清晰的提示词，向LLM解释任务、定义输出格式，并提供几个示例（即“少样本提示”或few-shotprompting）。这种方法开发速度极快，灵活性高，并且不需要任何自定义的模型训练或代码编写。对比了实现情感分类任务的三种方法从软件1. 0到3.0的演进，体现了技术能力与使用门槛之间关系的倒置。软件1. 0要求开发者具备深厚的编程语言知识；软件2. 0要求开发者掌握机器学习和数据工程的专业技能；而软件3. 0，在其基本形式上，仅要求使用者具备清晰的逻辑思维和自然语言表达能力。这极大地降低了软件创造的门槛，这一主题在后续的“氛围感编程”（vibecoding）中将得到进一步阐述。然而，这也预示着“资深”的定义正在改变。一个资深的软件3. 0工程师，其核心竞争力可能不再是传统的编码技巧，而是成为一个更优秀的AI“教师”和“沟通者”。他们擅长通过精妙的提示词工程（promptengineering）来引导、约束和激发模型的潜能，并深刻理解模型的“心理”特质，以规避其固有的缺陷。再次展示“GitHub地图”，并在其上增加了一块新大陆：“LLM提示，用英语编写”（软件3. 0）。同时，展示了Karpathy广为流传的推文：“最热门的新编程语言是英语”。软件“编程”的门槛被极大地降低了——从需要掌握形式化语言（如Python、C++）的专业知识，转变为熟练运用自然语言。这在极大程度上实现了软件创造的民主化，但同时也对技能提出了新的要求：从纯粹的编码转向提示工程、上下文管理和系统设计。展示了特斯拉Autopilot的技术栈。其中，“2. 0代码”模块（如BEVNet、Temporalmodule）处理来自摄像头和传感器的输入以生成预测，这些预测随后被“1. 0代码”用于控制转向和加速。这是一个“软件2. 0吞噬软件1.0”的真实世界案例10。作为特斯拉前AI总监，Karpathy提供了内部视角。特斯拉最初在视觉任务上更多地使用传统的算法方法（软件1. 0），但后来转向了一个统一的神经网络方法（软件2. 0），该方法直接从海量的驾驶数据中学习10。“鸟瞰图预测”（Bird’seyeviewpredictions）是神经网络（权重）的输出，这些输出接着成为经典控制系统（代码）的输入。这种范式转变并非简单的技术升级，而是一种深刻的权衡。软件2. 0在处理像自动驾驶这样复杂、数据丰富的领域时展现出超越人类的潜力，但同时也引入了新的挑战。特斯拉自动驾驶系统既能完成令人惊叹的驾驶操作，也因其在某些边缘场景下的可靠性问题而备受争议。这种在“能力”与“可靠性”之间的张力，是软件2. 0的核心特征。它以牺牲传统软件的确定性和可解释性为代价，换取了在模糊和复杂问题上的强大性能。“巨量的软件将被（重新）编写”，并用箭头表示从1. 0向2.0和3. 0的迁移7。向软件2. 0和3.0的转变不仅意味着创造新应用，更意味着对现有软件进行根本性的平台重构。这创造了巨大的经济机遇，堪比从大型机到个人电脑，或从桌面端到Web端的历史性转变。特征软件1. 0软件2. 0软件3. 0源产物显式代码（如Python文件）神经网络权重（如. pt文件）自然语言提示（如文本文件）开发过程编写显式逻辑策划数据集、训练模型提示工程、少样本示例运行环境CPUGPU&#x2F;TPU&#x2F;专用硬件LLM（作为服务或在设备上）核心技能算法思维、语言语法数据科学、机器学习工程提示设计、领域知识、系统设计示例simple_sentiment函数训练好的二元分类器Youareasentimentclassifier…提示这张表格清晰地总结了Karpathy所介绍的基础概念，为理解后续内容奠定了坚实的基础。它将抽象的1. 0、2. 0和3.0概念具体化、可比较化，极具参考价值。在本部分中，将深入分析卡帕西用以阐释LLM本质及其市场动态的三个关键类比。这三个类比——“效用设施”、“晶圆厂”和“操作系统”——共同构建了一个理解当前AI技术格局的强大心智模型，将其定位为一个全新的、基础性的计算平台。2. 1LLM作为一种公共事业或效用设施（Utility）卡帕西引用了吴恩达（AndrewNg）的名言“AI是新的电力”，将LLM类比为一种基础的效用设施或公共服务。●资本支出（CAPEX）与运营支出（OPEX）：训练一个基础模型的巨大前期投入（例如，xAI公司拥有10万块H100GPU的“巨像”计算集群），相当于建设一座“发电厂”的资本支出。而持续提供模型推理服务的成本，则构成了运营支出。●计量访问与同质化API：用户通过一个日益标准化的API（输入提示词，输出文本）接入这个“智能电网”，并根据使用量付费（例如，按百万令牌计费），这与支付电费的方式如出一辙。●可靠性与“断电”：用户要求服务具有高正常运行时间和低延迟，就像要求电网提供稳定的电压一样。当像OpenAI这样的主要供应商服务中断时，整个数字经济都会经历一次“智能断电”（intelligencebrownout）。2. 2LLM作为一座晶圆厂（Fab）这个类比将LLM训练中心比作半导体制造的晶圆厂。●深度技术与商业机密：两者都涉及巨额的资本支出、深度的研发投入和专有的技术秘密（“secretsauce”）。●“无厂”与“整合”模式：像Anthropic或Mistral这样在NVIDIA的GPU上训练模型的公司，类似于“无厂”（fabless）芯片设计公司（如AMD或苹果），它们依赖台积电（TSMC）的晶圆厂进行制造。而像Google这样使用自研芯片（TPU）进行训练的公司，则类似于“整合设备制造商”（IDM）（如英特尔），它们拥有自己的晶圆厂。这种区别对成本、控制能力和供应链安全具有重大的战略影响。潜在的xAI被视为垂直整合的参与者，它们“拥有自己的晶圆厂”。幻灯片中提到的xAI由10万块H100GPU组成的“Colossus”集群，直接指向了埃隆·马斯克正在孟菲斯建造的“计算超级工厂”。这一类比的意义超越了单纯的成本考量，它揭示了人工智能计算的地缘政治维度。全球半导体供应链已是地缘政治博弈的核心战场。同样，能否获得尖端的AI芯片（如NVIDIA的H100）以及运行它们所需的庞大能源，正迅速成为衡量国家实力的关键指标。卡帕西提及xAI的“巨像”集群，正是在强调构建一个顶尖LLM已成为一项需要国家级产业投入的行动，这与全球在半导体领域的竞赛遥相呼应。“LLM即晶圆厂”的概念预示着，未来AI的发展将受到与芯片产业相同的产业政策、出口管制和资本投资力量的塑造。将LLM训练集群比作半导体制造工厂（晶圆厂）。模型家族具体模型预估训练成本OpenAIGPT-47800万美元GoogleGemini1. 0Ultra1. 91亿美元MetaLlama3(家族)5亿多美元AnthropicClaude3Sonnet数千万美元基础模型预估训练成本论证LLM不仅仅是商品，更是一个复杂的软件生态系统，类似于操作系统（OS）。幻灯片展示了一个带有外围设备的“LLMOS”示意图7。●这是Karpathy最核心的类比。○内核&#x2F;用户空间：系统提示（开发者的指令）就像内核空间，而用户提示则是用户空间。这直接关联到提示注入这一安全挑战，即不受信任的用户输入可能会“攻击”内核的指令23。○内存(RAM)：上下文窗口是LLM的工作记忆。这是一个关键限制，导致了“顺行性遗忘症”（将在第三部分讨论）。○外围设备：LLM可以与计算器、Python解释器、浏览器甚至其他LLM等外部工具交互，将它们视为输入&#x2F;输出设备。将在一系列传统操作系统（Windows、Mac、Linux）上运行应用（VSCode），与在一系列LLM“操作系统”（GPT-4、Claude、Gemini）上运行LLM应用（Cursor）进行类比。这个类比有力地强化了操作系统的概念。应用（如Cursor这样的面向用户的产品）正与底层的“内核”（基础LLM）解耦。应用开发者可以、也将会为多个LLM进行开发，而用户最终将能够选择或切换它们，就像我们为电脑选择操作系统一样。这创造了一个新的竞争层面，也催生了对OpenRouter（见第14页）这类抽象层的需求。将当前AI的发展阶段比作20世纪50-70年代大型机的分时共享时代。随后，通过在AppleSilicon上运行大型模型的例子，展示了“个人计算v2”的早期迹象。●历史类比与未来趋势：○分时共享：我们通过“终端”（聊天界面）访问强大、集中的LLM（云端的“大型机”），计算任务被分批处理和流式传输。○个人计算v2：强大的端侧硬件，特别是苹果的统一内存架构（UnifiedMemoryArchitecture），正在开启一个新的范式。苹果的M系列芯片最高可支持512GB的统一内存，能够将拥有数千亿参数的庞大LLM完全加载到本地内存中运行24。幻灯片中展示的在多台Mac上运行稀疏专家混合（Mixture-of-Experts,MoE）模型（如Llama4和DeepSeek）的例子，正突显了这一趋势。MoE模型计算效率高，因为在处理任何给定token时，只有一小部分参数是活跃的，这使其非常适合在设备上进行推理26。将文本聊天界面比作图形用户界面（GUI）出现之前的终端，说明LLM如何颠覆了传统的技术扩散模型○聊天即终端：当前LLM的主要交互界面（如ChatGPT）就像命令行——功能强大但体验原始。这暗示着LLM的“GUI”尚未被发明，这在UI&#x2F;UX设计领域意味着巨大的机遇。○颠覆性扩散：Karpathy指出，技术通常是从军事领域扩散到企业，再到消费者（例如GPS、互联网）。LLM却颠覆了这一模式。最先进的模型几乎在一夜之间就直接提供给了数十亿消费者（“你好ChatGPT，怎么煮鸡蛋？”），而企业和政府现在才开始追赶。这是一个独特的历史时刻，对创新和监管都具有深远影响。28第一部分核心观点：LLM实验室如同晶圆厂，LLM类似于20世纪60年代通过分时共享访问的操作系统，而现在数十亿人突然获得了对其进行编程的能力。这部分内容为LLM作为一种新的、基础性的计算平台进行了全面的定位，为接下来探讨其具体特性和所创造的机会铺平了道路。如果LLM是一个操作系统，那么一场新的平台竞争将不可避免。正如Windows、macOS和Linux在功能、开发者生态和用户体验上各有千秋，来自OpenAI、Anthropic和Google的模型也展现出不同的“风格”和能力。像Cursor这样的AI原生应用虽然可以在不同的LLM上运行，但其行为可能会有细微差异，从而产生“转换摩擦”。这为模型供应商创造了强大的动力去构建自己的生态系统——包括“驱动程序”（API、工具集成）和“应用程序”，以锁定开发者和用户，这与上世纪90年代的操作系统战争如出一辙。这个框架解释了为何像VercelAISDK这样的开发者工具具有重要的战略意义，因为它们充当了跨平台的兼容层23。同时也说明了为什么像Stripe这样的公司要构建特定的“驱动程序”（如其模型上下文协议MCP），以确保自己的“硬件”（服务）能与这个新操作系统良好兼容26。本部分从技术和经济类比转向探讨LLM的行为特征，即Karpathy所称的“心理学”。将LLM描述为“人类的随机模拟”（stochasticsimulationsofpeople），它们拥有一种涌现出的“心理学”。“随机鹦鹉”（stochasticparrots）一词常被用作批判，但Karpathy将其重塑为“人类精神的模拟器”，这是一个更宽容的说法，承认了它们在模拟类人推理、知识和缺陷方面的能力。Transformer架构图再次出现，旨在将这种涌现行为追溯到其底层架构。电影《雨人》的海报，百科全书式的知识&#x2F;记忆3. 2核心病症及其安全隐患●幻觉（Hallucination）：这是指LLM以极高的置信度生成事实不正确或无意义内容的行为。○技术背景：幻觉并非程序错误，而是自回归模型（autoregressivemodel）的固有属性。这类模型的设计目标是预测下一个最可能的token，而非最真实的token27。幻觉的产生可能源于训练数据中的错误、有缺陷的注意力机制，或是模型试图“填补”其知识空白的结果27。○现实影响：幻觉是LLM在企业级应用中普及的主要障碍，尤其是在法律、金融等高风险领域，错误的输出可能导致严重后果28。这也是驱动像Perplexity这样基于检索增强生成（RAG）技术开发问答引擎的关键原因。电影《恐惧拉斯维加斯》的海报幻觉LLM倾向于生成看似合理但实际上不正确或毫无意义的信息。这是可靠性方面的一个主要问题，也是当前研究的重点领域。参差不齐的智能（Jaggedintelligence）一个模型可能在简单的算术或逻辑谜题上失败。这种“参差不齐的智能边界”使得在没有验证的情况下难以信任其输出。顺行性遗忘症（Anterogradeamnesia）LLM没有超越其上下文窗口的长期记忆。这个窗口的功能类似于一个短暂的工作记忆。它们不会通过与用户的互动来将新知识固化到其权重中。卡帕西用电影《记忆碎片》（Memento）和《初恋50次》（50FirstDates）来比喻这种记忆缺陷。为解决此问题，活跃的研究领域包括检索增强生成（Retrieval-AugmentedGeneration,RAG）以及更复杂的持续学习技术，如自适应SVD，这些技术试图在不覆盖关键知识的情况下更新模型权重29。这两部电影为LLM的记忆局限性提供了强大而直观的类比，使一个复杂的技术问题变得易于理解。《记忆碎片》的主角无法形成新的长期记忆，《初恋50次》主角的记忆每天都会重置——两者都是对LLM状态限制的完美隐喻。轻信（Gullibility），以及关于提示注入风险的警告安全深度解读：这指的是提示词注入（promptinjection）漏洞，OWASP将其列为LLM应用面临的头号威胁23。○威胁模型：攻击者将恶意指令嵌入到不受信任的数据中（例如，用户评论、检索到的网页）。由于LLM无法区分可信指令和不可信数据，它可能会遵循恶意指令23。○防御机制：研究重点在于防御机制，如StruQ（结构化指令调优）和SecAlign（特殊偏好优化）。这些方法通过微调模型来忽略数据部分的指令，通常使用特殊的分隔符标记，并从用户输入中过滤掉这些标记23。04新软件时代的机会（人工智能时代的战略机遇）本部分将卡帕西的理论框架转化为具体的商业机会，重点关注应用程序和智能体的构建，这是演讲中最长、最实用的部分，为清晰起见，分为三个小节进行分析。卡帕西主张，当前的战略重点应该是构建“钢铁侠战衣”（即增强人类能力的工具），而非追求“钢铁侠机器人”（即完全自主的系统）。最直接的机会在于开发“部分自治应用”（partialautonomyapps），或称“CopilotforX”类产品，它们旨在增强而非取代人类。这类应用的核心用户体验模式是一个紧密的循环：AI负责生成方案，人类负责验证。产品的成功取决于两点：一是让这个循环过程尽可能快速、便捷；二是将AI“拴在一条短绳上”，确保其生成的内容质量高且易于验证。产品分析：Cursor——程序员的“钢铁侠战衣”Cursor是一款AI原生的代码编辑器，是VisualStudioCode的一个分支，专为AI辅助编程而设计。Cursor的工作流程体现了“生成-验证”循环：(1)将当前状态（代码、文件、错误信息）打包到上下文窗口中；(2)编排对LLM的调用以生成代码修改建议；(3)提供一个定制化的图形界面（GUI），让用户可以方便地审查差异（diff）并一键接受或拒绝修改。Cursor通过其功能设计体现了“自治滑块”（autonomyslider）的概念。其自动化程度从简单的代码补全（按Tab键），到交互式聊天问答（Cmd+K），再到能够执行多步骤任务的智能体模式（Cmd+L），为开发者提供了不同层次的AI辅助。产品分析：PerplexityAI——研究者的“钢铁侠战-衣”Perplexity是一款“对话式问答引擎”，它将LLM与实时网络搜索相结合，旨在提供有来源可查的、准确的答案。其工作流程是：(1)接收用户查询；(2)编排网络搜索和LLM调用，对信息进行综合处理；(3)在一个定制化的GUI中呈现附有引用来源的答案，并提供建议的后续问题。这套流程是解决LLM幻觉问题的直接方案。Perplexity的自治滑块体现在其搜索模式上，用户可以选择从“快速搜索”到“深度研究”，从而控制AI在信息收集过程中的深度和广度。将“Copilot”或“CursorforX”作为主要应用模式详细分解了CursorAI代码编辑器的界面及其核心组件。分解了PerplexityAI问答引擎的构成。公司主要功能最新估值主要投资者HuggingFaceAI社区&#x2F;模型中心(\“AI界的GitHub\“)45亿美元(2023年8月)Google,Amazon,Nvidia,SalesforcePerplexityAIAI问答引擎90亿美元(2024年12月)IVP,JeffBezos,Nvidia,DatabricksCursorAI原生代码编辑器99亿美元(2025年6月)Thrive,Accel,a16z,DSTxAI基础模型与基础设施私有(马斯克生态系统的一部分)"></a>演讲中关于情感分类的例子极好地说明了这三种范式的差异：<br>●软件1. 0：一个脆弱的Python函数，依赖于一个硬编码的关键词列表。它易于理解，但无法处理任何细微的语言差别或反讽。<br>●软件2. 0：需要一个包含数万条正负面评论的大型标注数据集，经过特征工程（如词袋模型）处理后，用于训练一个二元分类器。这种方法更强大，但资源消耗巨大，且模型功能单一。<br>●软件3. 0：一段结构清晰的提示词，向LLM解释任务、定义输出格式，并提供几个示例（即“少样本提示”或few-shotprompting）。这种方法开发速度极快，灵活性高，并且不需要任何自定义的模型训练或代码编写。<br>对比了实现情感分类任务的三种方法<br>从软件1. 0到3.0的演进，体现了技术能力与使用门槛之间关系的倒置。软件1. 0要求开发者具备深厚的编程语言知识；软件2. 0要求开发者掌握机器学习和数据工程的专业技能；而软件3. 0，在其基本形式上，仅要求使用者具备清晰的逻辑思维和自然语言表达能力。这极大地降低了软件创造的门槛，这一主题在后续的“氛围感编程”（vibecoding）中将得到进一步阐述。<br>然而，这也预示着“资深”的定义正在改变。一个资深的软件3. 0工程师，其核心竞争力可能不再是传统的编码技巧，而是成为一个更优秀的AI“教师”和“沟通者”。他们擅长通过精妙的提示词工程（promptengineering）来引导、约束和激发模型的潜能，并深刻理解模型的“心理”特质，以规避其固有的缺陷。<br>再次展示“GitHub地图”，并在其上增加了一块新大陆：“LLM提示，用英语编写”（软件3. 0）。同时，展示了Karpathy广为流传的推文：“最热门的新编程语言是英语”。<br>软件“编程”的门槛被极大地降低了——从需要掌握形式化语言（如Python、C++）的专业知识，转变为熟练运用自然语言。这在极大程度上实现了软件创造的民主化，但同时也对技能提出了新的要求：从纯粹的编码转向提示工程、上下文管理和系统设计。<br>展示了特斯拉Autopilot的技术栈。其中，“2. 0代码”模块（如BEVNet、Temporalmodule）处理来自摄像头和传感器的输入以生成预测，这些预测随后被“1. 0代码”用于控制转向和加速。<br>这是一个“软件2. 0吞噬软件1.0”的真实世界案例10。作为特斯拉前AI总监，Karpathy提供了内部视角。特斯拉最初在视觉任务上更多地使用传统的算法方法（软件1. 0），但后来转向了一个统一的神经网络方法（软件2. 0），该方法直接从海量的驾驶数据中学习10。“鸟瞰图预测”（Bird’seyeviewpredictions）是神经网络（权重）的输出，这些输出接着成为经典控制系统（代码）的输入。<br>这种范式转变并非简单的技术升级，而是一种深刻的权衡。软件2. 0在处理像自动驾驶这样复杂、数据丰富的领域时展现出超越人类的潜力，但同时也引入了新的挑战。特斯拉自动驾驶系统既能完成令人惊叹的驾驶操作，也因其在某些边缘场景下的可靠性问题而备受争议。这种在“能力”与“可靠性”之间的张力，是软件2. 0的核心特征。它以牺牲传统软件的确定性和可解释性为代价，换取了在模糊和复杂问题上的强大性能。<br>“巨量的软件将被（重新）编写”，并用箭头表示从1. 0向2.0和3. 0的迁移7。<br>向软件2. 0和3.0的转变不仅意味着创造新应用，更意味着对现有软件进行根本性的平台重构。这创造了巨大的经济机遇，堪比从大型机到个人电脑，或从桌面端到Web端的历史性转变。<br>特征<br>软件1. 0<br>软件2. 0<br>软件3. 0<br>源产物<br>显式代码（如Python文件）<br>神经网络权重（如. pt文件）<br>自然语言提示（如文本文件）<br>开发过程<br>编写显式逻辑<br>策划数据集、训练模型<br>提示工程、少样本示例<br>运行环境<br>CPU<br>GPU&#x2F;TPU&#x2F;专用硬件<br>LLM（作为服务或在设备上）<br>核心技能<br>算法思维、语言语法<br>数据科学、机器学习工程<br>提示设计、领域知识、系统设计<br>示例<br>simple_sentiment函数<br>训练好的二元分类器<br>Youareasentimentclassifier…提示<br>这张表格清晰地总结了Karpathy所介绍的基础概念，为理解后续内容奠定了坚实的基础。它将抽象的1. 0、2. 0和3.0概念具体化、可比较化，极具参考价值。<br>在本部分中，将深入分析卡帕西用以阐释LLM本质及其市场动态的三个关键类比。这三个类比——“效用设施”、“晶圆厂”和“操作系统”——共同构建了一个理解当前AI技术格局的强大心智模型，将其定位为一个全新的、基础性的计算平台。<br>2. 1LLM作为一种公共事业或效用设施（Utility）<br>卡帕西引用了吴恩达（AndrewNg）的名言“AI是新的电力”，将LLM类比为一种基础的效用设施或公共服务。<br>●资本支出（CAPEX）与运营支出（OPEX）：训练一个基础模型的巨大前期投入（例如，xAI公司拥有10万块H100GPU的“巨像”计算集群），相当于建设一座“发电厂”的资本支出。而持续提供模型推理服务的成本，则构成了运营支出。<br>●计量访问与同质化API：用户通过一个日益标准化的API（输入提示词，输出文本）接入这个“智能电网”，并根据使用量付费（例如，按百万令牌计费），这与支付电费的方式如出一辙。<br>●可靠性与“断电”：用户要求服务具有高正常运行时间和低延迟，就像要求电网提供稳定的电压一样。当像OpenAI这样的主要供应商服务中断时，整个数字经济都会经历一次“智能断电”（intelligencebrownout）。<br>2. 2LLM作为一座晶圆厂（Fab）<br>这个类比将LLM训练中心比作半导体制造的晶圆厂。<br>●深度技术与商业机密：两者都涉及巨额的资本支出、深度的研发投入和专有的技术秘密（“secretsauce”）。<br>●“无厂”与“整合”模式：像Anthropic或Mistral这样在NVIDIA的GPU上训练模型的公司，类似于“无厂”（fabless）芯片设计公司（如AMD或苹果），它们依赖台积电（TSMC）的晶圆厂进行制造。而像Google这样使用自研芯片（TPU）进行训练的公司，则类似于“整合设备制造商”（IDM）（如英特尔），它们拥有自己的晶圆厂。这种区别对成本、控制能力和供应链安全具有重大的战略影响。潜在的xAI被视为垂直整合的参与者，它们“拥有自己的晶圆厂”。幻灯片中提到的xAI由10万块H100GPU组成的“Colossus”集群，直接指向了埃隆·马斯克正在孟菲斯建造的“计算超级工厂”。<br>这一类比的意义超越了单纯的成本考量，它揭示了人工智能计算的地缘政治维度。全球半导体供应链已是地缘政治博弈的核心战场。同样，能否获得尖端的AI芯片（如NVIDIA的H100）以及运行它们所需的庞大能源，正迅速成为衡量国家实力的关键指标。卡帕西提及xAI的“巨像”集群，正是在强调构建一个顶尖LLM已成为一项需要国家级产业投入的行动，这与全球在半导体领域的竞赛遥相呼应。“LLM即晶圆厂”的概念预示着，未来AI的发展将受到与芯片产业相同的产业政策、出口管制和资本投资力量的塑造。<br>将LLM训练集群比作半导体制造工厂（晶圆厂）。<br>模型家族<br>具体模型<br>预估训练成本<br>OpenAI<br>GPT-4<br>7800万美元<br>Google<br>Gemini1. 0Ultra<br>1. 91亿美元<br>Meta<br>Llama3(家族)<br>5亿多美元<br>Anthropic<br>Claude3Sonnet<br>数千万美元<br>基础模型预估训练成本<br>论证LLM不仅仅是商品，更是一个复杂的软件生态系统，类似于操作系统（OS）。幻灯片展示了一个带有外围设备的“LLMOS”示意图7。<br>●这是Karpathy最核心的类比。<br>○内核&#x2F;用户空间：系统提示（开发者的指令）就像内核空间，而用户提示则是用户空间。这直接关联到提示注入这一安全挑战，即不受信任的用户输入可能会“攻击”内核的指令23。<br>○内存(RAM)：上下文窗口是LLM的工作记忆。这是一个关键限制，导致了“顺行性遗忘症”（将在第三部分讨论）。<br>○外围设备：LLM可以与计算器、Python解释器、浏览器甚至其他LLM等外部工具交互，将它们视为输入&#x2F;输出设备。<br>将在一系列传统操作系统（Windows、Mac、Linux）上运行应用（VSCode），与在一系列LLM“操作系统”（GPT-4、Claude、Gemini）上运行LLM应用（Cursor）进行类比。<br>这个类比有力地强化了操作系统的概念。应用（如Cursor这样的面向用户的产品）正与底层的“内核”（基础LLM）解耦。应用开发者可以、也将会为多个LLM进行开发，而用户最终将能够选择或切换它们，就像我们为电脑选择操作系统一样。这创造了一个新的竞争层面，也催生了对OpenRouter（见第14页）这类抽象层的需求。<br>将当前AI的发展阶段比作20世纪50-70年代大型机的分时共享时代。随后，通过在AppleSilicon上运行大型模型的例子，展示了“个人计算v2”的早期迹象。<br>●历史类比与未来趋势：<br>○分时共享：我们通过“终端”（聊天界面）访问强大、集中的LLM（云端的“大型机”），计算任务被分批处理和流式传输。<br>○个人计算v2：强大的端侧硬件，特别是苹果的统一内存架构（UnifiedMemoryArchitecture），正在开启一个新的范式。苹果的M系列芯片最高可支持512GB的统一内存，能够将拥有数千亿参数的庞大LLM完全加载到本地内存中运行24。幻灯片中展示的在多台Mac上运行稀疏专家混合（Mixture-of-Experts,MoE）模型（如Llama4和DeepSeek）的例子，正突显了这一趋势。MoE模型计算效率高，因为在处理任何给定token时，只有一小部分参数是活跃的，这使其非常适合在设备上进行推理26。<br>将文本聊天界面比作图形用户界面（GUI）出现之前的终端，说明LLM如何颠覆了传统的技术扩散模型<br>○聊天即终端：当前LLM的主要交互界面（如ChatGPT）就像命令行——功能强大但体验原始。这暗示着LLM的“GUI”尚未被发明，这在UI&#x2F;UX设计领域意味着巨大的机遇。<br>○颠覆性扩散：Karpathy指出，技术通常是从军事领域扩散到企业，再到消费者（例如GPS、互联网）。LLM却颠覆了这一模式。最先进的模型几乎在一夜之间就直接提供给了数十亿消费者（“你好ChatGPT，怎么煮鸡蛋？”），而企业和政府现在才开始追赶。这是一个独特的历史时刻，对创新和监管都具有深远影响。28<br>第一部分核心观点：LLM实验室如同晶圆厂，LLM类似于20世纪60年代通过分时共享访问的操作系统，而现在数十亿人突然获得了对其进行编程的能力。<br>这部分内容为LLM作为一种新的、基础性的计算平台进行了全面的定位，为接下来探讨其具体特性和所创造的机会铺平了道路。<br>如果LLM是一个操作系统，那么一场新的平台竞争将不可避免。正如Windows、macOS和Linux在功能、开发者生态和用户体验上各有千秋，来自OpenAI、Anthropic和Google的模型也展现出不同的“风格”和能力。像Cursor这样的AI原生应用虽然可以在不同的LLM上运行，但其行为可能会有细微差异，从而产生“转换摩擦”。<br>这为模型供应商创造了强大的动力去构建自己的生态系统——包括“驱动程序”（API、工具集成）和“应用程序”，以锁定开发者和用户，这与上世纪90年代的操作系统战争如出一辙。这个框架解释了为何像VercelAISDK这样的开发者工具具有重要的战略意义，因为它们充当了跨平台的兼容层23。同时也说明了为什么像Stripe这样的公司要构建特定的“驱动程序”（如其模型上下文协议MCP），以确保自己的“硬件”（服务）能与这个新操作系统良好兼容26。<br>本部分从技术和经济类比转向探讨LLM的行为特征，即Karpathy所称的“心理学”。<br>将LLM描述为“人类的随机模拟”（stochasticsimulationsofpeople），它们拥有一种涌现出的“心理学”。<br>“随机鹦鹉”（stochasticparrots）一词常被用作批判，但Karpathy将其重塑为“人类精神的模拟器”，这是一个更宽容的说法，承认了它们在模拟类人推理、知识和缺陷方面的能力。Transformer架构图再次出现，旨在将这种涌现行为追溯到其底层架构。<br>电影《雨人》的海报，百科全书式的知识&#x2F;记忆<br>3. 2核心病症及其安全隐患<br>●幻觉（Hallucination）：这是指LLM以极高的置信度生成事实不正确或无意义内容的行为。<br>○技术背景：幻觉并非程序错误，而是自回归模型（autoregressivemodel）的固有属性。这类模型的设计目标是预测下一个最可能的token，而非最真实的token27。幻觉的产生可能源于训练数据中的错误、有缺陷的注意力机制，或是模型试图“填补”其知识空白的结果27。<br>○现实影响：幻觉是LLM在企业级应用中普及的主要障碍，尤其是在法律、金融等高风险领域，错误的输出可能导致严重后果28。这也是驱动像Perplexity这样基于检索增强生成（RAG）技术开发问答引擎的关键原因。<br>电影《恐惧拉斯维加斯》的海报幻觉<br>LLM倾向于生成看似合理但实际上不正确或毫无意义的信息。这是可靠性方面的一个主要问题，也是当前研究的重点领域。<br>参差不齐的智能（Jaggedintelligence）<br>一个模型可能在简单的算术或逻辑谜题上失败。这种“参差不齐的智能边界”使得在没有验证的情况下难以信任其输出。<br>顺行性遗忘症（Anterogradeamnesia）<br>LLM没有超越其上下文窗口的长期记忆。这个窗口的功能类似于一个短暂的工作记忆。它们不会通过与用户的互动来将新知识固化到其权重中。卡帕西用电影《记忆碎片》（Memento）和《初恋50次》（50FirstDates）来比喻这种记忆缺陷。为解决此问题，活跃的研究领域包括检索增强生成（Retrieval-AugmentedGeneration,RAG）以及更复杂的持续学习技术，如自适应SVD，这些技术试图在不覆盖关键知识的情况下更新模型权重29。<br>这两部电影为LLM的记忆局限性提供了强大而直观的类比，使一个复杂的技术问题变得易于理解。《记忆碎片》的主角无法形成新的长期记忆，《初恋50次》主角的记忆每天都会重置——两者都是对LLM状态限制的完美隐喻。<br>轻信（Gullibility），以及关于提示注入风险的警告<br>安全深度解读：这指的是提示词注入（promptinjection）漏洞，OWASP将其列为LLM应用面临的头号威胁23。<br>○威胁模型：攻击者将恶意指令嵌入到不受信任的数据中（例如，用户评论、检索到的网页）。由于LLM无法区分可信指令和不可信数据，它可能会遵循恶意指令23。<br>○防御机制：研究重点在于防御机制，如StruQ（结构化指令调优）和SecAlign（特殊偏好优化）。这些方法通过微调模型来忽略数据部分的指令，通常使用特殊的分隔符标记，并从用户输入中过滤掉这些标记23。<br>04<br>新软件时代的机会（人工智能时代的战略机遇）<br>本部分将卡帕西的理论框架转化为具体的商业机会，重点关注应用程序和智能体的构建，这是演讲中最长、最实用的部分，为清晰起见，分为三个小节进行分析。<br>卡帕西主张，当前的战略重点应该是构建“钢铁侠战衣”（即增强人类能力的工具），而非追求“钢铁侠机器人”（即完全自主的系统）。最直接的机会在于开发“部分自治应用”（partialautonomyapps），或称“CopilotforX”类产品，它们旨在增强而非取代人类。<br>这类应用的核心用户体验模式是一个紧密的循环：AI负责生成方案，人类负责验证。产品的成功取决于两点：一是让这个循环过程尽可能快速、便捷；二是将AI“拴在一条短绳上”，确保其生成的内容质量高且易于验证。<br>产品分析：Cursor——程序员的“钢铁侠战衣”<br>Cursor是一款AI原生的代码编辑器，是VisualStudioCode的一个分支，专为AI辅助编程而设计。<br>Cursor的工作流程体现了“生成-验证”循环：(1)将当前状态（代码、文件、错误信息）打包到上下文窗口中；(2)编排对LLM的调用以生成代码修改建议；(3)提供一个定制化的图形界面（GUI），让用户可以方便地审查差异（diff）并一键接受或拒绝修改。<br>Cursor通过其功能设计体现了“自治滑块”（autonomyslider）的概念。其自动化程度从简单的代码补全（按Tab键），到交互式聊天问答（Cmd+K），再到能够执行多步骤任务的智能体模式（Cmd+L），为开发者提供了不同层次的AI辅助。<br>产品分析：PerplexityAI——研究者的“钢铁侠战-衣”<br>Perplexity是一款“对话式问答引擎”，它将LLM与实时网络搜索相结合，旨在提供有来源可查的、准确的答案。<br>其工作流程是：(1)接收用户查询；(2)编排网络搜索和LLM调用，对信息进行综合处理；(3)在一个定制化的GUI中呈现附有引用来源的答案，并提供建议的后续问题。这套流程是解决LLM幻觉问题的直接方案。<br>Perplexity的自治滑块体现在其搜索模式上，用户可以选择从“快速搜索”到“深度研究”，从而控制AI在信息收集过程中的深度和广度。<br>将“Copilot”或“CursorforX”作为主要应用模式<br>详细分解了CursorAI代码编辑器的界面及其核心组件。<br>分解了PerplexityAI问答引擎的构成。<br>公司<br>主要功能<br>最新估值<br>主要投资者<br>HuggingFace<br>AI社区&#x2F;模型中心(\“AI界的GitHub\“)<br>45亿美元(2023年8月)<br>Google,Amazon,Nvidia,Salesforce<br>PerplexityAI<br>AI问答引擎<br>90亿美元(2024年12月)<br>IVP,JeffBezos,Nvidia,Databricks<br>Cursor<br>AI原生代码编辑器<br>99亿美元(2025年6月)<br>Thrive,Accel,a16z,DST<br>xAI<br>基础模型与基础设施<br>私有(马斯克生态系统的一部分)</h2><p>部分自主的普适性挑战<br>AdobePhotoshop和UnrealEngine等复杂软件的界面，并提问LLM如何能在其中“观察”和“行动”。<br>Karpathy将这一模式推广开来。要构建一个“Photoshop的Copilot”，核心挑战是相同的：如何给予AI感官输入（看到画布、图层、工具）和运动控制（在其中执行操作）以及如何让用户保持在监督环路中？这定义了下一代软件的工程任务。<br>人机协作的UI&#x2F;UX循环<br>成功的部分自主应用的关键在于一个紧凑、快速的生成-验证循环。AI生成一个建议，人类快速验证它。为了实现这一点，AI的建议必须是小规模、增量式且易于理解的。nilenso的提示示例展示了一个“深思熟虑”的提示，它将AI限制在一个具体、可验证的任务上，与宽泛、开放式的提示形成对比。这是构建可靠AI辅助工具的关键最佳实践。<br>完全自主的“从演示到产品的鸿沟”<br>使用特斯拉Autopilot的“自主性滑块”和自动驾驶汽车的漫长发展历程来说明实现完全自主的难度。<br>一个演示（demo）是works. any()——它只需成功一次就足以令人印象深刻。而一个产品（product）是works. all()——它必须在所有边缘情况下都可靠地工作。Karpathy借鉴他在特斯拉的经验警告说，弥合这一鸿沟需要付出巨大的努力，尤其是在高可靠性至关重要的领域。这是对围绕完全自主的炒作的一个重要警示。<br>4. 2智能体的十年：跨越“演示到产品”的鸿沟<br>卡帕西对“2025年是智能体元年”的说法提出了质疑，并给出了一个更为现实的预测：“2025到2035年是智能体的十年”。<br>他引入了一个至关重要的概念：“演示到产品的鸿沟”。一个成功的演示（demo）意味着系统在某个时刻成功运行了一次（works. any()），而一个成熟的产品则要求系统在所有情况下都能可靠地运行（works. all()）。对于可靠性至关重要的自治系统而言，这条鸿沟尤为巨大。<br>历史的镜鉴：自动驾驶（特斯拉vs. Waymo）<br>卡帕西用2015至2025年这“驾驶智能体的十年”作为前车之鉴。<br>●Waymo：代表了追求works. all()的路径。自2009年（作为谷歌项目）成立以来，Waymo专注于深度研发、定制硬件（激光雷达、雷达、摄像头），并在有限的地理区域内（地理围栏）实现完全无监督的自动驾驶40。其商业模式是成为“Waymo司机”——一个可授权的自动驾驶系统供应商。<br>●特斯拉：代表了从works. any()到works. all()的迭代路径。其Autopilot和FSD（受监督）系统是驾驶辅助功能，依赖纯视觉方案（软件2. 0），并进行广泛部署以收集数据，通过数据驱动的方式不断改进系统6。这恰好反映了卡帕西所倡导的“部分自治”或“钢铁侠战衣”的哲学。<br>特斯拉与Waymo的对比，为整个智能体市场提供了两种发展路径的范本。一些公司将效仿Waymo，致力于为狭窄但高价值的场景构建高度可靠的全自动智能体（例如，一个能完全自动化特定财务审计流程的智能体）。另一些公司则将遵循特斯拉的模式，构建“副驾驶”和“助手”，在广泛的任务中增强人类能力，并随着时间的推移逐步提高其自主性。卡帕西对“部分自治”的强调表明，他认为后一种模式对于初创公司而言是更具可行性的近期战略。<br>能体的十年——增强先行<br>○AI投资的“钢铁侠”理论：<br>1. 首先，演讲确立了“部分自主”（增强）是当前最直接、最切实的机遇，并以Cursor和Perplexity数十亿美元的估值作为市场证据。这就是“钢铁侠战衣”模式。<br>2. 接着，演讲明确警告了完全自主（“代理”）的巨大困难，引用了“从演示到产品的鸿沟”和自动驾驶的漫长发展时间线。这就是“钢铁侠机器人”模式。<br>3. 外部研究也证实了构建可靠企业级代理面临的巨大挑战：集成复杂性、安全性、上下文管理以及成熟工具的缺乏35。<br>4. 综合以上几点，可以得出一个战略路线图：在短期到中期内，最稳妥且最有利可图的路径是构建“钢铁侠战衣”——即增强人类能力的工具。而开发完全自主的“钢铁侠机器人”则是一项更长期、风险更高的研发任务。这个框架有助于区分近期的产品战略和长期的研究愿景。<br>4. 3氛围感编程（VibeCoding）：创造的民主化与风险<br>卡帕西引入了“氛围感编程”这一新概念，它描述了一种全新的创造方式：创造者“忘记代码的存在”，仅通过高层次的、对话式的指令来引导LLM，并且常常不经审查就接受其生成的代码。<br>●民主化：这种方式极大地降低了创造的技术门槛，使得非技术背景的用户甚至儿童都能构建功能性的应用程序。演讲中展示的MenuGen应用和关于9-13岁儿童编程活动的推文都是力证。<br>●隐藏的复杂性：然而，卡帕西在关于构建MenuGen的博客文章中揭示了一个关键点：“代码是最简单的部分！”。真正的挑战在于那些传统的“软件1. 0”任务：管理API密钥、部署（Vercel）、域名、支付等。演讲中关于使用Clerk添加谷歌登录的例子完美地诠释了这一点——这是一个漫长的、手动的过程，需要在不同的仪表盘之间点击和复制密钥，而这些任务目前还难以通过“氛围感编程”来自动化。<br>通过Karpathy的推文、一个模拟的维基百科条目以及儿童使用它的例子来定义“VibeCoding”。<br>“VibeCoding”是指通过自然语言向LLM描述期望的结果来构建软件，引导和完善AI生成的代码，而无需完全理解每一行代码。Karpathy在2025年2月创造了这个词3。它代表了软件开发的终极民主化，使非专家也能构建真实的应用。<br>如果“氛围感编程”让编写核心逻辑变得轻而易举，那么新的瓶颈就转移到了其他所有环节：基础设施、部署、认证、支付等。这为那些提供简单、近乎“无代码”解决方案的公司创造了巨大的市场机会。Clerk、Vercel和Stripe等公司正处于这个风口。对许多人来说，未来的开发模式可能是在一个强大且易于使用的托管服务框架之上，通过“氛围感编程”来构建核心业务逻辑。“氛围感编程”并没有消除复杂性，它只是将复杂性从代码本身转移到了基础设施层面。<br>案例研究——MenuGen<br>它通过拍摄菜单照片并为每个菜品生成图片来可视化菜单。并指出“代码是最简单的部分！”，并列出了真正的挑战。<br>结合Karpathy博客的深度解读：Karpathy的博客文章《VibecodingMenuGen》41提供了他构建一个真实世界应用时“痛苦跋涉”的第一手资料。<br>“简单”的部分：本地原型很快就创建好了。<br>“困难”的部分（集成噩梦）：大部分工作不是编码，而是在“浏览器里点点点”：<br>API：处理来自OpenAI和Replicate的速率限制、废弃的端点和令人困惑的文档。<br>部署(Vercel)：调试只在Vercel服务器上出现的构建错误，以及管理环境变量。<br>认证(Clerk)：为生产环境进行复杂的设置，包括自定义域名和与GoogleCloud的OAuth配置42。<br>支付(Stripe)：集成另一项服务，管理更多的密钥，并让LLM修复其自身实现中的一个关键设计缺陷。<br>集成的痛苦——谷歌登录展示了通过Clerk添加谷歌登录的复杂、多步骤的文档截图。<br>○“胶水层”作为下一个重大机遇：<br>1. Karpathy的论点是LLM（软件3. 0）是一种新的、强大的编程范式。<br>2. 他的“VibeCoding”经历表明，虽然核心的生成（“做什么”）变得容易，但集成各种不同的服务——即“胶水”——却极其困难和令人沮丧。<br>3. 他所使用的服务（Vercel、Clerk、Stripe）本身都是现代化的、对开发者友好的平台。复杂性源于它们之间的交互。<br>4. 由此可以推断：实现“VibeCoding”和AI驱动开发全部潜力的主要瓶颈，并非LLM本身，而是由API、认证和部署构成的脆弱、复杂的“胶水层”。这意味着，能够抽象掉这种集成复杂性、创建从“想法到部署应用”的无缝管道的平台或工具，存在着巨大的市场机会。解决这个“胶水”问题的公司将释放巨大的价值。<br>信息的三种消费者引入为代理而构建的想法，并列出了数字信息的三种消费者：人类（GUI）、计算机（API）和新的类别——代理（类人计算机）。<br>这是设计思维的根本性转变。几十年来，我们为人类的眼睛（GUI）或机器的解析器（API）设计界面。现在，我们需要为第三类消费者设计：AI代理，它们以一种介于两者之间的方式消费信息。<br>以人为中心vs. 以智能体为中心的网络协议<br>下表清晰地展示了从一个纯人类使用的网络向一个人机共存、智能体感知的网络范式的转变。<br>协议<br>目标“用户”<br>目的<br>类比<br>robots. txt<br>网络爬虫（计算机）<br>控制&#x2F;限制访问<br>“禁止入内”标志<br>HTML&#x2F;GUI<br>人类<br>展示&#x2F;交互<br>“商店橱窗”<br>llms. txt<br>LLM智能体<br>引导&#x2F;提供知识<br>“精心准备的欢迎礼包”<br>MCP&#x2F;可操作API<br>LLM智能体<br>赋能行动&#x2F;工具使用<br>“配备工具的服务台”<br>llms. txt——AI的robots. txt<br>由Answer. AI的JeremyHoward于2024年9月提出，llms. txt是一个为网站内容提供干净、Markdown格式、LLM友好版本的标准44。<br>它类似于robots. txt或站点地图，但不仅仅是控制访问，而是为AI代理提供一个权威的、易于解析的真实来源，剥离了复杂的HTML、CSS和JavaScript。<br>实践中的llms. txt展示了面向人类的文档（Vercel、Clerk）和它们对应的面向LLM的llms. txt或.md版本（Vercel、Stripe）。<br>市场采纳：这不仅仅是一个提案，主流科技公司正在采纳它。Vercel和Stripe现在都提供其文档的机器可读版本46。这表明业界已经认识到“为代理而构建”的必要性。<br>为代理设计的动作——从点击到cURL<br>将Manim（一个基于代码的动画引擎）作为机器可读格式的例子（第65页），并展示了Vercel在其文档中用cURL命令替代了之前的“点击”说明（第66页）。幻灯片还介绍了Stripe的模型上下文协议（ModelContextProtocol,MCP）。<br>cURL命令：这是一个简单但意义深远的转变。提供API命令（cURL）而非人类指令（“点击”），使得文档能被代理直接执行。<br>模型上下文协议(MCP)：这是一个更高级的标准。MCP是一个开放协议，用于标准化应用程序向LLM提供上下文和工具的方式48。Stripe的MCP服务器允许AI代理（如Cursor中的代理）被赋予一套工具，以结构化的方式直接调用StripeAPI并搜索其知识库46。它是一个正式的“代理API”。<br>5. 3自动化上下文构建：“摄取”层<br>●问题所在：要让一个智能体处理复杂任务（例如，重构一个代码库），必须将整个项目的状态“打包到上下文窗口中”。手动完成这项工作非常繁琐。<br>●解决方案：上下文构建器：一类新的工具正在涌现以自动化此过程。<br>○Gitingest：该工具能摄取一个GitHub仓库，并输出一个对提示词友好的文本摘要，包括文件结构和内容，为LLM做好准备。<br>○Devin的DeepWiki：该工具更进一步，不仅摄取代码，还能生成高层次的文档和系统架构图，帮助智能体（或人类）理解代码库的宏观结构。<br>上下文构建器——Gitingest和DeepWiki<br>展示了两款能自动将整个GitHub仓库准备成LLM上下文的工具。<br>Gitingest：一个能抓取整个Git仓库并将其文件结构和内容打包成一个巨大文本文件的工具，非常适合粘贴到具有大上下文窗口的LLM中（如Gemini2. 0Pro）49。它大规模地解决了代码的“上下文打包”问题。<br>DeepWiki：一个来自CognitionAI（Devin的创造者）的更高级的工具，它超越了简单的文本连接。它能分析一个公共GitHub仓库，并自动生成文档、架构图和一个交互式问答界面51。它为人类和AI都创建了一个关于代码库的结构化、语义化的理解。<br>在软件2. 0时代，编译器将人类可读的源代码转换为机器可执行的代码。在软件3. 0的世界里，这些“上下文构建器”扮演了一种新型编译器的角色。它们接收一个复杂的、结构化的产物（如一个Git仓库），并将其“编译”成一种新的“CPU”（即LLM）能够理解和处理的格式（即上下文窗口中的提示词）。这是智能体基础设施中一个至关重要但目前服务尚不完善的环节。<br>一个名为“Operator”的产品的截图，这是一个可以使用自己的浏览器来为用户执行任务的代理。<br>这是一个前瞻性的例子，展示了该领域的发展方向：更自主的代理，能够与现有的网络（为人类构建的GUI世界）进行交互。这弥合了“LLM操作系统”与庞大的人类中心界面遗产之间的鸿沟。<br>完整愿景——统一示意图一张综合性图表，将所有主要概念联系在一起：位于中心的LLMOS、三种软件范式、人机交互循环，以及“为代理而构建”的需求。<br>AndrejKarpathy的演讲展现了卓越的战略远见。他为当前AI热潮的混乱局面提供了一个连贯的心智模型，并规划出一条清晰、可行的路线图。文章认为，最大的机遇不仅在于构建下一个华而不实的智能体演示，更在于建设那些能够让“智能体的十年”成为现实的、强大的、可靠的、标准化的基础设施。这场转型过程将是复杂的，LLM的“心理”缺陷仍将是关键挑战，但发展轨迹已然明确：软件正在再次改变，而那些深刻理解这个新“操作系统”的建设者，将定义下一个科技时代。<br>基于对AndrejKarpathy演讲的全面分析，为不同角色的利益相关者提供以下战略建议：<br>●对于开发者：<br>○角色转变：应将重心从编写底层逻辑转向成为“系统架构师”和“AI编排者”。熟练掌握提示工程、上下文管理以及“给AI套上缰绳”的艺术至关重要。<br>○掌握“胶水层”：学习如何使用和集成各种服务（部署、认证、支付等）将成为核心竞争力。<br>●对于企业领导者：<br>○平台思维：认识到AI不仅是另一个工具，而是一个全新的计算平台。应优先构建能够增强员工能力的“钢铁侠战衣”式应用，以实现立竿见影的投资回报。<br>○数据与接口准备：投资于数据质量，并开始通过采纳llms. txt等标准和开发内部API，使内部系统和文档“为代理做好准备”。<br>●对于投资者：<br>○关注应用层：最大的机会可能不在于构建下一个基础模型（“晶圆厂”业务），而在于其上的各个层面。<br>○寻找价值所在：应寻找那些正在构建卓越“钢铁侠战衣”（特定垂直领域的Copilot）、创造“AI的GUI”，或者——最关键地——通过简化AI与现实世界产品集成的复杂性来解决“胶水层”问题的公司。Cursor和Perplexity的估值表明这已经发生。Karpathy的“VibeCoding”经历揭示了当前最大的痛点，也因此指向了最巨大的机遇。</p>
<p>3. AndrejKarpathy-Wikipedia,accessedJune20,2025,https :&#x2F;&#x2F;en. wikipedia.org&#x2F;wiki&#x2F;Andrej_Karpathy</p>
<p>6. ScaleAI:AcceleratetheDevelopmentofAIApplications,accessedJune20,2025,https :&#x2F;&#x2F;scale. com&#x2F;<br>7. SoftwareintheeraofAI.pdf</p>
<p>28. Blog|karpathy,accessedJune20,2025,https :&#x2F;&#x2F;karpathy. bearblog.dev&#x2F;blog&#x2F;</p>
<p>34. PerplexityAI-Wikipedia,accessedJune20,2025,https :&#x2F;&#x2F;en. wikipedia.org&#x2F;wiki&#x2F;Perplexity_AI</p>
<p>42. WelcometoClerkDocs,accessedJune20,2025,https :&#x2F;&#x2F;clerk. com&#x2F;docs</p>
<p>51. DeepWiki-DevinDocs,accessedJune20,2025,https :&#x2F;&#x2F;docs. devin.ai&#x2F;work-with-devin&#x2F;deepwiki</p>
<p>【AI技术与应用交流群｜仅限受邀加入】<br>AI算力领域TOP级从业者专属圈层<br>√与头部算力企业深度对话<br>√与AI上下游企业深度对话<br>√获取一手全球AI与算力产业信息<br>√获取AI热点及前沿产业独家信息<br>√随时了解全球AI领域高管最新观点及实录全文<br>√有机会参与AI主题产业交流活动<br>扫码验证身份（需备注姓名&#x2F;公司&#x2F;职务）<br>不止有DeepSeek，更有AI产业的未来！<br>|文章来源：数字开物<br>•END•<br>【专栏】精品再读<br>大模型最大的落地场景出现了｜2024数字开物大会成功举办<br>AI与数据中心出海东南亚面临两大挑战｜万字圆桌实录<br>2万字完整演讲实录：最强TPU芯片、全新AIAgent来了｜谷歌云Next大会<br>黄仁勋3万字完整精校实录：\“思考型token\“爆发，AIinfra即将巨变<br>何宝宏：大语言模型上半场已进入“垃圾时间”<br>深度｜“唤醒”特斯拉，进击的中国Robotaxi</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">ZejunCao</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://zejuncao.github.io/2025/06/24/1000003140-2650036049-1-1750757244/">https://zejuncao.github.io/2025/06/24/1000003140-2650036049-1-1750757244/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">ZejunCao</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                                    <span class="chip bg-color">人工智能学家</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2025/06/24/1000001422-2247509863-1-1750758154/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000001422-2247509863_1-1750758154.jpg" class="responsive-img" alt="动手学Dify：用Dify从0到1做智能体（文末送Dify Agent搭建实体书）">
                        
                        <span class="card-title">动手学Dify：用Dify从0到1做智能体（文末送Dify Agent搭建实体书）</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Coggle%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/">
                        <span class="chip bg-color">Coggle数据科学</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/06/24/1000003140-2650036049-4-1750757244/">
                    <div class="card-image">
                        
                        <img src="/medias/frontcover/1000003140-2650036049_4-1750757244.jpg" class="responsive-img" alt="图灵与维特根斯坦：天才的较量">
                        
                        <span class="card-title">图灵与维特根斯坦：天才的较量</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-06-24
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            ZejunCao
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%AD%A6%E5%AE%B6/">
                        <span class="chip bg-color">人工智能学家</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>



<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>



    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="503838841"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2025</span>
            
            <a href="/about" target="_blank">ZejunCao</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/ZejunCao" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:caozejun369@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=1378463428" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 1378463428" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="https://weibo.com/u/5915009280" class="tooltipped" target="_blank" data-tooltip="关注我的微博: https://weibo.com/u/5915009280" data-position="top" data-delay="50">
        <i class="fab fa-weibo"></i>
    </a>



    <a href="https://www.zhihu.com/people/Garfusion/posts" class="tooltipped" target="_blank" data-tooltip="关注我的知乎: https://www.zhihu.com/people/Garfusion/posts" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a>



</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
